# BM4LLM-SLR  
**Bias Mitigation for LLM-Assisted Systematic Literature Reviews**  

BM4LLM-SLR Ã© um sistema experimental e open-source projetado para apoiar pesquisadores na **fase de seleÃ§Ã£o de estudos** em **RevisÃµes SistemÃ¡ticas da Literatura (Systematic Literature Reviews â€“ SLRs)**.  
O objetivo Ã© tornar o uso de **Large Language Models (LLMs)** mais **confiÃ¡vel, transparente e menos enviesado**.  

ğŸ”— [Acesse a versÃ£o online do sistema](https://csm-research.github.io/10-BM4LLM-SLR/support-system/public/)  

---

## ğŸš€ Por que usar o BM4LLM-SLR?
RevisÃµes SistemÃ¡ticas da Literatura sÃ£o essenciais para consolidar evidÃªncias cientÃ­ficas, mas demandam **muito esforÃ§o manual** e estÃ£o sujeitas a **erros humanos**.  

Embora os **LLMs** possam auxiliar nessa tarefa, eles podem introduzir **viÃ©s ou inconsistÃªncias** se usados isoladamente.  

O BM4LLM-SLR adiciona uma camada de **mitigaÃ§Ã£o de viÃ©s**, oferecendo:  
- âœ… **ConfiguraÃ§Ã£o de limiares de confianÃ§a**  
- âœ… **Controle de rigor na seleÃ§Ã£o**  
- âœ… **ParticipaÃ§Ã£o ativa do revisor humano**  

Assim, aumenta-se a **confiabilidade** dos resultados e reduz-se o risco de viÃ©s.  

---

## ğŸ› ï¸ InstalaÃ§Ã£o e Uso

### 1. Rodar um LLM localmente com **Ollama**
VocÃª pode usar o [Ollama](https://ollama.com/) para executar modelos localmente.  

Com **Docker**:  
```bash
docker run -d --name ollama \
  -v ollama:/root/.ollama \
  -p 11434:11434 \
  -e OLLAMA_ORIGINS=* \
  ollama/ollama
