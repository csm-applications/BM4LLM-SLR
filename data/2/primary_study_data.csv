Secondary study DOI,Primary study Scopus EID,Primary study DOI,Title,Abstract,Keywords,Publication venue,Publication date,Publication type,Authors,Ground truth,Reason
10.1016/j.infsof.2022.107144,2-s2.0-85076144241,,"10th International Conference on Software Business, ICSOB 2019","The proceedings contain 38 papers. The special focus in this conference is on Software Business. The topics include: Educational innovations and gamification for fostering training and testing in software implementation projects; improving a startup learning framework through an expert panel; a board game to teach team composition in software startups; Does self-efficacy matter? on the correlation of self-efficacy and creativity in IT education; hard competencies satisfaction levels for software engineers: A unified framework; how software startup teams reflect: Approaches, triggers and challenges; amidst uncertainty – or not? decision-making in early-stage software startups; there’s no business like software business: Trends in software intensive business research; customer churn prediction in B2B contexts; online multiplayer games for crowdsourcing the development of digital assets: The case of ingress; Organizational innovativeness relies on business and IT alignment; MVP development process for software startups; technical debt trade-Off - Experiences from software startups becoming grownups; a dynamic software startup competency model; objectives and challenges in finnish software companies 2018 - Interview of 99 finnish software development firms; The impact of IT bootcamp on student learning - Experience from ICT enabled experiential-based course; implementing artificial intelligence ethics: A tutorial; A SECO meta-model: A common vocabulary of the SECO research domain; towards an understanding of iIoT ecosystem evolution - mindsphere case study; identifying architecture attributes in the context of software ecosystems based on a mapping study; activities and challenges in the planning phase of a software ecosystem; API management challenges in ecosystems; preface.",,Lecture Notes in Business Information Processing,2019-01-01,Conference Review,,Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-79953681609,10.1117/12.873726,20 Gbps optical link with high efficiency 1060 nm VCSEL,"Measurement results of a high speed, low power single channel optical link operating at 1060 nm are presented. The link is composed of low power VCSEL devices fabricated and provided by Furukawa Electric Co. Ltd. and a low cost OM2 fiber. Clear eye openings are observed at 20 Gbps with a 2 mA DC bias. A modulation voltage of 150 mVp-p results in a -4.1 dBm OMA at the fiber output in a back-to-back configuration, with 0.19 unit amplitude eye opening and 32 ps total jitter extrapolated to a 10-12 bit error ratio. The insertion of a 100 m-long OM2 fiber causes a small signal degradation due to low attenuation and dispersion. For an ideal index profile optimized for dual wavelength operation (850 and 1300 nm), the minimum modal dispersion of the fiber is in the vicinity of the current operation wavelength.",Dual-band OM2 fiber | High performance computing | High speed transmitter | InGaAs | Low power VCSEL | Optical interconnect,Proceedings of SPIE - The International Society for Optical Engineering,2011-04-11,Conference Paper,"Héroux, Jean Benoit;Takaki, Keishi;Tokunari, Masao;Nakagawa, Shigeru",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-84949238790,,"4th European Workshop on Software Process Technology, EWSPT 1995","The proceedings contain 33 papers. The special focus in this conference is on Metrics and Analysis Session. The topics include: Metrics and analysis session; process viewpoints; process-based software risk assessment; the use of roles and measurement to enact project plans in MVP-S; combining process models and metrics in practice; application experiments; space shuttle onboard software (OBS) development and maintenance process automation; a tentative characterisation; a survey and comparison of some research areas relevant to software process modeling; customising software process models; process differentiation and integration; open issues in the design of pm languages; in favour of a coherent process coding language; process modelling languages: one or many?; experiments in process interface descriptions, visualizations and analyses; related domains; the software process and the modelling of complex systems; interpretable process models for software development and workflow; integrating process technology and CSCW; distributed modelling session; process management in-the-many; a generalized multi-view approach; decentralised process modelling; coordination by behavioural views and communication patterns; configuration of situational process models; mechanisms for cooperation; current issues on integration; enveloping persistent tools for a process-centered environment; coordination for process support is not enough; coordination theory and software process technology; transaction technology for process modelling; stepwise specification of interactive processes in coo; session on change and meta-process; a reflexive formal software process model; transients change processes in process centered environments.",,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),1995-01-01,Conference Review,,Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-85032920588,,"4th International Conference on Lean Enterprise Software and Systems, LESS 2013","The proceedings contain 14 papers. The special focus in this conference is on Lean Enterprise Software and Systems. The topics include: Fuzzy cognitive maps as decision support tools for investigating critical agile adoption factors; agile project – an oxymoron? Proposing an unproject leadership model for complex space; exploring the tensions between software project portfolio management and agile methods: A research in progress paper; lean software development – what exactly are we talking about?; lean software development measures and indicators - A systematic mapping study; bringing total quality in to software teams: A frame for higher performance; improving development visibility and flow in large operational organizations; a brief history of budgeting: Reflections on beyond budgeting, its link to performance management and its appropriateness for software development; case study in responsive web design: Pragmatic agile and hero team approach - Time and cost savings with quality improvement; success factors in new service development - Digia flowd analysis; creating minimum viable products in industry-academia collaborations; preface.",,Lecture Notes in Business Information Processing,2013-01-01,Conference Review,,Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-85058519413,,"9th International Conference on Software Business, ICSOB 2018",The proceedings contain 12 papers. The special focus in this conference is on Software Business. The topics include: Changing and pivoting the business model in software startups; From MVPs to pivots: A hypothesis-driven journey of two software startups; Modeling support for strategic API planning and analysis; software ecosystem health of cryptocurrencies; benchmarking privacy policies in the mobile application ecosystem; artifact compatibility for enabling collaboration in the artificial intelligence ecosystem; continuous software portfolio performance management; generating win-win strategies for software businesses under coopetition: A strategic modeling approach; exploring business model changes in software-as-a-service firms; determinants for the success of software startups: Insights from a regional cluster.,,Lecture Notes in Business Information Processing,2018-01-01,Conference Review,,Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-85030237703,10.1109/ICME.2017.8019451,A block level adaptive MV resolution for video coding,"The latest video coding standard, HEVC, uses quarter pixel motion vector (MV) resolution for motion compensation. The adaptation of MV resolution supported by PMVR (progressive MV resolution) brings further improvement of the performance, by progressively adjusting the resolution according to the distance between the MV and the MV predictor (MVP). In this work, we propose to improve PMVR by adapting MV resolution at the prediction unit (PU) level relying on its size and its average absolute gradient. We additionally perform a smarter motion estimation around multiple MV predictors to fully take advantage of the proposed scheme. Compared to HEVC reference software (HM-16.6), the proposed method provides 1.2%, 3.2% and 1.2% average BD rate savings respectively for random access (RA), low-delay P (LP) and low-delay (LD) configurations.",HEVC | Motion compensation | Motion vector resolution | PMVR,Proceedings - IEEE International Conference on Multimedia and Expo,2017-08-28,Conference Paper,"Ray, Bappaditya;Jung, Joel;Larabi, Mohamed Chaker",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-0041521307,10.1109/CMPASS.1992.235756,A case study in process representation using MVP-L,"Explicit, formal representations of software processes are needed to help understand software development and maintenance processes, to analyze these processes prior to execution, to guide the execution of these processes, and finally to improve software processes in an evolutionary fashion. The creation of formal process representations includes activities such as requirements analysis, specification, design, coding, integration, and testing. We conducted a case study within TRW which involved the creation of formal process specifications and designs using MVP-L, an existing process notation. This paper describes the study, the lessons learned about process representation in general, and the lessons learned about the language MVP-L in detail.",Case study | Language assessment | Process design | Process representation | Process specification | Software process modeling,COMPASS 1992 - Proceedings of the 7th Annual Conference on Computer Assurance,1992-01-01,Conference Paper,"Klingler, Carol Diane;Neviaser, Melissa;Marmor-Squires, Ann;Lott, Christopher M.;Rombach, H. Dieter",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-85032656154,10.1007/978-3-319-68121-4_30,A coding efficiency improvement algorithm for future video coding,"Motion estimation is critical in motion coding. However, the fixed pattern of search center decision method in HEVC is lack of precision. Taking advantage of the surrounding coding unit information, a universal motion vector prediction framework is presented to improve the coding efficiency in HEVC. The proposed framework is composed of two parts: motion vector prediction (MVP) and search range (SR) selection. Firstly, a novel motion vector prediction (NMVP) method is presented to improve the coding efficiency. Secondly, an adaptive search range selection (ASRS) method is developed to reduce the coding complexity in motion estimation. The simulation results demonstrate that the overall bitrate can be reduced by 5.49% on average, up to 9.18% compared with HEVC reference software.",Coding efficiency | High efficiency video coding | Motion vector prediction | Search range,IFIP Advances in Information and Communication Technology,2017-01-01,Conference Paper,"Jiang, Xiantao;Wang, Xiaofeng;Yang, Yadong;Song, Tian;Shi, Wen;Katayama, Takafumi",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-85064160262,10.1109/LASCAS.2019.8667555,A Dependency-Free Real-Time UHD Architecture for the Initial Stage of HEVC Motion Estimation,"Novel coding tools and algorithms were proposed in the High Efficiency Video Coding Standard (HEVC), and are still being proposed over the HM reference software in order to achieve a better compression efficiency, decrease encoding time, make its stages suitable for hardware implementation, and other independent improvements. Particularly, for the initial stage of the motion estimation (ME) process, the Advanced Motion Vector Prediction (AMVP) and the Dynamic Search Range (DSR) algorithms were introduced in the field targeting the determination of the motion vector predictor (MVP), also used as the search center, and search range (SR), which are parameters needed in the subsequent steps of motion estimation (ME). However, the significant complexity of these new tools enhances the need to develop hardware (HW) accelerators. Furthermore, in the field of HW architectures for video compression, techniques that solve dependency problems (which are detrimental to performance)-in this case, between sub-stages of ME-were proposed by some authors. Thereupon, an integrated and synchronized dependency-free HW architecture for the initial stage of the ME process-regarding MV prediction and SR calculation-is proposed in this paper. Synthesis results on a middle ground FPGA (Kintex-7 xc7k70tfbv676-1) show that the integrated architecture can achieve a throughput up to 8K at 72 frames-per-second (4:2:2 subsampling) while using a maximum of 7.04% of the FPGA resources (on slice LUT's).",FPGA Design | HEVC | Motion Estimation | Motion Vector Prediction | Search Range,"2019 IEEE 10th Latin American Symposium on Circuits and Systems, LASCAS 2019 - Proceedings",2019-03-14,Conference Paper,"Chaudhry, Haris;Raffo, Mario;Silva-Cardenas, Carlos;Villegas, Cristopher",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-78651583358,10.1007/978-90-481-2311-7_45,A dynamic modeling of stock prices and optimal decision making using MVP theory,"In this paper, first a precise mathematical model is obtained for four competing or cooperating companies' stock prices and then the optimal buy/sell signals are ascertained for five different agents which are trading in a virtual market and are trying to maximize their wealth over 1 trading year period. The model is so that gives a good prediction of the next 30th day stock prices. The companies used in this modeling are all chosen from Boston Stock Market. Genetic Programming (GP) is used to produce the predictive mathematical model. The interaction among companies and the effect imposed by each of five agents on future stock prices are also considered in our modeling. Namely, we have chosen eight companies in order that there is some kind of interrelation among them. Comparison of the GP models with Artificial Neural Networks (ANN) and Neuro-Fuzzy Networks (trained by the LoLiMoT algorithm) shows the superior potential of GP in prediction. Using these models; five players, each with a specific strategy and all with one common goal (wealth maximization), start to trade in a virtual market. We have also relaxed the short-sales constraint in our work. Each of the agents has a different objective function and all are going to maximize themselves. We have used Particle Swarm Optimization (PSO) as an evolutionary optimization method for wealth maximization. © 2009 Springer Netherlands.",Genetic Programming | Mean-variance portfolio selection | Particle Swarm Optimization (PSO) | Price prediction | Stock market model,Lecture Notes in Electrical Engineering,2009-09-25,Conference Paper,"Rajabioun, Ramin;Rahimi-Kian, Ashkan",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-85031703882,10.1109/ICMEW.2017.8026229,A fast skip and direction adaptive search algorithm for Sub-Pixel Motion Estimation on HEVC,"Motion Estimation (ME) is one of the most time-consuming parts in video coding loop. It is important to develop fast Sub-Pixel ME (SPME) algorithm which brings higher prediction accuracy as well as higher computational complexity. In this paper, we propose a fast skip and direction adaptive search algorithm for SPME in order to balance the coding performance and complexity. Firstly, a fast skip algorithm is utilized to skip SPME directly in most stationary regions and an error-tolerant algorithm is introduced to avoid over-optimization. Next, a direction adaptive search algorithm with early-termination technique is applied to 1/2-pixel and 1/4-pixel motion search. Experimental results demonstrate the advantage of the proposed algorithm on HEVC reference software HM-16.0, which succeeds in reduction of the total encoding time averagely for up to 42.37% on surveillance videos and 26.60% on conference videos with a negligible coding efficiency loss.",direction adaptive search | HEVC | MVP | Sub-pixel motion estimation,"2017 IEEE International Conference on Multimedia and Expo Workshops, ICMEW 2017",2017-09-05,Conference Paper,"Yan, Jiaying;Tian, Yonghong;Wang, Yaowei;Dong, Siwei;Huang, Tiejun",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-0030618696,10.1016/S0006-3207(96)00134-6,A feasibility study of reintroducing wild boar Sus scrofa to Scotland: Are existing woodlands large enough to support minimum viable populations,"The feasibility of reintroducing wild boar Sus scrofa to Scotland was investigated through the identification of a minimum viable population (MVP) and an assessment of suitable woodland habitat that could support such an MVP. A population viability analysis was performed, using the VORTEX software to establish an MVP. The sensitivity of the results to alternative modelling strategies was tested. An initial population of 300 individuals had a probability > 0.95 of surviving 50 years, and was identified as the MVP. Supplementation of the population with unrelated individuals was also simulated, and a range of strategies modelled. With a supplementation level of four animals every 5 years the MVP was reduced to just 10 animals. Based on a review of Sus scrofa ecology, woodland habitats suitable for supporting wild boar were identified. Only woodlands containing some stands of semi-natural origin were considered. The suitability of the three largest woodlands for supporting an MVP was further reviewed at site level. None could be considered optimum habitat for wild boar and none was large enough to support an MVP of 300 animals. The study concluded that the goal of establishing a self-sustaining population of wild boar in Scotland is unrealistic in the short term. Management options that would support a reintroduction programme are discussed.",minimum viable population and Scotland | reintroduction | VORTEX | wild boar,Biological Conservation,1997-07-01,Article,"Howells, O.;Edwards-Jones, G.",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-84903690273,10.1109/WICSA.2014.13,A journey through the land of model-view-design patterns,"Every software program that interacts with a user requires a user interface. Model-View-Controller (MVC) is a common design pattern to integrate a user interface with the application domain logic. MVC separates the representation of the application domain (Model) from the display of the application's state (View) and user interaction control (Controller). However, studying the literature reveals that a variety of other related patterns exists, which we denote with Model-View- (MV) design patterns. This paper discusses existing MV patterns classified in three main families: Model-View-Controller (MVC), Model-View-View Model (MVVM), and Model-View-Presenter (MVP). We take a practitioners' point of view and emphasize the essentials of each family as well as the differences. The study shows that the selection of patterns should take into account the use cases and quality requirements at hand, and chosen technology. We illustrate the selection of a pattern with an example of our practice. The study results aim to bring more clarity in the variety of MV design patterns and help practitioners to make better grounded decisions when selecting patterns. © 2014 IEEE.",controller | Design pattern | model | MVC | MVP | MVVM | User interface | view,"Proceedings - Working IEEE/IFIP Conference on Software Architecture 2014, WICSA 2014",2014-01-01,Conference Paper,"Syromiatnikov, Artem;Weyns, Danny",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-85069040040,10.1080/12460125.2019.1642081,A Lean Start-up approach for developing minimum viable products in an established company,"The minimum viable product (MVP) is a fundamental concept of the Lean Start-up approach as it enables a company to quickly start the learning process by integrating feedback from early adopters. Although the MVP concept has evolved over the years, its application is most often reported in a start-up context, even though established companies struggle to develop MVPs. This study reports on the experience and lessons learned at Texuna, an established company, where the software product innovation team created a process map for developing MVPs. This is the first study that allows the original MVP approach to be extended and applied to established organisations.",Lean start-up | minimum viable product | product market fit,Journal of Decision Systems,2019-07-03,Article,"Dennehy, Denis;Kasraian, Laleh;O’Raghallaigh, Paidi;Conboy, Kieran;Sammon, Dave;Lynch, Patrick",Include,Yes
10.1016/j.infsof.2022.107144,2-s2.0-79954446562,10.1007/s11265-009-0357-0,A low power reconfigurable analog baseband block for software defined radio,"In this paper, an inverter based transconductor using double CMOS pair is proposed for implementation of a reconfigurable analog baseband block consisting of a variable gain amplifier (VGA) and a second order lowpass G m-C filter. The centre frequency of the filter is varied using current steering DAC. Major contributions of this paper are: proposal for operating the transconductance (G m) stage and current steering DAC in sub-threshold region in order to minimize the power dissipation, design of variable gain amplifier (VGA) using switched G m cells with dummy stages, proposal for a digital tuning technique for the filter based on phase comparison method for compensation against process, voltage and temperature variations. The proposed analog baseband block is designed and implemented on TSMC-0.18∈μm CMOS process with 1.8 V supply using g m/I d design methodology. The post layout simulation results demonstrate the tunability of the centre frequency from 100 KHz to 20 MHz which meets the requirements of zero IF receivers for SDR applications. The third order input intercept point (IIP3) is found to be 15 dBVp for an input signal of 100 mVp. The power dissipated by the baseband block is 1 mW and 5 mW at 100 KHz and 20 MHz respectively and it requires silicon area of 0.173 mm 2. The SFDR over the entire bandwidth is 58 dB. The proposed approach guarantees the upper bound on THD to be-40 dB for 300 mVpp signal swing. The use of inverters with double CMOS pair results in 34 dB higher PSRR compared to those using push pull inverter. © 2009 Springer Science+Business Media, LLC.",Analog baseband filter | Continuous-time filter | Current steering DAC | Double CMOS pair | Reconfigurable filter | Software Defined Radio | Subthreshold,Journal of Signal Processing Systems,2011-02-01,Article,"Ramasamy, S.;Venkataramani, B.",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-85097529516,10.1109/UYMS50627.2020.9247024,A Mobile Health Application for Healthy Living: HWOW (Healthier Work for Office Workers),"In this paper, the author shares the knowledge and experiences about a mobile health application named HWOW (Healthier Work for Office Workers) which is designed as a means to support a healthier work for office workers (gold or white-collar employees working relatively inactive at the computer or the desk all day). In this scope, initially, some important definitions and concepts related to electronic health (e-health), mobile health (m-health), and relevant applications are provided. What's more, all-inclusive specifics are provided on the subjects of the answers for the questions of what, how, and why regarding HWOW, the information about HWOW's development process, the results of the polls to decide on the minimum viable product, the differences of HWOW from related applications, and the features of HWOW. Lastly, the current status and plans for HWOW are presented. In the contexts of software engineering for health and mobile health, the author thinks this paper is going to be beneficial for both product developers and relevant researchers.",e-health | health informatics | healthier work for office workers | healthy living | HWOW | m-health,"2020 Turkish National Software Engineering Symposium, UYMS 2020 - Proceedings",2020-10-07,Conference Paper,"Degerli, Mustafa",Exclude,EC1
10.1016/j.infsof.2022.107144,2-s2.0-85061493745,10.1007/978-3-030-11030-7_2,A model-driven method for fast building consistent web services from OpenAPI-compatible models,"Lots of software companies rely on web technologies to test market hypotheses in order to develop viable businesses. They often need to quickly build web services that are at the core of their Minimum Viable Products (MVPs). MVPs must be reliable whereas they are based on specifications and hypotheses that are likely to change. Web services need to be well documented, to make it easy to develop applications that consume them. Model Driven Engineering approaches have been proposed and used to develop and evolve web services on one hand, and document them on the other hand. However, these approaches lack the ability to be suitable for both (i) rapid prototyping, (ii) model verification, (iii) compatibility with common programming languages and (iv) alignment between documentation and implementation. Here we propose a meta-model to express web services, the related tool to verify models consistency and an integration of this approach into the OpenAPI Specification. We adopt a shallow verification process to allow rapid prototyping by developers who are not formal methods experts, while still offering design-time guarantees that improve product quality and development efficiency. Web services are defined using parametric components which enable to express and formally verify web service patterns and to safely reuse them in other contexts. We built a tool to check consistency of extended OpenAPI 3.0 models and associated components implementations in order to generate corresponding web services. This allows us to give flexibility and verification support to developers, even in the context of an incremental development, as illustrated by a case study.",Code generation | Formal verification | Model-driven engineering | OpenAPI 3.0 | Web applications | Web services,Communications in Computer and Information Science,2019-01-01,Conference Paper,"Sferruzza, David;Rocheteau, Jérôme;Attiogbé, Christian;Lanoix, Arnaud",Exclude,EC1
10.1016/j.infsof.2022.107144,2-s2.0-85052012039,10.5220/0006531900150024,A model-driven method for fast building consistent web services in practice,"Nowadays, lots of software companies rely on web technologies to test market hypothesis and develop viable businesses. They often need to quickly build web services that are at the core of their Minimum Viable Products (MVPs). MVPs must be reliable and are based on specifications and hypothesis that are likely to change. Model Driven Engineering approaches have been proposed and used to develop and evolve web services. However, these approaches lack the ability to be suitable for both (i) rapid prototyping, (ii) model verification and (iii) compatibility with common programming languages. Here we propose a meta-model to express web services and the related tool to verify models consistency. We adopt a shallow verification process to allow rapid prototyping by developers who are not formal methods experts, while still offering design-time guarantees that improve product quality and development efficiency. Web services are defined using parametric components which enable to express and formally verify web service patterns and to safely reuse them in other contexts. We built a tool to check consistency of models and associated components implementations in order to generate corresponding web services. This allows us to give flexibility to developers, as well as verification support and an easier onboarding for new developers.",Formal Verifications | Model-driven Engineering | Software Engineering | Web Applications | Web Services,MODELSWARD 2018 - Proceedings of the 6th International Conference on Model-Driven Engineering and Software Development,2018-01-01,Conference Paper,"Sferruzza, David;Rocheteau, Jérôme;Attiogbé, Christian;Lanoix, Arnaud",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-85063457137,10.1016/j.physb.2019.02.041,A modern approach to QENS data analysis in Mantid,"Data analysis of Quasi-elastic Neutron Scattering (QENS) experiments often requires multiple steps involving fitting the elastic and quasi-elastic parts of spectra with several empirical functions and analytical models. Parameters of those models can be interdependent and also dependent on the momentum transfer vector Q. Here we present a modern data analysis interface dedicated for QENS data analysis implemented within the open source software Mantid. The interface has been implemented using the state-of-the-art design pattern Model-View-Presenter (MVP). The MVP, an architectural software design pattern, facilitates automated unit tests as well as decoupling of the business logic, presentation logic and the graphical interface. Several models are implemented for analysing both elastic and quasi-elastic parts of the dynamical scattering function S(Q, ω) and intermediate scattering function I(Q, t). To understand the nature of dynamics in a QENS experiments, several models are also implemented for elastic incoherent structure factor (EISF) and jump diffusions. The interface has been validated by analysing a sample of liquid water at room temperature. The nature of hydrogen bond dynamics of the hydrogen bonded organic ferroelectric 2, 4, 5 − Br 3 imidazole, for the first time has been analysed using this newly implemented software. It is found that protons exhibit localised random motion in this material.",Mantid interface | Model-View-Presenter design pattern | Organic ferroelectrics | QENS data analysis | Quasi-elastic Neutron Scattering | Scientific software,Physica B: Condensed Matter,2019-06-15,Article,"Mukhopadhyay, Sanghamitra;Hewer, Brandon;Howells, Spencer;Markvardsen, Anders",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-85099761448,10.1109/IEEM45057.2020.9309952,A pilot study of industry 4.0 asset interoperability challenges in an industry 4.0 laboratory,"System integration is a crucial concept in the Industry 4.0 (I4.0) vision, where information processes supporting flexible production are digital. System integration paves the way for leveraging the Industrial Internet of Things, big data analysis, simulation, cloud computing, and augmented reality. The first step towards system integration is to examine the assets (machine software) ability to exchange information in an I4.0 setting. This paper aims to analyze challenges for asset interoperability by conducting asset integration in the University I4.0 laboratory (I4.0 lab). Conducting asset integration has been a part of building an Information Backbone (IB) as a minimum viable product in the I4.0 lab. An IB is a software infrastructure that involves integrating into various assets, e.g., warehouse, transport, and robotic systems, and providing communication among them. The pilot study reveals that the maturity of assets interoperability readiness are at very different levels, e.g. missing external interfaces, poor documentation, and varying technologies. These challenges need to be further addressed to collect architectural requirements for system integration, and establish a common vocabulary and understanding of I4.0 concepts.",Asset interoperability | Challenges | Flexible Robots | IIoT | Industry 4.0 | Information Processing and Engineering | Software infrastructure | System Integration,IEEE International Conference on Industrial Engineering and Engineering Management,2020-12-14,Conference Paper,"Jepsen, S. C.;Mork, T. I.;Hviid, J.;Worm, T.",Exclude,EC1
10.1016/j.infsof.2022.107144,2-s2.0-84964219504,10.1109/CIT/IUCC/DASC/PICOM.2015.214,A simple software development methodology based on mvp for Android applications in a classroom context,"With the world becoming a more mobile place for everyone through the use of smartphones, tablets and laptop computers, the need to help people to get mobile programming skills has never been greater. If anyone wants to become a mobile applications developer, the best approach might just be to learn how to develop and start doing it, and it's ""to learn how to develop"", the really important point. In this paper, we present a simple methodology which takes many features of different programming methodologies and uses its own. The main purpose of our methodology is that professionals in any field, with limited skills in mobile programming, can perform simple Android applications for use in their work environment or undergraduate engineering students can develop amazing apps with a minimum effort.",Android | Developing process or methodology | Learning | Mvp | Prototyping | Simple sequence diagrams,"Proceedings - 15th IEEE International Conference on Computer and Information Technology, CIT 2015, 14th IEEE International Conference on Ubiquitous Computing and Communications, IUCC 2015, 13th IEEE International Conference on Dependable, Autonomic and Secure Computing, DASC 2015 and 13th IEEE International Conference on Pervasive Intelligence and Computing, PICom 2015",2015-12-22,Conference Paper,"Ojeda-Guerra, C. N.",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-84991325547,10.1109/VHCIE.2016.7563567,A software framework for developing mathematical model driven virtual human,"Virtual Humans (VH) have many benefits, such as simulating humans when using real humans is difficult, impossible, or dangerous. VHs realism in behavior and response may be improved by mathematical models, which can provide dynamic responses and interactions and have the potential to be widely applied in training and education, such as medical training (e.g. physiological models of blood flow). However, the difficulties of developing mathematical model driven VHs may restrict the application of it, especially in the areas where the professionals do not know how to program (e.g. doctors). We present Mathematical Virtual People (MVP), which is a software framework that may simplify the developing job and encourage the applications of VHs driven by mathematical models, such as the drug reaction models and the cardiovascular system models.",Mathematical Model | Software Framework | Virtual Human,"2016 IEEE Virtual Humans and Crowds for Immersive Environments, VHCIE 2016",2016-09-08,Conference Paper,"Mei, Chao;Quarles, John",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-85060018993,10.1109/ICELTICS.2018.8548784,A Tale of Two Development Approach: Empirical Study on the Maintainability and Modularity of Android Mobile Application with Anti-Pattern and Model-View-Presenter Design Pattern,"Software development on mobile devices is overgrowing. However, the software still frequently unstructured developed without any pattern that can facilitate other developers to continue that software development, we called this approach as »anti-pattern.» To overcome the anti-pattern problem and with the goal of improving maintainability, the developer begins to apply various architectural design patterns such as MVC, MVP, and MVVM to the development of Android-based mobile application. In this paper, we compare maintainability and modularity between 2 applications build with design pattern (MVP) and without design pattern or commonly referred as 'anti-pattern' using jHawk 6 as a software metrics tools. Use of jHawk 6 reduced subjectivity of measurements in some of the previous studies that make this research more proven with the use of selected maintainability and modularity metrics from previous qualified studies. In the end, this study proved empirically, use of MVP Design pattern significantly increase modularity by two times. With this results, we strongly recommend the use of the MVP design pattern in android based mobile application development.",Android; Design Pattern | Maintainability | Mobile Application Development | Modularity,"Proceedings - 2nd 2018 International Conference on Electrical Engineering and Informatics, ICELTICs 2018",2018-11-27,Conference Paper,"Prabowo, Ginanjar;Suryotrisongko, Hatma;Tjahyanto, Aris",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-84956780221,10.1016/j.jns.2015.09.363,Absence of association between major vault protein (MVP) gene polymorphisms and drug resistance in Chinese Han patients with partial epilepsy,"Drug resistance in epilepsy is common despite many antiepileptic drugs (AEDs) available for treatment. The development of drug resistant epilepsy may be a result of multiple factors. Several previous studies reported that the major vault protein (MVP) was significantly increased in epileptogenic brain tissues resected from patients with partial-onset seizures, indicating the possible involvement of MVP in drug resistance. In this article, we aimed to identify the association between single nucleotide polymorphisms (SNPs) of MVP gene and drug resistance of partial epilepsy in a Chinese Han population. A total of 510 patients with partial-onset seizures and 206 healthy controls were recruited. Among the patients, 222 were drug resistant and 288 were responsive. The selection of tagging SNPs was based on the Hapmap database and Haploview software and the genotyping was conducted on the Sequenom MassARRAY iPLEX platform. For the selected loci rs12149746, rs9938630 and rs4788186 in the MVP gene, there was no significant difference in allele or genotype distribution between the drug resistant and responsive groups, or between all of the patients and healthy controls. Linkage disequilibrium between any two loci was detected but there was no significant difference in haplotype frequency between the drug resistant and responsive groups. Our results suggest that MVP genetic polymorphisms and haplotypes may not be associated with drug resistance of partial epilepsy in the Chinese Han population.",Chinese Han | Drug resistance | Epilepsy | Haplotype | Major vault protein | Polymorphism,Journal of the Neurological Sciences,2015-01-07,Article,"Zhou, Luo;Zhang, Mengqi;Long, Hongyu;Long, Lili;Xie, Yuanyuan;Liu, Zhaoqian;Kang, Jin;Chen, Qihua;Feng, Li;Xiao, Bo",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-85089031990,10.23919/CISTI49556.2020.9140904,Accessible Features to Support Visually Impaired People in Game Development: : A Systematic Literature Review of the last 15 years,"This paper presents a systematic review of the literature to investigate best practices for developing digital games for people with visual impairments. The execution of the search protocol that focused on papers published between 2004 and 2019, 17 papers were obtained from two online databases. The selected papers present information about the application of accessibility features that were tested in a minimum viable product applied to people with visual impairments. As a result, it was found that most papers focus on navigation systems, which is a feature used in most digital games, and all of them make use of sound effects. In most of the researched papers, audio is the main instrument to assist the visually impaired player. The development features presented in the systematic review can serve as a basis for developers in the field. Finally, there is still little content in the literature on accessible features available in the context of digital games, which makes it an indispensable research field to explore.",accessibility | component | digital games | game development | visually impaired,"Iberian Conference on Information Systems and Technologies, CISTI",2020-06-01,Conference Paper,"Garcez, Leonardo;Thiry, Marcello;Fernandes, Anita",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-85098572458,10.1109/FIE44824.2020.9273821,Accommodating Shortened Term Lengths in a Capstone Course using Minimally Viable Prototypes,"This Full Paper presents a novel way of implementing the first half of a two-semester software design and implementation capstone course. The paper compares prior work from traditional (15-week) terms to a compressed (7-week) format and a significantly compressed (4-week) format employing this approach. To maximize competitiveness, many programs are under pressure to do more with less: competing to provide more outcomes and more practical real-world experiences in less time and with fewer courses. These challenges become especially significant in capstone courses, where students, still learning, must design and implement solutions consolidating a wide variety of skills and knowledge covered in the curriculum.The capstone course spans two semesters; the first semester focuses on design and the second semester focuses on implementation. In the standard approach, teams meet with the client and develop design documents including use cases, user interface sketches, and data models. In this approach, rather than starting from scratch, students received artifacts from a previous capstone course employing a consultancy model. Artifacts included a request for proposal (RFP), a minimally viable prototype (MVP) partial implementation, and corresponding design documents. The work reviews students' ability to effectively incorporate the provided artifacts to produce a high quality design for complete implementation of the project.The work includes an evaluation of first-semester team deliverables generated under both the compressed and significantly compressed schedules and relates the expectations and outcomes to those in a traditional-length term. This approach offers a common means to assess schedule impacts and tailor the course in accordance with the relative concentration of contact hours associated with the schedule. This paper describes variations in expectations and options for MVP, client interaction schedules (including frequency and duration), and discusses the associated impacts as perceived by clients and mentors on engagement and student learning outcomes. Finally, the paper offers specific recommendations and lessons learned for those educators that are - or plan to - offer capstone courses under a highly compressed schedule.",capstone | computer science education | design methodology | minimally viable prototypes | pedagogy | software engineering,"Proceedings - Frontiers in Education Conference, FIE",2020-10-21,Conference Paper,"Eloe, Nathan;Hoot, Charles",Include,IC1
10.1016/j.infsof.2022.107144,,,ACM International Conference Proceeding Series,,,,,,,Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-85061580763,10.23736/S0394-3410.18.03872-9,Adaptive-compensatory reactions in athletes with locomotor disorders at different stages of the multiyear training,"BACKGROUND: The article considers the issues of the adaptation of athletes with musculoskeletal injuries to intensive physical loads at the stages of the long-term training process, depending on the functional class of the Paralympic athletes. METHODS: The study involved 28 highly qualified athletes with MSD, members of the national team (classes S5-8 with spinal cord injuries, with amputations of the extremities). To determine the state of the neuromuscular system, the bioelectrical activity of the athlete's deltoid muscle was assessed using 2-channel digital neurophysiological complex for electromyography and evoked potentials with the Neuro-MVP.net software. Hemodynamics and functional state of the cardiovascular system were studied using ""Valenta +"" computer appliance. RESULT S: After amputation of the lower extremities as a result of disinhibition of the sympathetic part of the autonomous nervous system, there are pronounced changes in the circulatory system, but properly planned adaptive sport trainings lead to improvement of the circulatory system. In athletes with TDSC, autonomic contour regulation is observed. Athletes with amputation have a significant decrease in the influence of sympathetic regulation and the contribution of central control levels to the regulation of heart rhythm. Adaptive sports activities reduce the time spent on the most rapidly conducting axons of the median nerve and the slowest conduction nerves, reduce the average latency. CONCLUSIONS: The transition from a short-term stage to a stable long-term adaptation is characterized by the development of structural transformations in regulatory mechanisms and morphofunctional systems. However, the course changes in athletes with TDSC and amputations has cardinal differences, which must be taken into account at all stages of long-term sports training.",Athletes | Disabled persons | Exercise | Health | Physiology,Minerva Ortopedica e Traumatologica,2018-09-01,Article,"Rumyantseva, Elvira;Dayanova, Albina",Include,IC1
10.1016/j.infsof.2022.107144,,,Adding agile architecture practices to a Cyber-Physial System development [Incorporación de prácticas de arquitectura ágiles en el desarrollo de un Sistema Ciber Físico],,,"Applications in Software Engineering - Proceedings of the 5th International Conference on Software Process Improvement, CIMPS 2016",,Conference Paper,,Exclude,EC3
10.1016/j.infsof.2022.107144,2-s2.0-85079486465,10.2118/191975-ms,Agile field development planning: A systems approach,"It can take months, perhaps a year or two, to get through Front End Loading (FEL) stages with the current industry approaches. As the industry strives to be more efficient, faster to market in this lower for longer world, we need a different and much faster, lower risk approach that does not Erode value. Multiple tools exist that allow subsurface/surface simulation integration and coupling, but these are cumbersome to configure and not appropriate for an early field development at the stage of pre-FEED (Front End Engineering and Design). To meet this challenge, an agile approach to Field Development Planning (FDP) has been established. The approach is inspired by agile project management techniques and best practices that are currently used in the automotive, aerospace, construction, software development industries and lean start-ups. It is based on parallel sprints rather than the waterfall approaches to project management. Collaborative teams work on parallel deliverables to create a minimum viable product (MVP) and value drivers for further development are established quantifiably with an Analytic Hierarchy Process (AHP). The notion of a fully representative dynamic techno-economic model is presented. This model applies a multi-dependent system thinking approach, with dynamic integration of economic, reservoir, subsea, facilities and schedule data. Two case studies are discussed where this approach was used to maximise economic benefits of the asset and accelerate the decision-making process during FEL stages: 1. Identification of the best compression solution to optimise the economic outcome of production from a complex group of 350 wells intersecting different reservoirs. The result of this example was an 18-month acceleration of the decision process and 30% cost saving. 2. Deciding whether the FEED should be oriented towards simultaneous or sequential production for the development of two marginal offshore satellite fields. This presentation will be of interest to anyone looking to speed up the time to first oil/gas and reduce production costs on undeveloped or underdeveloped fields and bid more confidently on assets during licence rounds with less risk. It will also be of interest to those wanting to accelerate their decision-making process during FEL stages from months or years to weeks and allow decision makers to visualise and test interdependencies creatively with less cognitive bias.",,"Society of Petroleum Engineers - SPE Asia Pacific Oil and Gas Conference and Exhibition 2018, APOGCE 2018",2018-01-01,Conference Paper,"Ciccarelli, John;McLachlan, Duncan;Singh, Himadri;Thomson, Rob",Include,IC1
10.1016/j.infsof.2022.107144,,,Agile needs FBM,,,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),,Conference Paper,,Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-85074312077,10.1007/978-1-4842-4081-6,Agile office 365: Successful project delivery practices for an evolving platform,"Plan, deploy, and run Office 365 using an agile project management approach. This soup-to-nuts guide teaches you how to apply agile techniques in order to make your Office 365 implementation a success, even as the Microsoft Office 365 platform continues to evolve and introduce new features. The author's approach to teaching time- and resource-saving concepts mirrors the process a team might typically encounter in delivering software projects. Learning begins with an overview of Office 365 and Agile. From there, you delve into topics correlating to product conception, execution, and deployment. The book wraps up with a comprehensive discussion on how Office 365, straight out of the box, can be used as a tool to manage Office 365 deployments and other types of projects. What You'll Learn: Understand what Office 365 is and why it is the world’s most popular online business app Adapt your delivery process to work with Office 365 and its regular update schedule Recognize potential risk areas and develop mitigation strategies Discover the tools that are available to make your life easier Manage the transition from deployment to operations Follow end-to-end guidance packed with useful case studies and tools to make your job easier This book is for project managers, business analysts, IT managers, and other team members involved in managing Office 365 in order to deliver solutions for their organization. While not required, a basic understanding of Agile methodologies and Office 365 is useful. Haniel Croitoru is a seasoned SharePoint and Office 365 consultant and Microsoft Office 365 MVP with more than 15 years of experience in public and private sectors, focusing on SharePoint in the roles of consultant, project manager, business analyst, and trainer. Haniel enjoys sharing his expertise and can be found presenting at many conferences and community events. He holds an MS degree in Computer Science, a Master’s Certificate in Project Management, and has been a certified Project Management Professional (PMP) since 2007 and Agile Certified Practitioner since 2013.",Implementation | Microsoft | Migration | PointI | Share | Tmanager,Agile Office 365: Successful Project Delivery Practices for an Evolving Platform,2017-01-01,Book,"Croitoru, Haniel",Exclude,EC4
10.1016/j.infsof.2022.107144,2-s2.0-85057182619,,Agile Prototyping for technical systems Towards an adaption of the Minimum Viable Product principle,"The realization of radical innovations is a crucial success factor for manufacturing companies acting in an environment of increasing market dynamics. Heterogeneous customer requirements, which are increasingly changing in shorter cycles, become a major challenge for manufacturers of technical systems. Alongside these external circumstances, functional complexity of technical systems increases, which constitutes another major challenge in product development. As an answer to similar circumstances, the software industry introduced agile development methods in the early 1990s. The iterative development of functional product increments being shippable to potential customers at the end of a development phase has helped the industry to dynamically align the product to the customers' needs and to reduce the development time significantly. In this context, the concept of Minimum Viable Product (MVP) has gained particular attention. The MVP is a product, carrying just enough functionality to satisfy customers and to gather feedback for subsequent development with the least amount of effort and time. Taking the Lean Start Up initiative into account, the idea of MVP is generalized to be applicable to any type of new business or product. However, the aspect of selling incomplete products is commonly considered to be hardly applicable to technical systems. Nevertheless, the idea of iteratively validating major concerns and risks in product development applying the least amount of time and resources is equally agreed as a necessary step to tackle the challenges described above. Based on user stories for the product to be developed, major concerns and risks are deduced to be cleared out as early as possible with impacted stakeholders. Following the Design Thinking approach, Feasibility (Can we do this?), Desirability (Do they want this?) and Viability (Should we do this?) are types of uncertainty to be reduced as far as possible with each iteration. Due to increasingly interconnected technical systems, most of these subjects are very likely to impact several non-separable functions and disciplines within the system at once. Considering this along with the inherent fact of expensive and time-consuming realization of physical prototypes, the application of the MVP principle becomes a major challenge itself. Therefore, this paper introduces a holistic framework to elaborate an appropriate methodology to support the planning and design of prototypes in agile product development of technical systems. Thereby, the methodology provides an approach to implement physical prototypes in line with the Minimum Viable Product principle. As part of the overall methodology, the paper outlines a procedure to systematically structure design variables, which are meant to be specified and validated by a prototype with respect to particular concerns and risks under investigation. Therefore, the affected functions are systematically graduated and described by generic prototype features, capturing generic design elements such as the geometrical shape, the operating principle or the performance level which enables an initial evaluation whether a feature needs to be specified and captured within the physical realization. Based on this classification, a target-oriented design of physical prototypes is facilitated. Subsequent research will focus on further validating this procedure and on detailing the overall methodology, encompassing the procedure subject to this paper.",Agile Product Development | Minimum Viable Product | Product Design | Prototyping,"Proceedings of NordDesign: Design in the Era of Digitalization, NordDesign 2018",2018-01-01,Conference Paper,"Schuh, Günther;Dölle, Christian;Schloesser, Sebastian",Exclude,EC2
10.1016/j.infsof.2022.107144,2-s2.0-85055782385,10.1088/1757-899X/400/6/062003,"An ""agile"" approach to develop a crowdsourcing platform: The case of Cre@tive.biz","Globalization has a significant impact over economic and social development, thus it also influences the speed of developing new products, starting from the product idea to the Minimum Viable Product (MVP). The software industry is one of the industries which have to face tough and specific challenges within this highly dynamic context, playing a major role in defining the world's data for businesses, with a direct impact on the competitiveness of various industries. According to Lynn Holmlund's survey [1] of IT decision makers across a range of industries, 59 percent of respondents reported that improving the quality of decision making is the primary goal driving investments in data technologies. In a world underpinned by ever-more powerful, affordable, and public digital technology platforms, software is fast becoming the key source of economic value and competitive advantage in business. As a result, software applications are redefining nearly every industry, and Agile methodologies are redefining the software development process. Understanding the demand for developing software applications on time and responding to the users' needs and expectations are the first steps in using the Agile framework in product development and are even more important within the context of research projects, such as CRE@TIVE.BIZ, an ongoing project within the framework of the Romanian National Plan for Research, Development and Innovation 2014 - 2020 (PNCDI III). The goal of the project is to develop an open collaboration and innovation platform, CRE@TIVE.BIZ, which will be an experimental model dedicated to create a community where all relevant stakeholders can meet, interact, gain access and share information, knowledge and resources. The paper presents the platform development scenario, using a new and ""agile"" approach, namely Scrum, for product development based on continuous learning and optimization of development process, team involvement, prioritize the features - especially from the users' perspective - and stakeholder's involvement in describing the product, testing and acceptance. This new approach improves the delivery time and maximizes the results by using client's involvement in each step of the process, describing more clearly the platform functionalities and shortening the decision-making process. The tangible result will be the road map for CRE@TIVE.BIZ platform development, specifying tasks, roles, milestones and outcomes.",,IOP Conference Series: Materials Science and Engineering,2018-09-20,Conference Paper,"Bagiu, N.;Avasilcǎi, S.;Alexa, L.",Exclude,EC1
10.1016/j.infsof.2022.107144,2-s2.0-84874741557,10.1109/ICTEA.2012.6462877,An approach to a pattern for business process management and deployment of software engineering for small companies in a crossplatform era,"Software engineering and its constant evolution bring new concepts, new technologies and new devices. It requires big efforts, skills and resources to acquire in depth knowledge of all the parts that are necessary for building applications professional and efficiently today. Many small technological companies and freelance developers have serious doubts about how to manage a project, where to start it and how to evolve it. Cloud Computing, Web Services, Databases, Server Side Programming, Web and Native Applications for clients and many more are mandatory to know, understand and study to give to the project development technical and economical viability. This paper describes the theory of technologies, frameworks and common tools and proposes a widely used modern development pattern with good results. © 2012 IEEE.",Business Process Management | Cloud Computing | Minimum Viable Product | Programming Paradigms | Service-Oriented Architecture | Startups | Web Services,"2012 2nd International Conference on Advances in Computational Tools for Engineering Applications, ACTEA 2012",2012-12-01,Conference Paper,"Fernández-García, Antonio;Iribarne, Luis;Criado, Javier;Vallecillos, Jesús",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-85034426461,10.1109/SEAA.2017.45,An automated feedback-based approach to support mobile app development,"The acceptance of mobile applications is highly dependent on the realized set of features and on the quality of the application. Information about their acceptance can be gained quickly by collecting and analyzing user feedback such as explicit textual reviews provided by an application's users or implicitly provided usage data. With an approach based on developing a minimal set of functions in order to realize a minimum viable product (MVP), it is possible to put a product on the market within a short amount of time. Currently, the elicitation, analysis, and processing of user feedback is unfocused and takes too much time and effort to mitigate the poor quality of the application. Hence, we outline an approach named Opti4Apps, which is aimed at tailored quality assurance as part of MVP development and enables and expands the benefits of an MVP by providing a semiautomated feedback elicitation, analysis, and processing framework. This is intended to raise the effectiveness and efficiency of early user feedback consideration during further development in order to assure the quality and acceptance of an app as an MVP. We will present the overall structure as well as the process behind the Opti4Apps framework. As proof-ofconcept, we implemented an initial prototype of our idea, focused on textual user feedback.",Automation | Mobile | MVP | User feedback,"Proceedings - 43rd Euromicro Conference on Software Engineering and Advanced Applications, SEAA 2017",2017-09-26,Conference Paper,"Scherr, Simon Andre;Elberzhager, Frank;Holl, Konstantin",Include,Yes
10.1016/j.infsof.2022.107144,2-s2.0-85086053731,10.3997/2214-4609.20141755,An effective method for mineral exploration,"Since the beginning of this century geoelectric methods that utilize natural alternating electromagnetic field of the Earth ia becoming more and more popular in the practice of geophysical surveys. This fact is due to the high sensitivity and resolution, as well as mobility and smaller team of field crew. One of such methods is Magnetovariational Profiling (MVP). Method is based on the measurement of three orthogonal magnetic components of Earth' EM field. The method has a well established technique of field work, well endowed instrumental base and advanced software for processing and analyis of field data. MVP methods also has well developed techniques for both the profiles and the plane data interpretation, including methods of robust interpretation of the tipper frequency characteristics. Based on these characteristics, it is possible to determine the position of the object in terms of the ore, the depth to its center, the shape and conductivity of the body directly in the field. To the date, vast experience of successful application of MVP method had been accumulated for mining exploration and solving other geological tasks. Application of precision tripods for mounting magnetic sensors provides year-round, high-performance applications of the method in any terrain conditions.",,GEOBAIKAL 2014 - 3rd International Geobaikal Conference 2014: Exploration and Field Development in East Siberia,2014-01-01,Conference Paper,"Senchina, N.;Ermolin, E. U.;Ingerov, I.",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-85065655207,10.1145/3297280.3297447,An exploratory study of MVC-based architectural patterns in android apps,"Mobile app development now represents a significant part of the software industry, with Android being the largest ecosystem. Android development comes with its own design practices and templates (layouts, activities, etc.). Developers also use different established architectural patterns for designing interactive software such as MVC, MVP and MVVM. They implement these patterns based on their understanding and experience. Thus, the choice and the implementation of such patterns varies from a developer to another. To the best of our knowledge, there is no work that provides a comprehensive view of the use of these patterns in mobile apps. Moreover, there is no clear understanding of which pattern to use and what is the trend for designing mobile apps using such patterns. In this paper, we propose an automatic approach to identify which MVC-based architectural pattern (MVC, MVP and MVVM) is used predominantly in a given app. For this purpose, we defined each of these patterns through a number of heuristics according to the pattern's potential implementations within the Android framework. We conducted an empirical study on a large set of mobile apps downloaded from the Google Play Store. We found, not surprisingly, a dominance of the popular MVC pattern, a rare use of MVP while MVVM is almost unused and a significant number of apps do not follow any pattern. The empirical study also enabled us to analyse the use of these patterns by domain, size and last-update date of the apps. We observed that MVC has been the most used pattern over the past years and it continues to gain popularity, and that small-size apps are mostly the ones that do not use any pattern.",Architectural patterns | Design patterns | Mobile development | MVC | MVP | MVVM | Software architecture,Proceedings of the ACM Symposium on Applied Computing,2019-01-01,Conference Paper,"Daoudi, Aymen;Moha, Naouel;ElBoussaidi, Ghizlane;Kpodjedo, Sègla",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-4944223373,,An integrated video sensor design for traffic management and control,"A new integrated video sensor design for applications in traffic management and control to solve problems associated with affordability and reliability was discussed. This integrated video sensor has many features such as integration of the transducers and the MVP into one compact unit improving detection reliability and lowering susceptibility to EMI. The sensor also lowered installation costs, reduced installation time and enabled rapid deployment making the system more readily portable. The new communication architecture offered optimal routing of the machine vision detection results, full motion video as well as digital imagery and supervisory control.",Automated incident detection | Automated speed enforcement | Machine vision sensor | Network communication architecture | Queue measurement | Software architecture | Traffic data collection | Vehicle tracking | Video vehicle detection,Recent Advances in Signal Processing and Communications,1999-12-01,Article,"Panda, Durga P.",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-56149101286,,An XML standard for virtual patients: exchanging case-based simulations in medical education.,"Virtual Patients are computer-based simulations of a clinical encounter where the user plays the role of a healthcare provider while receiving in-context instruction. This unique pedagogical approach enables active case-based learning for learners. Academic institutions around the world have developed high-quality virtual patients using many different authoring and playback technologies. However, sustainability and scalability have proved challenging due to the number of cases needed and production costs. In an effort to promote sharing of Virtual Patients and broader adoption into medical education at all levels, MedBiquitous organized an international working group to create an XML-based ""MedBiquitous Virtual Patient Standard"" (MVP) describing a common structure for virtual patient content and activities. The MVP enables virtual patient exchange across systems, modification, and display within conformant player software.",,AMIA ... Annual Symposium proceedings / AMIA Symposium. AMIA Symposium,2007-01-01,Article,"Triola, Marc M.;Campion, Ned;McGee, James B.;Albright, Susan;Greene, Peter;Smothers, Valerie;Ellaway, Rachel",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-79953886887,,Analysis of core physics experiments on irradiated BWR MOX fuel in REBUS program,"As part of analyses of experimental data of a critical core containing a irradiated BWR MOX test bundle in the REBUS program, depletion calculations was performed for the BWR MOX fuel assemblies from that the MOX test rods were selected by using a general purpose neutronics code system SRAC. The core analyses were carried out using SRAC and a continuous energy Monte Carlo code MVP. The calculated keffs were compared with those of the core containing a fresh MOX fuel bundle in the program. The SRAC-diffusion calculation underestimates keffs of the both cores by 1.0 to 1.3%dk and the keffs of MVP are 1.001. The difference in keff between the irradiated BWR MOX test bundle core and the fresh MOX one is 0.4%dk in the SRAC-diffusion calculation and 0.0%dk in the MVP calculation. The calculated fission rate distributions are in good agreement with the measurement in the SRAC-diffusion and MVP calculations. The calculated neutron flux distributions are also in good agreement with the measurement. The calculated bumup reactivity in the both calculations well reproduce the measurements.",,"International Conference on the Physics of Reactors 2008, PHYSOR 08",2008-01-01,Conference Paper,"Yamamoto, Toru;Ando, Yoshihira;Hayashi, Yamato",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-84859233195,10.1080/00223131.2011.649075,Analysis of core physics experiments on irradiated BWR MOX fuel in the REBUS program,"Critical experiments were performed in the REBUS program on a core loaded with a test bundle including 16 irradiated BWR-type MOX rods of average burnup of 61 GWd/t. The experimental data were analyzed using diffusion, transport, and continuous-energy Monte Carlo calculation codes coupled with nuclear data libraries based on JENDL-3.2 or JENDL-3.3. Biases in effective multiplication factors of the critical cores were -1.0%Δk for the diffusion calculations (JENDL-3.2), -0.3%Δk for the transport calculations (JENDL-3.3), and 0.2%Δk for the Monte Carlo calculations (JENDL-3.2). The measured core fission rate and co-activation rate distributions were generally well reproduced using the three types of calculations. The burnup reactivity determined using the measured water level reactivity coefficients was -2.41±0.08%Δk/ kk', which also agreed with the results of the three type of calculations within the measurement and calculation errors. The most probable isotopic inventories in the irradiated MOX rods was tentatively obtained by using the ratios of the calculation to chemical assay data on a pellet sample, and the burnup reactivity was reanalyzed to split the calculation error into those due to the inventory and reactivity calculations. This approach showed that the inventory calculation error compensated the reactivity calculation error. © 2012 Atomic Energy Society of Japan. All rights reserved.",Burnup calculation | BWR | CITATION | Core calculation | Core physics experiment | Irradiated MOX rod | MVP | REBUS | SRAC | THREEDANT,Journal of Nuclear Science and Technology,2012-04-05,Article,"Yamamoto, Toru;Ando, Yoshihira;Hayashi, Yamato;Azekura, Kazuo",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-0012255418,10.1016/0164-1212(94)00107-X,Analyzing knowledge-based systems with multiviewpoint clustering analysis,"Knowledge-based systems have wide commercial applicability. However, a credible validation methodology for knowledge-based systems is currently lacking. Better knowledge acquisition techniques as well as better management, understanding, and enhancement of the knowledge base is critical to the success of any verification or validation activities. Our research addresses the feasibility of partitioning rule-based systems into a number of meaningful units to enhance the comprehensibility, maintainability, and reliability of expert systems software. Preliminary results have shown that no single structuring principle or abstraction hierarchy is sufficient to understand complex knowledge bases. We therefore propose the multiviewpoint clustering analysis (MVP-CA) 'methodology to provide multiple views of the same expert system. MVP-CA provides an ability to discover significant structures within the rule base by providing a mechanism to structure both hierarchically (from detail to abstract) and orthogonally (from different perspectives). Here we describe our approach to understanding large knowledge bases via MVP-CA. We demonstrate the need for MVP-CA by use of a couple of small classic rule bases, as well as a deployed knowledge-based system that navigates the space shuttle's reentry. We also discuss the impact of this approach on verification and validation of knowledge-based systems. MVP-CA provides an essential first step toward building an integrated environment for verification and validation of knowledge-based applications. It allows one to build reliable knowledge-based systems by suitably abstracting, structuring, and otherwise clustering the knowledge in a manner that facilitates its understanding, manipulation, testing, and utilization. © 1995.",,The Journal of Systems and Software,1995-01-01,Article,"Mehrotra, Mala;Wild, Chris",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-77949671882,10.1109/CISE.2009.5366503,Application of MVP architecture in reengineering of legacy financial system,"As the progress of information technology, some financial systems used for long time can no longer meet the requirement of customers in both user interface and business process, and need reengineering imminently. In order to save the human resource and financial effort, this article raises a reengineering approach by encapsulating the back-end data access code of legacy system and only refactoring the front-end user interface and business logic. In the reengineering work, this article uses MVP (Model-View-Presenter) Architecture. By extracting screen logic into Presenters, the display code in View is independent from logic code in Presenter. Also, the introduction of MVP Architecture greatly enhances the reusability and the testability of business logic code, and finally improves the efficiency of development and test work significantly. ©2009 IEEE.",Code reuse | MVP architecture | Reengineering on legacy system | Windows presentation foundation,"Proceedings - 2009 International Conference on Computational Intelligence and Software Engineering, CiSE 2009",2009-12-01,Conference Paper,"Wu, Bo;Yang, Xiaohu",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-84958092807,10.15439/2015F142,Approach to building a web-based expert system interface and its application for software provisioning in clouds,"This paper focuses on a generalized approach to providing user interface to a web-based expert system (WBES). We examine MVC and MVP design patterns used traditionally to construct a web application user interface. In order to leverage the strength of the MVC/MVP design patterns we propose a special ontology representing a user communication domain. We describe a self-service networked infrastructure for automatic deployment of command line interface (CLI) applications. We demonstrate how to apply the proposed ontology for the design of a WBES aimed at supporting client software re-execution in clouds. In particular, we address the problems existing in the area of software development for music information retrieval algorithms implementation.",,"Proceedings of the 2015 Federated Conference on Computer Science and Information Systems, FedCSIS 2015",2015-01-01,Conference Paper,"Pyshkin, Evgeny;Kuznetsov, Andrey",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-85018688189,10.1007/978-3-319-57633-6_11,Are software startups applying agile practices? The state of the practice from a large survey,"Software startups operate under various uncertainties and the demand on their ability to deal with change is high. Agile methods are considered a suitable and viable development approach for them. However, the competing needs for speed and quality may render certain agile practices less suitable than others in the startup context. The adoption of agile practices can be further complicated in software startups that adopt the Lean Startup approach. To make the best of agile practices, it is necessary to first understand whether and how they are used in software startups. This study targets at a better understanding of the use of agile practices in software startups, with a particular focus on lean startups. Based on a large survey of 1526 software startups, we examined the use of five agile practices, including quality related (regular refactoring and test first), speed related (frequent release and agile planning) and communication practice (daily standup meeting). The findings show that speed related agile practices are used to a greater extent in comparison to quality practices. Daily standup meeting is least used. Software startups who adopt the Lean Startup approach do not sacrifice quality for speed more than other startups do.",Agile practice | Lean startup | Minimum viable product | Pivot | Quality vs speed | Software startups,Lecture Notes in Business Information Processing,2017-01-01,Conference Paper,"Pantiuchina, Jevgenija;Mondini, Marco;Khanna, Dron;Wang, Xiaofeng;Abrahamsson, Pekka",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-0031187671,10.1109/54.606003,Automated diagnosis in testing and failure analysis,"To meet market demands for the rapid introduction of new semiconductor products, automated means of diagnosing defective silicon are fast becoming mandatory. The authors describe the development and deployment of an automated diagnosis methodology within Texas Instruments.",,IEEE Design and Test of Computers,1997-07-01,Article,"Butler, Kenneth M.;Johnson, Karl;Platt, Jeff;Kinra, Anjali;Saxena, Jayashree",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-0034290331,10.1049/ip-sen:20000899,Automated software module reconfiguration through the use of artificial intelligence planning techniques,"One important approach to enhancing software re-use is through the creation of large-scale software libraries. By modularizing functionality, many complex specialized applications can be built up from smaller reusable general-purpose libraries. Consequently, many large software libraries have been formed for applications such as image processing and data analysis. However, knowing the requirements and formats of each of these routines requires considerable expertise - thus limiting the usage of these libraries to experts. An approach is described to enable novices to use complex software libraries. In this approach, the interactions between, and requirements of, the software modules are represented in a declarative language based on artificial intelligence (AI) planning techniques. The user is then able to specify their goals in terms of this language-designating what they want accomplished, instead of how to do it. The AI planning system then uses this model of the available subroutines to compose a domain specific script to fulfill the user request. Three such systems developed by the Artificial Intelligence Group of the Jet Propulsion Laboratory and described. The multimission VICAR planner (MVP) was deployed in 1994 and used to support image processing for science product generation for the Galileo mission. MVP reduced the time for filling certain classes of requests from 4 h to 15 min. The automated SAR image processing system (ASIP) was deployed in 1996 to the Department of Geology at Arizona State University to support aeolian science analysis of synthetic aperture radar images. ASIP reduces the number of manual inputs in science product generation tenfold. Finally, the DPLAN system reconfigures software modules that control complex antenna hardware in configuring antennas to support a wide range of tracks for NASA's Deep Space Network of communications and radio science antennas.",,IEE Proceedings: Software,2000-10-01,Article,"Chien, S.;Fisher, F.;Estlin, T.",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-85027715972,10.1109/EMES.2017.7980399,Automated testing framework development based on social interaction and communication principles,"The speed of development of the IT industry as well as the computational power which are increasing exponentially, create great competitiveness in the process of development but also in the launching of software products on the market. Automated testing comes to help with these challenges by trying to increase the speed of development by offering fast feedback and trustworthy quality by means of repeated runs of the implemented tests. This isn't a problem just on a technical level, but also on a social level, especially in the area of communication and understanding the requirements of the client. This work presents the implementation of an automated testing framework which also addresses the social problems. BDD or 'Behavior Driven Development' includes an approach which would like to line up the area of client requests to the technical area, offering a uniform platform of collaboration and development. The implementation of this principle is applied in an MVP (Minimum Viable Product) type project which is meant to demonstrate the technical solution which may draw together, both socially and communication wise, the business teams and the technical implementation teams.",automated testing | BDD | Gherkin language | testing process,"2017 14th International Conference on Engineering of Modern Electric Systems, EMES 2017",2017-07-13,Conference Paper,"Contan, Andrei;Miclea, Liviu;Dehelean, Catalin",Exclude,EC1
10.1016/j.infsof.2022.107144,2-s2.0-0025828490,10.1016/0010-4809(91)90025-R,Automatic tracking and digitization of multiple radiopaque myocardial markers,"An 80386 PC-based system was designed to track automatically multiple, miniature radiopaque markers implanted in the heart wall. This system eliminated the need for tedious, time-consuming manual digitization of marker coordinates. Use of a MATROX MVP-AT/NP image processing board incorporated advanced image processing and graphics features into the low-cost PC environment. Digital image enhancement and segmentation techniques (such as limiting analysis to predefined windows of interest, spatial band-pass and matched filtering, contrast stretching and clipping, linear adaptive prediction, intensity histogram analysis, adaptive binary thresholding, region growing, expanding region of analysis, and feature extraction) were incorporated into a user-friendly integrated marker processing software environment. Improved speed, accuracy, and reproducibility of the marker digitizing process were realized. These basic techniques have broad applications to other image processing needs in biomedical research. © 1991.",,Computers and Biomedical Research,1991-01-01,Article,"Niczyporuk, Marek A.;Miller, D. Craig",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-79951594383,10.1109/TEST.2010.5699294,AXle® 2.0 and MVP-C: Open ATE software standards,"Open software standards AXIe®2.0 and MVP-C are introduced. The AXIe®2.0 software standard provides an interface mechanism to hardware by supplying inventory, parallel addressing (multi-site) and tester configuration services. The AXIe®2.0 is the software companion to the AXIe®l.l hardware standard. The MVP-C standard (Multisite Virtual Pin - C language) is a set of a comprehensive, multiple level instrument API standards, which provide enhancement of existing instrumentation software standards for high performance, ATE test systems. Together, the AXIe®2.0 and MVP-C standards, supply a consistent methodology for ATE vendors to use as a partial or complete solution. For ATE customers, the option of truly mixing vendors' solutions becomes a software reality, and with it, the potential for substantial cost savings. © 2010 IEEE.",,Proceedings - International Test Conference,2010-01-01,Conference Paper,"Spargo, Kenneth",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-84994158719,10.1161/CIRCIMAGING.115.005113,Basal Left Ventricular Dilatation and Reduced Contraction in Patients with Mitral Valve Prolapse Can Be Secondary to Annular Dilatation: Preoperative and Postoperative Speckle-Tracking Echocardiographic Study on Left Ventricle and Mitral Valve Annulus Interaction,"Background - Prominent mitral valve (MV) annular dilatation with only modest left ventricular (LV) dilatation in patients with MV prolapse (MVP) suggests predominant dilatation in adjacent basal LV, which may augment regional wall tension and attenuate contraction by Laplace's law. We hypothesized that MV annular dilatation in patients with MVP is associated with the basal predominance of LV dilatation and attenuated contraction, which can be altered by surgical MV plasty with annulus reduction. Methods and Results - Echocardiography with speckle-tracking analysis to assess regional cross-sectional short-axis area and longitudinal contraction (strain) of basal, middle, and apical LV was performed in 30 controls and 130 patients with MVP. The basal value/averaged middle and apical values (B/M·A ratio) of LV cross-sectional area and strain were obtained. Patients with MVP showed significantly greater MV annular area (6.4±1.6 versus 3.7±0.6 cm 2 /m 2), increased B/M·A LV area ratio (2.4±0.5 versus 1.8±0.2), and reduced B/M·A LV strain ratio (0.83±0.14 versus 0.96±0.09) than controls (P<0.001). Multivariable analyses identified that MV annular dilatation was independently associated with increased B/M·A LV area ratio (β=0.60, P<0.001), which was associated with reduced B/M·A LV strain ratio (β=-0.32, P<0.001). In 35 patients with MVP, B/M·A LV area and strain ratio significantly altered after surgical MV plasty with annulus reduction (2.5±0.5-1.8±0.3 and 0.73±0.10-0.89±0.17, P<0.001, respectively). Conclusions - In patients with MVP, MV annular dilatation was associated with the basal predominance of LV dilatation and reduced contraction, which can be altered by surgical MV plasty with annulus reduction, suggesting unfavorable influence from MV annular dilatation on basal LV.",dilatation | echocardiography | left ventricle | mitral valve | prolapse,Circulation: Cardiovascular Imaging,2016-10-01,Article,"Fukuda, Shota;Song, Jae Kwan;Mahara, Keitaro;Kuwaki, Hiroshi;Jang, Jeong Yoon;Takeuchi, Masaaki;Sun, Byung Joo;Kim, Yun Jeong;Miyamoto, Tetsu;Oginosawa, Yasushi;Sonoda, Shinjo;Eto, Masataka;Nishimura, Yosuke;Takanashi, Shuichiro;Levine, Robert A.;Otsuji, Yutaka",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-0032480067,10.1016/S0920-3796(98)00249-X,Benchmark experiment on void effects in a bulk shield assembly and investigation on the predictive ability of these effects by transport calculations,"A benchmark experiment on void effects in a bulk shield assembly made of type 316 stainless steel was carried out, and prediction capabilities of these void effects using three transport calculation codes, i.e. DOT, MCNP and MVP was investigated. It is found that continuous energy Monte Carlo calculations with MCNP and MVP predict almost perfectly the void effects. Multi-group SN calculations by DOT may contain uncertainties in the prediction of the void effects when the self-shielding correction from the cross section is disregarded. The use of less angular quadratures such as S8 is also a cause of uncertainties due to the ray-effect radiated from the secondary source point at the beginning of the void space appearing. © 1998 Elsevier Science S.A. All rights reserved.",,Fusion Engineering and Design,1998-09-03,Article,"Maekawa, Fujio;Konno, Chikara;Ikeda, Yujiro;Oyama, Yukio;Uno, Yoshitomo;Maekawa, Hiroshi",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-85036462505,,Benchmark study on realized random packing model for coated fuel particles of HTTR using MCNP6,"The Coated Fuel Particle plays an important role in the excellent safety feature of the High Temperature Gascooled Reactor. However, the random distribution of CFPs also makes the simulation of HTGR fuel become more complicated. The Monte Carlo N-particle (MCNP) code is one of the most well-known codes for validation of nuclear systems; unfortunately, it does not provide an appropriate function to model a statistical geometry explicitly. In order to deal with the stochastic media, a utility program for the random model, namely Realized Random Packing (RRP), has been developed particularly for High Temperature engineering Test Reactor (HTTR). This utility program creates a number of random points in an annular geometry. Then, these random points will be used as the center coordinate of CFPs in the MCNP6 input file and therefore the actual random arrangement of CFPs can be simulated explicitly. First, a pin-cell calculation was carried out to validate the RRP by comparing with Statistical Geometry (STG) model of MVP code. After that, the comparison between the RRP model (MCNP) and STG model (MVP) was shown in whole core criticality calculation, not only for the annular core but also for the fully-loaded core. The comparison of numerical results showed that the RRP model and STG model differed insignificantly in the multiplication factor as expected, regardless of the pin-cell or whole core calculations. In addition, the RRP model did not make the calculation time increase a lot in comparison with the conventional regular model (uniform arrangement).",Coated Fuel Particle | HTTR | MCNP6 | MVP | Realized Random Packing | Stochastic arrangement,"2017 International Congress on Advances in Nuclear Power Plants, ICAPP 2017 - A New Paradigm in Nuclear Power Safety, Proceedings",2017-01-01,Conference Paper,"Quan, H. H.;Morita, K.;Honda, Y.;Fujimoto, N.;Takada, S.",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-85088045631,10.1007/978-3-030-35983-6_20,Brazilian startups and the current software engineering challenges: The case of tecnopuc,"Brazil is consolidating itself in the world of software startups, both by the strength of the market and by the innovation ecosystems that help these new companies to start and grow. In this chapter, we present the technical challenges that these software startups encounter. We share our experience at Tecnopuc, one specific STP located in the south of Brazil, with more than 170 organizations, from which 90 are startups. We present a set of technical challenges that relate to the following steps in developing an MVP: requirements engineering, product prototyping, architectural design, and software testing. Based on the analysis of these challenges, we reflect on how innovation ecosystems such as science and technology parks (STP) could help startups on addressing the challenges identified.",Brazil | Innovation ecosystem | Science and technology park | Software development | Software engineering | Software startups | Tecnopuc,Fundamentals of Software Startups: Essential Engineering and Business Aspects,2020-02-28,Book Chapter,"Pompermaier, Leandro;Prikladnicki, Rafael",Include,Yes
10.1016/j.infsof.2022.107144,2-s2.0-85092531895,10.2196/16355,"Building a digital tool for the adoption of the world health organization's antenatal care recommendations: Methodological intersection of evidence, clinical logic, and digital technology","Background: One of the key mandates of the World Health Organization (WHO) is to develop guidelines, defined as ""a document containing recommendations for clinical practice or public health policy.""Guidelines represent the global standard for information sources shaping clinical practice and public health policies. Despite the rigorous development process and the value of guidelines for setting standards, implementing such standards within local contexts and at the point of care is a well-documented challenge. Digital technologies enable agile information management and may facilitate the adaptation of guidelines to diverse settings of health services delivery. Objective: The objective of this paper is to detail the systematic and iterative process involved in transforming the WHO Antenatal Care (ANC) guidelines into a digital decision-support and patient-record application for routine use in primary health care settings, known as the WHO digital ANC module. Methods: The WHO convened a team of clinical and digital health experts to develop the WHO digital ANC module as a tool to assist health care professionals in the implementation of WHO evidence-based recommendations for pregnant women. The WHO digital ANC module's creation included the following steps: defining a minimum viable product (MVP), developing clinical workflows and algorithms, algorithm testing, developing a data dictionary, and the creation of a user interface or application development. The overall process of development took approximately 1 year to reach a stable prototype and to finalize the underlying content requirements of the data dictionary and decision support algorithms. Results: The first output is a reference software reflecting the generic WHO ANC guideline content, known as the WHO digital ANC module. Within it, all actionable ANC recommendations have related data fields and algorithms to confirm whether the associated task was performed. WHO recommendations that are not carried out by the health care worker are saved as pending tasks on a woman's health record, and those that are adequately fulfilled trigger messages with positive reinforcement. The second output consists of the structured documentation of the different components which contributed to the development of the WHO digital ANC module, such as the data dictionary and clinical decision support workflows. Conclusions: This is a novel approach to facilitate the adoption and adaptation of recommendations through digital systems at the health service delivery level. It is expected that the WHO digital ANC module will support the implementation of evidence-based practices and provide information for monitoring and surveillance; however, further evidence is needed to understand how the WHO digital ANC module impacts the implementation of WHO recommendations. Further, the module's implementation will inform the WHO's ongoing efforts to create a pathway to adaptive and integrated (Smart) Guidelines in Digital Systems to improve health system quality, coverage, and accountability.",Antenatal care | Clinical decision support | Digital health | Evidence-based | Implementation | Requirements gathering | WHO guidelines,Journal of Medical Internet Research,2020-10-01,Article,"Haddad, Samira M.;Souza, Renato T.;Cecatti, Jose Guilherme;Barreix, Maria;Tamrat, Tigest;Footitt, Carolyn;Mehl, Garrett L.;Syah, Inraini F.;Shankar, Anuraj H.;Tunçalp, Özge",Include,Yes
10.1016/j.infsof.2022.107144,2-s2.0-84937391663,10.1145/2593812.2593816,Building blocks for continuous experimentation,"Development of software-intensive products and services increasingly occurs by continuously deploying product or service increments, such as new features and enhancements, to customers. Product and service developers need to continuously find out what customers want by direct customer feedback and observation of usage behaviour, rather than indirectly through up-front business analyses. This paper examines the preconditions for setting up an experimentation system for continuous customer experiments. It describes the building blocks required for such a system. An initial model for continuous experimentation is analytically derived from prior work. The model is then matched against empirical case study findings from a startup company and adjusted. Building blocks for a continuous experimentation system and infrastructure are presented. A suitable experimentation system requires at least the ability to release minimum viable products or features with suitable instrumentation, design and manage experiment plans, link experiment results with a product roadmap, and manage a flexible business strategy. The main challenges are proper and rapid design of experiments, advanced instrumentation of software to collect, analyse, and store relevant data, and the integration of experiment results in both the product development cycle and the software development process.",Agile Software Development | Architecture | Continuous Experimentation | Lean Software Development | Lean Startup | Product Development,"1st International Workshop on Rapid Continuous Software Engineering, RCoSE 2014 - Proceedings",2014-06-03,Conference Paper,"Fagerholm, Fabian;Guinea, Alejandro Sanchez;Mäenpää, Hanna;Münch, Jürgen",Exclude,EC1
10.1016/j.infsof.2022.107144,2-s2.0-0032664206,10.1016/S0022-3115(99)00085-9,Burnup analysis of rock-like oxide fuel disks irradiated in the Japan Research Reactor No. 3,"Burnup analysis of rock-like oxide (ROX) fuel disks has been carried out and the results have been compared with measured values. Two kinds of ROX disks: zirconia and thoria, were fabricated and irradiated in an irradiation hole of the Japan Research Reactor No. 3 (JRR-3). After irradiation, several post-irradiation examinations (PIE) were performed. Computer codes used for the calculations were the SRAC and the MVP-BURN codes. Firstly, the neutron spectrum in the irradiation hole was calculated using the SRAC code system. Fixed source problems were solved to obtain the neutron spectra and effective cross-sections of the disks and burnup calculations were performed. The calculated results of burnup, isotopic abundance of plutonium and production of americium and curium were compared with measurement values. Calculations overestimate the measured burnup by 7 to approximately 15% and both codes largely underestimate the measured production of americium and curium isotopes. The calculated plutonium abundance agrees moderately well with the measured values.",,Journal of Nuclear Materials,1999-08-02,Article,"Nakano, Y.;Akie, H.;Magara, M.;Takano, H.",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-85087951852,10.1080/00295639.2020.1775433,Burnup Performance of CANDLE Burning Reactor Using Sodium Coolant,"The CANDLE (Constant Axial shape of Neutron flux, nuclide densities and power shape During Life of Energy production) reactor concept was proposed to overcome the disadvantages of current reactor technologies. In this study, a Monte Carlo–based procedure is developed for quantitative comparison of burnup performance and neutronic characteristics between lead bismuth eutectic (LBE)–cooled and sodium-cooled CANDLE reactors to demonstrate the possibility of using sodium coolant in a small CANDLE burning reactor. In this procedure, a neutron transport equation is solved using the MVP code with the JENDL-4.0 library, and the burnup calculation is solved using the MVP-BURN code with the detailed burnup chain. To simulate the fuel-shuffling process, an auxiliary code was developed using Python. The results show that for the same fuel pin design and core volume, changing the coolant from LBE to sodium reduced the keff by 2.3% and the average discharge burnup by 15.6%, due to the softer neutron spectrum and larger neutron leakage fraction. It would be necessary to increase the fuel volume and core radius approximately 38% and 17%, respectively, for criticality in a sodium-cooled CANDLE core.","CANDLE | MVP | MVP-BURN, sodium",Nuclear Science and Engineering,2020-01-01,Article,"Nguyen, Hoang Hai;Nishiyama, Jun;Obara, Toru",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-85054193933,10.1063/1.5054462,"Calculation of 134Cs, 137Cs, and 154Eu activity as the high temperature engineering test reactor (HTTR) burn-up parameter using Monte Carlo vector processor (MVP)","Simulation of HTTR fuel rod burn-up has been performed using MVP-BURN software. The purpose of this study was to determine the activities of 134Cs, 137Cs, 154Eu and also the ratio of 134Cs/137Cs, 154Eu/137Cs and its trend. The core of HTTR was modeled as a prismatic block fuel consists of 6% enriched UO2 coated with TRISO. Graphite was used for the moderator and reflector material. Reactor thermal power was set constantly at 30 MW. Burn-up calculation was performed from 1,000 MWd/t to 35,000 MWd/t and divided into 8 burn-up steps. The activity of 134Cs, 137Cs, and 154Eu obtained from this simulation was (5.871 ± 0.012)×1014 Bq, (7.319 ± 0.014)×1014 Bq, and (1.8242 ± 0.0036)×1013 Bq, respectively and the ratio of 134Cs/137Cs and 154Eu/137Cs was (0.8022 ± 0.0016) and (0.024924 ± 0.000049) respectively. The trending of 134Cs and 154Eu was observed as a quadratic function towards the burn-up. We also observed that the linearity trending occurred in 137Cs as well as an the ratio of 134Cs/137Cs and 154Eu/137Cs. As conclusion, these nuclides can be used as a burn-up parameter.",,AIP Conference Proceedings,2018-09-21,Conference Paper,"Inayah, S. N.;Suharyana, ;Riyatun, R.;Khakim, A.",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-47949109335,10.1108/03321640810878199,Characteristics investigation of a new type AFPM machine according to the geometric structure of rotor using 3D FEM,"Purpose - The purpose of this paper is to present the performance characteristics analysis of a new type axial flux permanent magnet (AFPM) machine according to the geometric structure of rotor such as permanent magnet dimension, the air-gap length and so on. Design/methodology/approach - The 3D finite element method (FEM) is used to analyse electromagnetic fields with the aid of an ANSYS software package. The FEM is based on the magnetic vector potential and the governing equation can be obtained from the Maxwell equation. Using the dynamometer system, the characteristics of the AFPM machine were estimated according to load torque. Findings - The AFPM machine characteristics with static torque, cogging torque and flux density according to rotor geometric dimensions are analyzed using a 3D FEM software package. And then, the prototype of an AFPM machine and several rotors with different PM structure are manufactured and tested. Resulting from the experiment, the characteristics such as EMF waveform, speed and efficiency curves according to load torque, and efficiency curves according to PM thickness, are obtained. The measured performance results verified the overhang effects and improved the efficiency of the motor. Originality/value - The paper proposes a new type AFPM machine structure with T-shape teeth and laminated back yoke and two types of rotor with fan-shaped permanent magnets. It presents the results of characteristics of the proposed AFPM machine throughout the simulation and experiment. © Emerald Group Publishing Limited.",Electric machines | Finite element analysis | Magnetic devices,COMPEL - The International Journal for Computation and Mathematics in Electrical and Electronic Engineering,2008-07-30,Article,"Lee, Byung Jun;Kim, Byoung Kuk;Cho, Yun Hyun;Chun, Yon Do;Koo, Dae Hyun",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-85072687065,10.1152/physiolgenomics.00125.2018,Characterization of eqtls associated with androstenone by rna sequencing in porcine testis,"Characterization of genetic variants affecting genome-wide gene expression levels (expression quantitative trait loci or eQTLs) in pig testes may improve our understanding of genetic architecture of boar taint (an animal welfare trait) and helps in genome-assisted or genomic selection programs. The aims of this study were to identify eQTLs associated with androstenone, to find candidate eQTLs for low androstenone, and to validate the top eQTL by reverse transcriptase quantitative PCR (RT-qPCR). Gene expression profiles were obtained by RNA sequencing in testis from Danish cross-bred pigs and genotype data by 80K single nucleotide polymorphism panel. A total of 262 eQTLs [false discovery rate (FDR) < 0.05] were identified by using two software packages: Matrix eQTL and Krux eQTL. Of these, 149 cis-acting eQTLs were significantly associated with androstenone concentrations and gene expression (FDR < 0.05). The eQTLs were associated with several genes of boar taint relevance including CYP1A2, CYB5D1, and SPHK2. One eQTL gene, AMPH, was differentially expressed (FDR < 0.05) and affected by chicory. Five candidate eQTLs associated with low androstenone concentrations were discovered, including the top eQTL associated with CYP1A2. RT-qPCR confirmed target gene expression to be significantly (P < 0.05) different based on eQTL genotypes. Furthermore, eQTLs were enriched as QTLs for 15 boar taint related traits from the PigQTLdb. This is the first study to report eQTLs in testes of commercial crossbred pigs used in pork production and to reveal genetic architecture of boar taint. Potential applications include development of a DNA test and in advanced genomic selection models for boar taint.",Androstenone | Boar taint | Chicory | Expression quantitative trait loci | RNA-Seq,Physiological Genomics,2019-10-01,Article,"Drag, Markus H.;Kogelman, Lisette J.A.;Maribo, Hanne;Meinert, Lene;Thomsen, Preben D.;Kadarmideen, Haja N.",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-79959685033,,Chicken little and the iPad,"Ron Matejko, president of MVP Media, a digital publishing company, expects the bright future of the digital publishing industry, though he advises users to be patient. According to him, once publishers can offer larger audiences from their digital publications, the demand will increase. The key is selling reader engagement and the higher response rates to ads that digital publications have offered so far. Current software options are very limited and have yet to offer the full array of tools needed to create truly interactive publications that help publishers overcome the no-flash edict by Apple. The legacy publishers are finally coming around on the pricing issue with their recent adjustments and acceptance of Apple's subscription terms.",,Publishing Executive,2011-05-01,Short Survey,"Matejko, Ron",Exclude,EC4
10.1016/j.infsof.2022.107144,2-s2.0-0027744135,,Chromatin texture features in hematoxylin and eosin-stained prostate tissue,"A pilot study was undertaken to determine the expression of certain nuclear features in prostatic lesions. Twenty cases, 5 of hyperplasia and 5 each of carcinoma, Mostofi grades I-III, were selected as a training set, and an additional 20 cases were used as a test set, including 5 cases of hyperplasia and 5 cases each in Mostofi grades I-III. Images of hematoxylin and eosin-stained, 4-μm paraffin sections were obtained with a JVC BY-110 three-color camera and digitized by an IBM personal computer with a Matrox MVP-AT/NP imaging board. Thirty nuclei for each case from the training set, for a total of 600 nuclei, and 10 nuclei for each case from the test set, for a total of 200 nuclei, were analyzed by quantitative cytometric software on a SUN 3/60 workstation. A linear discriminant model was used for statistical analysis. One hundred percent of the hyperplasia group, 98% of the low grade group, 92% of the medium grade group and 82% of the high grade group were classified correctly in the test set with an overall success rate of 93%. Statistically significant chromatin texture features included heterogeneity, condensation, margination, run length nonuniformity, long run emphasis, gray level nonuniformity and inertia. Area, roundness and staining intensity (total extinction) were also significant. The results with standard hematoxylin and eosin-stained tissue sections were similar to those previously obtained with Feulgen-stained material. These results indicate that routine hematoxylin and eosin-stained material offers consistent diagnostic clues.",,Analytical and Quantitative Cytology and Histology,1993-12-01,Article,"Christen, R.;Xiao, J.;Minimo, C.;Gibbons, G.;Fitzpatrick, B. T.;Galera-Davidson, H.;Bartels, P. H.;Bibbo, M.",Include,IC1
10.1016/j.infsof.2022.107144,,,Clinical analysis of on-pimp mitral valve repair combined with off-pump coronary artery bypass graft surgery: 32 cases report [非 体 外 循 环 下 冠 状 动 脉 旁 路 移 植 术 同 期 行 体 外 循 环 下 二 尖瓣成形术：32例临床报告],,,Medical Journal of Chinese People's Liberation Army,,Article,,Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-84930450192,10.17660/ActaHortic.2015.1078.25,Colchicine treatment: A method for genetic diversity induction of doritis pulcherrima Lindl. Orchid of Thailand,"Doritis pulcherrima Lindl. is one of the orchid species in Asia, including Thailand. Natural diploid and tetraploid Doritis pulcherrima, 17 clones, were used in this research. The diploid MVP 12 clone was selected to culture with aseptic technique for protocorm producing. Protocorms derived from this clone were used to induce tetraploid orchid plants. Polyploidization was induced via 2 month aged protocorms with various colchicine treatments. The suitable treatment was 100 mg/ L of colchicine for 10 days. The survival rate of protocorms and plantlets were 39.2 and 67.0%, respectively. The 25% of induced plantlets were observed as tetraploid by somatic chromosome counting. The five tetraploid plantlets were selected. They were 4N1, 4N'1, 4N'2, 4N2 and 4N3. Most morphological characteristics of plantlets were significant, except stem diameter, leaf number, root diameter, lateral sepal length, and lip length. The genetic relationship among Doritis pulcherrima plants were performed with Amplified Fragment Length Polymorphism (AFLP) fingerprinting, DNA bands were observed as raw data. Phylogenetic tree was constructed using NTSYSpc 2.1 software. Results showed closely genetic diversity of this orchid species and all tetraploid induction plants were very close to the diploid mother plant, except for the 4N3 tetraploid induction plant. This interesting observation was due to mutation during polyploidization, so the colchicine treatment was a technique to make wider genetic diversity for this orchid species.",AFLP | Colchicine treatment | Doritis pulcherrima | Genetic diversity | Orchid | Polyploidization,Acta Horticulturae,2015-03-27,Conference Paper,"Rungruchkanont, K.;Apisitwanich, S.",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-85072806508,10.1109/CHASE.2019.00014,Collaborative practices for software requirements gathering in software startups,"Capturing requirements during the software development process has always been a challenge. Usually, there is a customer with a defined problem or a problem to be explored. However, when we talk about software startups, the requirements gathering process changes. The entrepreneurs need to systematically work with hypotheses and experimentations, and test them as quickly as possible, trying to understand whether these assumptions can become requirements for a system or not. In this context, entrepreneurship training programs, specially for technical students, help these entrepreneurs to understand this new way of gathering systems requirements. This paper describes how some of these practices were performed in a program for new entrepreneurs that took place in a science and technology park. Our preliminary results indicate that several collaborative practices can foster the understanding of the software requirement process for software startups.",Collaboration | MVP | Software Requirements | Software Startups,"Proceedings - 2019 IEEE/ACM 12th International Workshop on Cooperative and Human Aspects of Software Engineering, CHASE 2019",2019-05-01,Conference Paper,"Chanin, Rafael;Pompermaier, Leandro;Sales, Afonso;Prikladnicki, Rafael",Include,Yes
10.1016/j.infsof.2022.107144,2-s2.0-85026877453,10.1109/SoftStart.2017.5,Collaborative-Startup (Co-Startup): The Role of Communities of Practices,"Today, technology is enabling change in most of our lives. Also, crucial for most of these changes, are software startups whose contributions have led to the creation of a global market, jobs, and some help in fighting the 'brain drain' pertaining in most developing countries. However, there is not enough academic literature to guide practitioners on how to leverage the collaborative potentials of startups to arrival at a faster and sustainable Minimum Viable Product (MVP). By reviewing literature, and using Communities of Practice theory (COP), we propose a conceptual model known as Co-Startup, as part of this position paper to guide practitioners to achieve a sustainable MVP faster, to stimulate innovation in the private sector, and arouse further academic research in this budding phenomenon.",Co-Startup | Collaborative MVP | Collaborative startup | Communities of practice | MVP | Software startup,"Proceedings - 2017 IEEE/ACM 1st International Workshop on Software Engineering for Startups, SoftStart 2017",2017-06-30,Conference Paper,"Agyavo, Nana",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-77958020446,10.1109/ESIAT.2010.5567323,Comparative analysis of WebForms MVC and MVP architecture,"Introduced WebForms, MVC and MVP architecture works under the NET platform,,the characteristics of the three structures were analyzed and compared, especially described WebForms's ViewState, the performance and client ID pollution problems and give solutions; combing their respective advantages, noted suitable scenarios of three kinds framework, aiming to supply reference for developing Web system. ©2010 IEEE.",ASP.NET | MVC | MVP | Software architecture | Web system,"2010 2nd Conference on Environmental Science and Information Application Technology, ESIAT 2010",2010-10-22,Conference Paper,"Gu, Ming Xia;Tang, Keming",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-85066147963,,COMPASS 1992 - Proceedings of the 7th Annual Conference on Computer Assurance,The proceedings contain 11 papers. The topics discussed include: a case study in process representation using MVP-L; an analysis of selected software safety standards; a review of computer controlled systems safety and quality assurance concerns for acquisition managers; software safety and economics; the use of Ada PDL as the basis for validating a system specified by control flow logic; efficient response time bound analysis of real-time rule-based systems; a formal approach for security evaluation; a probabilistic approach to assurance of database design; modular verification of Ada library units; verification of numerical programs using Penelope/Ariel; and using Z specifications in category partition testing.,,COMPASS 1992 - Proceedings of the 7th Annual Conference on Computer Assurance,1992-01-01,Conference Review,,Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-85050543423,,Conducting anomalies localization with local and regional real induction vectors,"Real induction vectors are a powerful tool for determining the location in plan and in the depth of single conducting objects, including the determination of the basic parameters of anomalous objects. However, the picture in the vectors behavior becomes not so unambiguous, if several such objects are marked on the exploration area. The authors have created a software tool that makes it possible to divide the field of induction vectors into local and regional parts. The work of the program has been verified on numerous model data, as well as on data of practical MT and MVP surveys of various scales. Thus, the interpreter has another effective tool for extracting information from the obtained during the field survey MVP data.",,Engineering and Mining Geophysics 2018 - 14th Conference and Exhibition,2018-01-01,Conference Paper,"Lozovij, A.;Mendrii, I.;Ingerov, I.",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-0033896664,,Consortium for promoting the use of mediaprocessors in multimedia applications,"Mediaprocessors, such as Philips Trimedia and Hitachi/Equator Technologies MAP, combine the computational power of high-end DSPs with various I/O capabilities in a single programmable chip. Due to their programmability, mediaprocessors have greater flexibility than ASICs and other special-purpose hardware. Early mediaprocessors, such as Texas Instruments TMS320C80 (MVP) since its introduction in 1994, have had limited success due to their difficulty in programming, insufficient computational power, and high cost. Fortunately, several newer mediaprocessors, which are available or under development, are easier to program, are less expensive, and/or have more computational power. However, due to the earlier difficulties and inherent uncertainties in the programmable solutions, mediaprocessor user companies (set makers) are often hesitant in adopting the mediaprocessors in their products. Furthermore, set makers still need to expend a lot of time and manpower in making a successful transition from hardwired to mediaprocessor-based products. Therefore, we introduce the Mediaprocessor (MP) Consortium, which aims to remove the barrier to the widespread use of programmable mediaprocessors. Through publications, web site, training courses, software libraries, and objective evaluations of mediaprocessors, the MP Consortium can increase the awareness of the benefits of mediaprocessors over ASICs, make the transition to mediaprocessor-based products easier for set makers, and help them attain full advantage of using mediaprocessors.",,Proceedings of SPIE - The International Society for Optical Engineering,2000-01-01,Conference Paper,"Grow, Michael;Kim, Donglok;Kim, Woong Joe;Park, Hyun Wook;Kim, Yongmin",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-84956991748,10.1007/978-1-4842-1272-1,Continuous delivery with visual studio ALM 2015,"This book is the authoritative source on implementing Continuous Delivery practices using Microsoft's Visual Studio and TFS 2015. Microsoft MVP authors Mathias Olausson and Jakob Ehn translate the theory behind thismethodology and show step by step how to implement Continuous Delivery in a real world environment. Building good software is challenging. Building high-quality software on a tight schedule can be close to impossible. Continuous Delivery is an agile and iterative technique that enables developers to deliver solid, working software in every iteration. Continuous delivery practices help IT organizations reduce risk and potentially become as nimble, agile, and innovative as startups. In this book, you'll learn: • What Continuous Delivery is and how to use it to create better software more efficiently using Visual Studio 2015 • How to use Team Foundation Server 2015 and Visual Studio Online to plan, design, and implement powerful and reliable deployment pipelines • Detailed step-by-step instructions for implementing Continuous Delivery on a real project",,Continuous Delivery with Visual Studio ALM 2015,2015-01-01,Book,"Olausson, Mathias;Ehn, Jakob",Exclude,EC4
10.1016/j.infsof.2022.107144,2-s2.0-85097156576,10.1145/3368089.3417039,Continuous experimentation on artificial intelligence software: A research agenda,"Moving from experiments to industrial level AI software development requires a shift from understanding AI/ ML model attributes as a standalone experiment to know-how integrating and operating AI models in a large-scale software system. It is a growing demand for adopting state-of-the-art software engineering paradigms into AI development, so that the development efforts can be aligned with business strategies in a lean and fast-paced manner. We describe AI development as an ""unknown unknown""problem where both business needs and AI models evolve over time. We describe a holistic view of an iterative, continuous approach to develop industrial AI software basing on business goals, requirements and Minimum Viable Products. From this, five areas of challenges are presented with the focus on experimentation. In the end, we propose a research agenda with seven questions for future studies.",AI software | AI system | Continuous Experimentation | Industrial Artificial Intelligence,ESEC/FSE 2020 - Proceedings of the 28th ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering,2020-11-08,Conference Paper,"Nguyen-Duc, Anh;Abrahamsson, Pekka",Exclude,EC1
10.1016/j.infsof.2022.107144,2-s2.0-85056516391,10.1109/TEMSCON.2018.8488399,Continuous Innovation Through Experimentation,"This paper describes an approach used to implement innovation management within an organization. The foundation of this effort centers on continuous innovation beginning with experimentation. Experimentation can be an effective means to generate and foster innovation in organizations where it is not a core competency or widely accepted. Establishing and driving innovation in organizations steeped in the traditional can be very difficult and you will face challenges in many areas, including, culture, structure, process, and resources. This paper will outline how leading with experimentation can help establish and grow an innovation culture within your organization.",Culture | Design Thinking | Experimentation | Innovation | Minimum Viable Product | Processes | Proof of Concept | Prototyping | Resources | Strategy | Structure | Variation,"2018 IEEE Technology and Engineering Management Conference, TEMSCON 2018",2018-10-09,Conference Paper,"Amirat, Cherif;Reeps, Richard",Exclude,EC2
10.1016/j.infsof.2022.107144,2-s2.0-84989851801,10.3389/fninf.2016.00027,CoSMoMVPA: Multi-modal multivariate pattern analysis of neuroimaging data in matlab/GNU octave,"Recent years have seen an increase in the popularity of multivariate pattern (MVP) analysis of functional magnetic resonance (fMRI) data, and, to a much lesser extent, magneto- and electro-encephalography (M/EEG) data. We present CoSMoMVPA, a lightweight MVPA (MVP analysis) toolbox implemented in the intersection of the Matlab and GNU Octave languages, that treats both fMRI and M/EEG data as first-class citizens. CoSMoMVPA supports all state-of-the-art MVP analysis techniques, including searchlight analyses, classification, correlations, representational similarity analysis, and the time generalization method. These can be used to address both data-driven and hypothesis-driven questions about neural organization and representations, both within and across: space, time, frequency bands, neuroimaging modalities, individuals, and species. It uses a uniform data representation of fMRI data in the volume or on the surface, and of M/EEG data at the sensor and source level. Through various external toolboxes, it directly supports reading and writing a variety of fMRI and M/EEG neuroimaging formats, and, where applicable, can convert between them. As a result, it can be integrated readily in existing pipelines and used with existing preprocessed datasets. CoSMoMVPA overloads the traditional volumetric searchlight concept to support neighborhoods for M/EEG and surface-based fMRI data, which supports localization of multivariate effects of interest across space, time, and frequency dimensions. CoSMoMVPA also provides a generalized approach to multiple comparison correction across these dimensions using Threshold-Free Cluster Enhancement with state-of-the-art clustering and permutation techniques. CoSMoMVPA is highly modular and uses abstractions to provide a uniform interface for a variety of MVP measures. Typical analyses require a few lines of code, making it accessible to beginner users. At the same time, expert programmers can easily extend its functionality. CoSMoMVPA comes with extensive documentation, including a variety of runnable demonstration scripts and analysis exercises (with example data and solutions). It uses best software engineering practices including version control, distributed development, an automated test suite, and continuous integration testing. It can be used with the proprietary Matlab and the free GNU Octave software, and it complies with open source distribution platforms such as NeuroDebian. CoSMoMVPA is Free/Open Source Software under the permissive MIT license. Website: http://cosmomvpa.org Sourcecode:https://github.com/CoSMoMVPA/CoSMoMVPA.",Cognitive neuroscience | Electroencephalography | Functional magnetic resonance imaging | Magnetoencephalography | Multi-variate pattern analysis | Open source | Software,Frontiers in Neuroinformatics,2016-07-22,Article,"Oosterhof, Nikolaas N.;Connolly, Andrew C.;Haxby, James V.",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-84951729029,10.1007/978-3-642-44930-7_9,Creating minimum viable products in industry-academia collaborations,"Customer value determines how products and services succeed in the marketplace. Early assessment of customer value is important for software startups, spin-off companies, and new product development in existing companies. Software technology often influences customer value and typically defines the main competitive advantage in both entrepreneurial and intrapreneurial settings. Value-related feedback from real customers is needed during software development and maintenance, and decision-making should be increasingly based on empirical evidence acquired through experiments. Getting such value-related feedback usually requires a so-called minimum viable product (MVP), i.e., an artefact that may be incomplete in functionality or quality, but displays characteristics that allows determining its customer value. In this article we report on a case study which used industry-academia collaboration for creating such an MVP. Our goal was to identify strengths and weaknesses of such an approach to creating MVPs while providing practical recommendations for improvement. The process followed in the case study was found to be very suitable for creating MVPs, reducing company-specific risks when testing customer-value, and advancing university education.",Case study | Entrepreneurship | Intrapreneurship | Lean startup | Minimum viable product | Prototyping | Software factory | Software start-ups,Lecture Notes in Business Information Processing,2013-01-01,Conference Paper,"Münch, Jürgen;Fagerholm, Fabian;Johnson, Patrik;Pirttilahti, Janne;Torkkel, Juha;Järvinen, Janne",Include,Yes
10.1016/j.infsof.2022.107144,2-s2.0-85097535720,10.1109/UYMS50627.2020.9247050,Delivering Machine Learning Applications via Cloud Platforms: An Experience Report,"Cloud technologies enable developers and organizations to focus on their product, without having to consider issues such as local server capacity, infrastructure modifications, data security, licensing or human capital. This paper attempts to explain a case in which a Machine Learning application is deployed via Amazon Web Services (AWS) tools. In doing so, it demonstrates the reasoning behind choosing a cloud-based environment instead of on-premise sources, by putting forward the advantages of the former. On the other hand, it should be noted that the application in this experience is generated with a hybrid approach: It is developed using on-premise infrastructure and then moved to the Cloud environment for the deployment phase only. In this regard, it can be read as a PaaS experience. This study is considered to be a beneficial guide for entrepreneurs and start-ups on a budget who aim at launching their products in a swift and scalable manner.",agility | cloud computing | entrepreneurship | machine learning | MVP (Minimum Viable Product) | PaaS | productization,"2020 Turkish National Software Engineering Symposium, UYMS 2020 - Proceedings",2020-10-07,Conference Paper,"Sener, Yigit;Yetim, Hasan Fahri;Bagriyanik, Selami",Exclude,EC1
10.1016/j.infsof.2022.107144,2-s2.0-84864059889,10.1109/PCS.2012.6213280,Depth-based motion vector prediction in 3D video coding,"There are several data formats available for 3D video, among which is the Multiview Video plus Depth (MVD) representation that enables depth-image-based rendering (DIBR). In addition to DIBR, the MVD data format can enable more efficient compression for texture video coding. In this paper, we propose advanced motion vector prediction (MVP) techniques which utilize the availability of depth information in the MVD format for more efficient coding of the corresponding texture pictures. The proposed MVP was implemented on top of the Multiview Video Coding (MVC) extension of the Advanced Video Coding (H.264/AVC) standard and its reference software and tested under the simulation conditions of the Call for Proposals of 3D video coding technology issued by the Moving Picture Experts Group (MPEG). In the provided simulation results the proposed scheme significantly outperformed the conventional MVP (by up to 9.9% and on average by 7.5% in Bjontegaard delta bitrate) when it was applied for coding of 3-view MVD data. © 2012 IEEE.",3DV | motion vector prediction | MVC | MVD,"2012 Picture Coding Symposium, PCS 2012, Proceedings",2012-07-25,Conference Paper,"Su, Wenyi;Rusanovskyy, Dmytro;Hannuksela, Miska M.;Li, Houqiang",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-85039897285,10.1109/ICCSNT.2016.8069371,Design and implementation of a second-hand items trading platform based on Android,"With the continuous improvement of 4G communication technologies and the popularity of smart mobile devices, the mobile Internet quickly involves into the people's life and work, and more and more users are accustomed to using mobile phones, tablet PCs and other mobile devices for shopping and consumption. But these goods purchased online will result in the problem of idle items at home. Therefore, in order to achieve convenient, fast transaction of second-hand items, a second-hand items electronic trading platform based on the Android platform was developed in the paper. In the process of constructing the platform, functional requirements of the system were analyzed. The MVP architectural pattern was utilized to design the system structure, and finally the software of second-hand items trading platform was implemented. The system has the characteristics of better maintainability and oriented programming interface.",Android | Mobile | MVP | Second-hand Items trading platform,"Proceedings of 2016 5th International Conference on Computer Science and Network Technology, ICCSNT 2016",2017-10-16,Conference Paper,"Huo, Jiuyuan;Qu, Hong",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-85063634594,10.1109/ICSESS.2018.8663776,Design and Implementation of the Lost-and-Found System Based on Amap API,"The lost-and-found information management system, as an important part of the social public service system, has its special significance. With the change of traditional lost-and-found pattern, the process of lost-and-found has fallen into the dilemma of 'people looking for things, things for people' and the proportion of lost property retrieve is less than 10%. The rapid development of location service, 4G communication technology and intelligent terminal has provided a new way to establish a lost-and-found information service system with GIS functions, which effectively solved the problem of 'where' in the process of lost-and-found. By the integration of Android system and interface technology, focusing on the actual needs, technical architecture, functional architecture and database structure of the system have been designed. Using the C/S architecture and MVP development model, the lost-and-found system based on Amap API have been implemented subsequently. Whereafter, the functional test and performance test were carried out. Through testing and using, each module of the system achieves the desired design effect. The client takes only 12.75ms<16ms to load a frame image and the system is fluent and stable. By means of location service and spatial analysis methods, users enable to release, browse, search and share lost-and-found information conveniently. The organic integration of location service and lost-and-found models has made the process of lost property retrieve more efficient and faster.",Amap | lost-and-found | mobile GIS | spatial search | The back-end cloud platform,"Proceedings of the IEEE International Conference on Software Engineering and Service Sciences, ICSESS",2018-07-02,Conference Paper,"Zhao, Hang;Peng, Shuangyun",Exclude,EC1
10.1016/j.infsof.2022.107144,2-s2.0-79960328378,10.1109/TNSRE.2011.2164937,Design and performance of a multichannel vestibular prosthesis that restores semicircular canal sensation in rhesus monkey,"In normal individuals, the vestibular labyrinths sense head movement and mediate reflexes that maintain stable gaze and posture. Bilateral loss of vestibular sensation causes chronic disequilibrium, oscillopsia, and postural instability. We describe a new multichannel vestibular prosthesis (MVP) intended to restore modulation of vestibular nerve activity with head rotation. The device comprises motion sensors to measure rotation and gravitoinertial acceleration, a microcontroller to calculate pulse timing, and stimulator units that deliver constant-current pulses to microelectrodes implanted in the labyrinth. This new MVP incorporates many improvements over previous prototypes, including a 50% decrease in implant size, a 50% decrease in power consumption, a new microelectrode array design meant to simplify implantation and reliably achieve selective nerve-electrode coupling, multiple current sources conferring ability to simultaneously stimulate on multiple electrodes, and circuitry for in vivo measurement of electrode impedances. We demonstrate the performance of this device through in vitro bench-top characterization and in vivo physiological experiments with a rhesus macaque monkey. © 2011 IEEE.",Neural engineering | semicircular canal implant | sensory neural prosthesis,IEEE Transactions on Neural Systems and Rehabilitation Engineering,2011-10-01,Article,"Chiang, Bryce;Fridman, Gene Y.;Dai, Chenkai;Rahman, Mehdi A.;Della Santina, Charles C.",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-77952855127,10.1115/FEDSM2009-78103,Design of high-speed magnetic pump based on the numerical simulation,"The high-speed magnetic pump has the characteristic of zero leakage, small volume and high efficiency. In order to enhance the performance of high-speed magnetic pump and shorten the design period, the hydraulic components and magnetic coupling are designed on the basis of numerical simulation. The hydraulic components designed initially are applied by the design method of high-speed partial emission pump. The internal flow field of the pump is simulated with the FLUENT CFD software. The distributions of absolute velocity, relative velocity and total pressure of pump are gained. The inlet structure and geometry of the magnetic pump are modified based on the simulation results. The magnetic coupling is designed by using empirical factors. The magnetic field of the magnetic coupling is simulated with 2-D Magnetic Vector Potential (MVP) formula using the ANSYS software. The distributions of magnetic force line at origin, working situation and maximum magnetic rotating angle are obtained. The magnetic torque simulated value approaches the result calculated with the empirical formula. The test results of the improved magnetic pump show that the hydraulic performance and outline dimensions meet requirements. The method of design-simulation-improvement-test is successful. Copyright © 2009 by ASME.",High-speed magnetic pump | Magnetic coupling | Maximum magnetic torque | Simulation | Test,"Proceedings of the ASME Fluids Engineering Division Summer Conference 2009, FEDSM2009",2009-12-01,Conference Paper,"Kong, Fanyu;Wang, Zhiqiang;Gao, Cuilan;Zhang, Hongli",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-85074349115,10.1145/3355402.3355407,Design of modular learning analytics framework for early childhood education: A case study,"On the provision of early childhood education, education-oriented software for enabling parent and teacher collaboration becomes popular. However, by providing merely on the asynchronous communication support, this sort of software overlooks a feature allowing parents (or teachers) to trace their child’s physical development or learning progress. In this paper, it is argued that the missing feature is indeed necessary, and should be realized through the use of learning analytics technology. In this regard, a service-oriented design framework for rapid application development is suggested by a means of web mashup of open source software. Based on the minimum viable product, it is clearly the graph visualization of learning analytics can potentially empower parents on their early childhood education so that actions can be taken in time accordingly if necessary.",Early Childhood Education | Headless CMS | Learning Analytics | Service-Oriented Architectures,ACM International Conference Proceeding Series,2019-08-16,Conference Paper,"Rueangprathum, Atchara;Witosurapot, Suntorn",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-85093095782,10.1145/3372787.3390430,Developing a conversational agent with a globally distributed team: An experience report,"In this experience report, we discuss the development of a solution that enables conflict-affected youth to discover and access relevant learning content. A team of individuals from a not-for-profit, a large multi-national technology company, and an academic institution, collaborated to develop that solution as a conversational agent named Hakeem. We provide a brief motivation and product description before outlining our design and development process including forming a distributed virtual team, engaging in user-centred design with conflict-affected youth in Lebanon, and using a minimum viable product approach while adapting Scrum for distributed development. We end this report with a reflection on the lessons learned thus far.",chatbot | global software engineering | software development,"Proceedings - 2020 ACM/IEEE 15th International Conference on Global Software Engineering, ICGSE 2020",2020-06-26,Conference Paper,"Ruane, Elayne;Smith, Ross;Bean, Dan;Tjalve, Michael;Ventresque, Anthony",Include,Yes
10.1016/j.infsof.2022.107144,2-s2.0-85090822433,,Developing a high-speed connectionless file transfer system with wasm based client,"This paper describes an application named FFTM (Fast File Transfer Manager) that is based on Xinan Liu's Reliable File Transfer Protocol. The system consists of a server and a client program utilizing UDP connection. The aim is to transfer big files quickly by this program on busy network connections. We developed a Java-based minimum viable product relying on Xinan Liu's solution by adding control over chunk size. This article introduces the results of rewriting the modified software in C++ and the improvement of the client by a graphical user interface. Furthermore, we want to make this program available for as many platforms as we can. To achieve this goal we paid special attention to the WebAssembly programming language. Thanks to the generated WASM binary, our application can be used from a browser without installation.",Congestion control | High-performance computing | High-speed networking | Internet | Parallel communication | Scale independence | Statistical analysis | Traffic engineering,CEUR Workshop Proceedings,2020-01-01,Conference Paper,"Tornai, Robert;Kiss-Imre, Dalma;Fürjes-Benke, Péter;Gál, Zoltán",Exclude,EC1
10.1016/j.infsof.2022.107144,2-s2.0-0028510179,,Developing applications for TI's MVP,"The MVP is perhaps the world's most complex silicon device. This device is the first commercially-available single-chip multiprocessor to combine parallel DSP and RISC architectures. MVP offers unprecedented power to the DSP designer. Harnessing this power is considered to be an unprecedented challenge. To demonstrate this, an application of MVP is provided.",,Electronic Product Design,1994-09-01,Article,"Anon, ",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-84988884558,10.1007/978-981-10-2669-0_55,Development and credibility of multi-disciplinary virtual prototype,"The development of multi-disciplinary virtual prototype (MVP) is a system engineering which involves analysis, development, integration, testing and other activities. The credibility of MVP is important which decides whether or not the MVP could be applicable. The authors’ team has developed a software development kit for MVP named collaborative simulation (COSIM). Based on the research work, firstly, the development and execution process of MVP engineering is illustrated. Secondly, verification, validation and accreditation (VV&A) across the whole MVP development process is introduced, and the indicator system of credibility evaluation is proposed. Finally, an application of VV&A for landing gear virtual prototype is given as an example.",Credibility | Multi-disciplinary virtual prototype | VV&A,Communications in Computer and Information Science,2016-01-01,Conference Paper,"Qu, Huiyang;Shi, Guoqiang;Pu, Ruiying",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-85055473276,10.1007/s10209-018-0637-1,Development of an app for the dental care of Deaf people: Odontoseñas,"Background: Most Deaf people are often illiterate and communicate via sign language, hindering their dental care, causing high levels of oral morbidity and feelings of unfairness by the dental staff. Objective: To achieve effective communication between the dentist and the Deaf patient using an app. Materials and methods: Focus group were conducted by a team comprising dentists, Chilean Sign Language (ChSL) interpreters, Deaf people and a software programmer to identify the most prevalent and important phrases used during dental care. A Minimum Viable Product App including draft videos in SL were developed and evaluated by external teams through in-office simulations and surveys. Evaluation by Deaf people and dentists was carried out using the Dental Visit Satisfaction Scale and System Usability Scale, respectively. Improvements were made in each cycle, until reaching agreement for a final (release) version. Results: Thirteen ChSL videos were recorded and incorporated in the App Odontoseñas. The overall usability of the software scored 96 points over 100. The overall satisfaction of Deaf people without the software was 21, and with the software was 29 over 30. Conclusions: Odontoseñas gives relevant information about dental care, facilitating diagnosis, treatment and improving oral health care experience for the Deaf patient.",Dental care | Dental care for the disabled | Hearing loss | Mobile applications,Universal Access in the Information Society,2020-06-01,Article,"Campos, Valeria;Cartes-Velásquez, Ricardo;Bancalari, Carla",Include,Yes
10.1016/j.infsof.2022.107144,2-s2.0-85010540371,10.1109/ICISCT.2016.7777398,Development of multiple tracking system for smart VIP car placement and monitoring,"nowadays, vehicles have become a very significant role in transport which remain a major problem in most cities around the world, especially in developing regions resulting in massive delays, turn traffic congestion, increased fuel wastage and monetary losses. There are many alternative systems, but one possible solution to this problem is parking system has become the sparking factors of the mentioned problems above. In this paper, we present various techniques as far as the smart parking system is mainly debated which are already implemented. When we are deepening into this parking issue, many contributors contributed a lot in monitoring smart parking system (SPS) and management of SPS with an asset of various gadgets and technologies including Bluetooth, Cameras, Image Processing, wireless sensors, ZigBeee accompanied by software explanations based on mobile application. Following this analysis will enhance researcher's thought on SPS which will result in a real solution of the technique.",App | IP Camera | MVP | Retrofit | Tracking,"2016 International Conference on Information Science and Communications Technologies, ICISCT 2016",2016-12-07,Conference Paper,"Khajiev, Nizomjon;Lee, Chol U.;Kim, Kyung Sook;Kim, Seung Ho;Oh, Ryum Duck",Exclude,EC1
10.1016/j.infsof.2022.107144,2-s2.0-85095700942,,Digital transformation of well completion selection and design through data insights,"Well completion selection and design involve the selection of optimum well completion architecture and associated downhole equipment to deliver hydrocarbon to surface in a safe and efficient manner. A number of well architectures can be conceived for a given application, and a plethora of equipment is available across the industry, with hardware to meet a wide range of operating conditions including hole size, pressure, temperature, flow rate and fluid type. This wealth of choice results in a highly complex and challenging selection process that today is done manually, relying on subject matter experts and local best practices through trial and error approach. As a result, the process can be quite inefficient, designs can be suboptimal and fail to consider unique reservoir and well conditions leading to premature equipment failure causing loss of production and well integrity. These failures can have impact ranging from unplanned well intervention, equipment pull outs, fishing operations, extended rig time, workovers, or even complete well loss-costing the oil and gas industry billions of dollars. The shortcomings in design are therefore ripe for innovative digital solutions. This paper describes how manual completion selection process can be seamlessly transformed into an intuitive digital solution providing insights for the well completion selection process. The proposed digital solution describes software tools and architecture used to consolidate thousands of historic, unstructured, completion schematic data into a structured database. It automatically maps the completion architecture and equipment details to relevant operating environments, captures nonproductive time and highlights installation challenges. The solution also identifies correlations and data trends across various types of well designs and equipment categories, using advanced artificial intelligence and machine learning algorithms to provide insights into equipment reliability, operational efficiency, total cost of ownership and production performance. A minimum viable product consisting of 24,000 wells from across the world has been successfully developed to demonstrate key value propositions. New data coming in from recently completed wells can be seamlessly integrated with the existing data bases and the algorithms constantly improvise its learning process to provide better accuracy. The digital solution proposed for well completion selection and design process ultimately enables oil and gas companies to optimize well completion configurations and equipment that can deliver maximum value. It allows them to identify offset well issues, derisk operational concerns, check compatibility of equipment with respect to dimensional constraints, pressure and load rating requirements, thread configurations, metallurgy constraints, seal elements, complete well on digital file with tracing and accountability.",,Proceedings - SPE Annual Technical Conference and Exhibition,2020-01-01,Conference Paper,"Gottumukkala, Varma;Worthington, Matthew;Basak, Debasmita;Radhakrishnan, Renuka;Srinivasan, Jay;Ramesh, Smitha",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-46749093764,,Dobb's architecture & design world,"Dr. Dobb's Architecture & Design World will be conducting a four days of real-world training for software architects, developers, and modeling/design professionals at the Hyatt Regency McCormick Place in Chicago on July 21,2008. The program tracks will be focusing on service-oriented architecture/web services, solutions/technical architectures, roll-up-your-sleeves, agile development and methods, traditional development and methods, and modeling and design. The new SOA track offers SOA in Practice, that is a two-part tutorial by Nicolai Jossutis and Designing Service-Oriented Applications, by Mike Rosen. Agile development track features courses taught by Rober Martin, Chris Armstrong, Neal Ford, and James Hobart. Another featured speaker is Udi Dahan, a Microsoft Solutions Architect MVP and .NET expert who will teach classes such as Intentions & Interfaces: Making Patterns Concrete and Avoid a Failed SOA: Business & Autonomous Components to the Rescue.",,Dr. Dobb's Journal,2008-07-01,Article,"Ankerholz, Amber",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-85092607031,10.1007/978-3-030-58817-5_53,Does the Lean Inception Methodology Contribute to the Software Project Initiation Phase?,"This work aims to make a comparative analysis of the Lean Inception methodology and the Scrum methodology applied in the initiation phase of the embedded software project that consists of a small greenhouse for the indoor cultivation of sage, controlled by a cell phone application. The Lean Inception methodology is a combination of Lean Startup and Design Thinking that, at the end of the process, quickly obtains the Minimum Viable Product (MVP). Some of the questions explored in this paper were how much the Lean Inception methodology interferes in the agility of the production of MVP, how much it influences in the quality of the final product and depicting advantages in using this methodology in the project initiation phase.",Lean Inception | Minimum Viable Product | Project initiation | Scrum,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2020-01-01,Conference Paper,"Braga, Igor;Nogueira, Marcelo;Santos, Nuno;Machado, Ricardo J.",Include,Yes
10.1016/j.infsof.2022.107144,2-s2.0-0030388895,,DVFLEX: A flexible MPEG real time video CODEC,"The MPEG-2 video coding standard offers great latitude in implementation and covers a wide variety of applications. The DVFLEX video encoder allows taking advantage of this flexibility by making the whole coding loop, including the bitstream generation, software programmable. The DVFLEX architecture is basically an array of linearly-connected processing modules. These modules are based on the MVP (TMS320C80) and include dedicated I/O ports for video, bitstream and inter-processor communications. All these I/O ports allow the processing to be performed in parallel with I/Os. The processing workload is distributed among these modules on an image region per processor basis. As for the on-chip MVP processors, tasks assignment is much more constrained because of the bitstream handling problems. Although suboptimal, the solution we describe is simple and gives satisfactory results. However, the on-chip to off-chip memory I/Os have to be carefully handled so as to keep the processors busy.",,IEEE International Conference on Image Processing,1996-12-01,Conference Paper,"Bouville, C.;Houlier, P.;Dubois, J. L.;Marchal, I.;Thebault, B.;Klefstad, M.",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-0032255525,10.1006/rtim.1998.7010,Efficient implementation of image warping on a multimedia processor,"The spatial transformation of images, commonly known as image warping, is fundamental to many applications, e.g. remote sensing, medical imaging, computer vision, and computer graphics. Computational demands in image warping are high, requiring a geometric transformation, address and coefficient generation, and some form of interpolation. However, unlike most image processing algorithms, the data flow for image warping can be highly irregular, which makes any efficient implementation challenging. This paper describes an efficient algorithm which addresses these challenges by making use of the capabilities of a single-chip multiprocessing microprocessor, the Texas Instruments TMS320C80 MVP (multimedia video processor). The M VP s advanced digital signal processors (ADSPs) off er tremendous computational power through instruction-level parallelism and several key features designed for image processing. The MVP's intelligent input/output interface via the transfer controller (TC) permits efficient irregular memory axesses. Affine and perspective warps have been implemented for 8-bit, 16-bit and RGB color data using bilinear interpolation. The affine warp can generate 512 × 512 warped output images faster than real-time video rates require. For 8-bit images, the performance is 14.1 ms. Although the amount of computation necessary is the same for 16-bit images, the execution time increases to 15.2 ms since twice as many bytes need to be transferred. For RGB color images, it takes 28.0 ms. The perspective warp requires 46.3 ms for 8-bit and 16-bit images, and 60.4 ms for RGB color images. This unprecedented performance for software-based image warping exceeds many hardwired approaches reported in the literature. © 1998 Academic Press.",,Real-Time Imaging,1998-01-01,Article,"Evans, O. D.;Kim, Y.",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-85072735997,10.3389/fpubh.2019.00218,Electronic Immunization Registries in Tanzania and Zambia: Shaping a Minimum Viable Product for Scaled Solutions,"As part of the work the Better Immunization Data (BID) Initiative undertook starting in 2013 to improve countries' collection, quality, and use of immunization data, PATH partnered with countries to identify the critical requirements for an electronic immunization registry (EIR). An EIR became the core intervention to address the data challenges that countries faced but also presented complexities during the development process to ensure that it met the core needs of the users. The work began with collecting common system requirements from 10 sub-Saharan African countries; these requirements represented the countries' vision of an ideal system to track individual child vaccination schedules and elements of supply chain. Through iterative development processes in both Tanzania and Zambia, the common requirements were modified and adapted to better fit the country contexts and users' needs, as well as to be developed with the technology available at the time. This process happened across four different software platforms. This paper outlines the process undertaken and analyzes similarities and differences across the iterations of the EIR in both countries, culminating in the development of a registry in Zambia that includes the most critical aspects required for initially deploying the registry and embodies what could be considered the minimum viable product for an EIR.",digital | electronic immunization registry | immunization | patient data | register | registry | requirements,Frontiers in Public Health,2019-08-07,Article,"Seymour, Dawn;Werner, Laurie;Mwansa, Francis Dien;Bulula, Ngwegwe;Mwanyika, Henry;Dube, Mandy;Taliesin, Brian;Settle, Dykki",Exclude,EC1
10.1016/j.infsof.2022.107144,2-s2.0-85047911618,10.5220/0006224801280132,Enabling focused software quality assurance in agile software development processes for mobile applications using text and usage mining methods,"The acceptance of mobile applications that support services, such as navigation guidance or travel management, is highly dependent on the set of features implemented and the application quality. Information about the acceptance can be gained quickly by collecting user feedback like explicit textual reviews given by the application users or their implicitly given usage data. Considering an approach that bases on developing a minimal set of functions in order to realize a minimal viable product (MVP), it is possible to place a product with a short time to market. In this paper the Opti4Apps approach is presented. It aims at a focused quality assurance as part of the MVP development, which enables and expands the benefits of MVP by providing a semi-automated feedback elicitation, analysis and processing framework. The Opti4Apps process adjusts to mobile development habits including an additional automated feedback and usage data processing infrastructure.",Agile Software Development | Data Analytics | Data Mining | Mobile Computing | Software Maintenance Tools,"VISIGRAPP 2017 - Proceedings of the 12th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications",2017-01-01,Conference Paper,"Bauer, Michael;Sergieieva, Kateryna;Meixner, Gerrit",Include,Yes
10.1016/j.infsof.2022.107144,2-s2.0-0345890017,10.1142/S0218194097000102,Enriching software process support by knowledge-based techniques,"Representations of activities dealing with the development or maintenance of software are called software process models. Process models allow for communication, reasoning, guidance, improvement, and automation. Two approaches for modeling processes and instantiating and managing the process models, namely CoMo-Kit and MVP-E, are combined to build a more powerful one. CoMo-Kit is based on AI/KE technology; it is a support tool system for general complex design processes, and was not been developed specifically with software development processes in mind. MVP-E is a process-sensitive software engineering environment for modeling and analyzing software development processes, and guides software developers. Additionally, it provides services to establish and run measurement programmes in software organizations. Because both approaches were developed independently from one another, major integration efforts had to be made to combine both their advantages. This article concentrates on the resulting language concepts, and their operationalization necessary for building automated process support.",,International Journal of Software Engineering and Knowledge Engineering,1997-01-01,Article,"Dellen, Barbara;Maurer, Frank;Münch, Jürgen;Verlage, Martin",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-85054155369,10.1063/1.5054445,Estimation of HTTR fission products released from homogeneous and heterogeneous fuel configuration using MVP software,"Burn-up simulation of High Temperature Engineering Test Reactor (HTTR) has been performed using MVP software. The purpose of this study is to estimate the fission products from the reactor fuel. The type of fuel was modeled as prismatic blocks containing 6% enrichment UO2 pebbles coated with TRISO. The burn-up was calculated from 1,000 MWd/t to 35,000 MWd/t with 8 steps at a constant power of 30 MWth and the fuel configurations were either homogenous or heterogeneous. We only analyzed the xenon, iodine and cesium groups fission products. The result of each group for homogeneous was (9.361 ± 0.021)×1014 Bq, (2.7362 ± 0.0067)×1015 Bq and (9.781 ± 0.024)×1013 Bq while for heterogeneous was (1.0969 ± 0.0024)×1016 Bq, (3.3071 ± 0.0068)×1016 Bq and (1.1812 ± 0.0024)×1015 Bq respectively for 135Xe, 135I and 137Cs. These results clearly showed that the heterogeneous configuration have higher activities than those of the homogeneous.",,AIP Conference Proceedings,2018-09-21,Conference Paper,"Audila, Elma;Suharyana, ;Riyatun, R.;Khakim, Azizul",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-77953660026,10.4244/EIJV5I1A15,Ex vivo analysis of human coronary bifurcation anatomy: Defining the main vessel-to-side-branch transition zone,"Aims: Defining vessel diameters and angles that comprise coronary side-branch intersections could assist in tailoring treatments to match anatomy, improve haemodynamic flow, and minimise mechanical trauma. We sought to characterise intersections of main vessels and side-branches by measuring actual diameters, angles, and shapes at the ostia in human coronary arteries. Methods and results: Polymer casts were created using coronary trees from 23 adult cadaver hearts. Seventy-five arterial intersections between main vessels and side-branches were captured using the combination of a microscope (Smartscope MVP100) and computer program (Gage-X metrology software) specifically calibrated for video-based inspection and measurement (34-fold magnification). The intersection between main vessels and side-branches was a multifaceted, curvilinear transition rather than a bisecting angle. The shape of the ostia was typically elliptical rather than circular. Mean diameters were 2.88 mm in proximal main vessels, 2.34 mm in ostia, and 2.00 mm in side-branches (first-level branches). Obtuse proximal (150 degrees) and distal (111 degrees) angles with accentuated side-branch taper create a ""barn door"" effect with wider curvature at the bottom. Conclusions: Matching treatments to these various forms of asymmetry at the main vessel-to-side-branch intersection may minimise injury and optimise scaffolding, and haemodynamic flow. © Europa Edition. All rights reserved.",Angles | Coronary bifurcation | Human coronaries | Ostium | Vessel diameters,EuroIntervention,2009-01-01,Article,"Russell, Mary E.;Binyamin, Gary;Konstantino, Eitan",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-0032404008,10.1117/12.312547,Fast convolution on a programmable mediaprocessor and application in unsharp masking,"Convolution is a fundamental operation to many image processing algorithms and applications. One such algorithm is unsharp masking, which is widely used in medical imaging. A major component in unsharp masking is the computation of a lowpass-filtered image, e.g., via generalized convolution with a Gaussian filter or via specialized convolution with a boxcar filter. Generalized convolution is computationally expensive, e.g., convolution with a 3 × 3 kernel on a 512 × 512 image takes 1.45 sec on SUN SparcStation 20/71. In order to achieve faster computation in convolution, hardwired solutions with ASICs and/or fixed-function chips with little programmability have been traditionally used. The disadvantages associated with hardwired implementations are that they are rigid, unifunctional and not upgradable. Our approach has been programmable convolution, which is flexible, multi-functional, easily-upgradable and has a performance comparable to the hardwired implementations. This paper describes efficient software implementations of both generalized and boxcar convolution on a programmable multimedia processor, the Texas Instruments TMS320C80, also known as Multimedia Video Processor (MVP). Using the MVP's advanced digital signal processors (ADSPs), instruction-level parallelism and intelligent input/output interface, we have been able to significantly improve the performance of both generalized and boxcar convolution. For a 512 × 512 8-bit image, generalized convolution takes 19.5 ms for a 3 × 3 kernel. While the boxcar convolution has similar performance for a 3 × 3 kernel, the performance improvement by a factor of up to 13 has been achieved for large-size kernels such as 21 × 21. Our implementation of convolution algorithms on programmable mediaprocessor clearly demonstrates the feasibility of software-based approach.",Boxcar convoluion | Convolution | HMPV | Programmable mediaprocessor | TMS320C80 | Unsharp masking,Proceedings of SPIE - The International Society for Optical Engineering,1998-12-01,Conference Paper,"Managuli, Ravi A.;Basoglu, C.;Pathak, Sayan D.;Kim, Y.",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-84893706273,10.1109/VCIP.2013.6706441,Fast merge mode decision for diamond search in High Efficiency Video Coding,"This paper proposes a merge mode decision algorithm while maintaining the accuracy of a diamond search (DS) in motion estimation and compensation. In High Efficiency Video Coding (HEVC), the merge mode is used to reduce the bit rate in order to carry motion information. The rate-distortion (RD) cost of the merge mode is compared with the RD cost of the inter-prediction mode in the course of the motion estimation which can be terminated early when the merge cost is smaller than the estimated cost of the inter-prediction mode. To this end, this paper proposes a fast merge mode prediction algorithm when the DS is used for motion estimation. The main purpose of this work is to estimate the RD cost of the merge mode in advance by utilizing the distortion information of the RD cost of the motion vector prediction (MVP) so as to early terminate the motion search operation. Experimental results show that the proposed fast merge mode estimation achieves a comparable RD performance but reduces the amount of computation by 16.6% on the average when compared to the fast motion estimation with the diamond search implemented in the HM 8.0 reference software. © 2013 IEEE.",HEVC | mode decision | motion estimation | video coding | visual communications,IEEE VCIP 2013 - 2013 IEEE International Conference on Visual Communications and Image Processing,2013-12-01,Conference Paper,"Kim, Miok;Lee, Hyuk Jae;Ling, Nam",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-79955364625,,Feasibility and performance of novel software to quantify metabolically active volumes and 3D partial volume corrected SUV and metabolic volumetric products of spinal bone marrow metastases on 18F-FDG-PET/CT,"Our aim was to assess feasibility and performance of novel semi-automated image analysis software called ROVER to quantify metabolically active volume (MAV), maximum standardized uptake value-maximum (SUVmax), 3D partial volume corrected mean SUV (cSUVmean), and 3D partial volume corrected mean MVP (cMVPmean) of spinal bone marrow metastases on fluorine-18 fluorodeoxyglucose-positron emission tomography/computerized tomography (18F-FDG-PET/CT). We retrospectively studied 16 subjects with 31 spinal metastases on FDG-PET/CT and MRI. Manual and ROVER determinations of lesional MAV and SUVmax, and repeated ROVER measurements of MAV, SUVmax, cSUVmean and cMVPmean were made. Bland-Altman and correlation analyses were performed to assess reproducibility and agreement. Our results showed that analyses of repeated ROVER measurements revealed MAV mean difference (D)=-0.03±0.53cc (95%CI(-0.22, 0.16)), lower limit of agreement (LLOA)=-1.07cc, and upper limit of agreement (ULOA)=1.01cc; SUVmax D=0.00±0.00 with LOAs=000; cSUVmean D=-0.01±0.39 (95%CI(-0.15, 0.13)), LLOA=-0.76, and ULOA=0.75; cMVP mean D=-0.52±4.78cc (95%CI(-2.23, 1.23)), LLOA=-9.89cc, and ULOA=8.86cc. Comparisons between ROVER and manual measurements revealed volume D= -0.39±1.37cc (95%CI (-0.89, 0.11)), LLOA=-3.08cc, and ULOA=2.30cc; SUVmax D=0.00±0.00 with LOAs=000. Mean percent increase in lesional SUVmean and MVPmax followinq partial volume correction using ROVER was 84.25±36.00% and 84.45+35.94%, respectively. In conclusion, it is feasible to estimate MAV, SUVmax, cSUV mean, and cMVPmean of spinal bone marrow metastases from 18F-FDG-PET/CT quickly and easily with good reproducibility via ROVER software. Partial volume correction is imperative, as uncorrected SUV mean and MVPmean are significantly underestimated, even for large lesions. This novel approach has great potential for practical, accurate, and precise combined structural-functional PET quantification of disease before and after therapeutic intervention.",18 F-FDG-PET/CT | Bone marrow metastasis | Global disease assessment | Partial volume correction | Quantitative analysis | Software analysis,Hellenic Journal of Nuclear Medicine,2011-01-01,Article,"Torigian, Drew A.;Lopez, Rosa Fernandez;Alapati, Sridevi;Bodapati, Geetha;Hofheinz, Frank;Van Den Hoff, Joerg;Saboury, Babak;Alavi, Abass",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-84871867082,,Feasibility of estimation of brain volume and 2-deoxy-2- 18F-fluoro-D-glucose metabolism using a novel automated image analysis method: Application in Alzheimer's disease,"The development of clinically-applicable quantitative methods for the analysis of brain fluorine-18 fluoro desoxyglucose-positron emission tomography (18F-FDG-PET) images a major area of research in many neurologic diseases, particularly Alzheimer's disease (AD). Region of interest visualization, evaluation, and image registration (ROVER) is a novel commercially-available software package which provides automated partial volume corrected measures of volume and glucose uptake from 18F-FDG PET data. We performed a pilot study of ROVER analysis of brain 18F-FDG PET images for the first time in a small cohort of patients with AD and controls. Brain 18F-FDG-PET and volumetric magnetic resonance imaging (MRI) were performed on 14 AD patients and 18 age-matched controls. Images were subjected to ROVER analysis, and voxel-based analysis using SPM5. Volumes by ROVER were 35% lower than MRI volumes in AD patients (as hypometabolic regions were excluded in ROVER-derived volume measurement) while average ROVER- and MRI-derived cortical volumes were nearly identical in control population. Whole brain volumes when ROVER-derived and whole brain metabolic volumetric products (MVP) were significantly lower in AD and accurately distinguished AD patients from controls (Area Under the Curve (AUC) of Receiver Operator Characteristic (ROC) curves 0.89 and 0.86, respectively). This diagnostic accuracy was similar to voxel-based analyses. Analysis by ROVER of 18F-FDG-PET images provides a unique index of metabolically-active brain volume, and can accurately distinguish between AD patients and controls as a proof of concept. In conclusion, our findings suggest that ROVER may serve as a useful quantitative adjunct to visual or regional assessment and aid analysis of whole-brain metabolism in AD and other neurologic and psychiatric diseases.",18 F-FDG | Alzheimer's disease | Metabolic volume | PET | ROVER | Whole brain metabolism,Hellenic Journal of Nuclear Medicine,2012-09-01,Article,"Musiek, Erik S.;Saboury, Babak;Mishra, Shipra;Chen, Yufen;Reddin, Janet S.;Newberg, Andrew B.;Udupa, Jayaram K.;Detre, John A.;Hofheinz, Frank;Torigian, Drew;Alavi, Abass",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-85058561760,10.1007/978-3-030-04840-2_12,From MVPs to pivots: A hypothesis-driven journey of two software startups,"Software startups have emerged as an interesting multiper-spective research area. Inspired by Lean Startup, a startup journey can be viewed as a series of experiments that validate a set of business hypotheses an entrepreneurial team make explicitly or inexplicitly about their startup. It is little known about how startups evolve through business hypothesis testing. This study proposes a novel approach to look at the startup evolution as a Minimum Viable Product (MVP) creating process. We identified relationships among business hypotheses and MVPs via ethnography and post-mortem analysis in two software startups. We observe that the relationship between hypotheses and MVPs is incomplete and non-linear in these two startups. We also find that entrepreneurs do learn from testing their hypotheses. However, there are hypotheses not tested by MVPs and vice versa, MVPs not related to any business hypothesis. The approach we proposed visualizes the flow of entrepreneurial knowledge across pivots via MVPs.",Entrepreneurial journey | Lean startup | Minimum viable product | Pivot | Software startup,Lecture Notes in Business Information Processing,2018-01-01,Conference Paper,"Khanna, Dron;Nguyen-Duc, Anh;Wang, Xiaofeng",Include,Yes
10.1016/j.infsof.2022.107144,2-s2.0-84871595566,10.1109/MoDRE.2012.6360084,From use cases and their relationships to code,"Use cases are used in many methodologies to drive the software engineering process. Though, their transition to code was usually a mostly manual process. In the context of MDD, use cases gain attention as first-class artifacts with representation notations allowing for automatic transformations to analysis and design models. The paper concentrates on an important problem of constructing transformations that cater for use case relationships. It presents a notation that unifies the ambiguous ""include"" and ""extend"", and allows for representing them within textual use case scenarios. This notation, equipped with runtime semantics, is used to construct a direct transformation into working code. The code is placed within method bodies of the Controller/Presenter and View layers within the MVC/MVP framework. Based on this transformation, an agile use-case-driven development process is possible. © 2012 IEEE.",,"2012 2nd IEEE International Workshop on Model-Driven Requirements Engineering, MoDRE 2012 - Proceedings",2012-12-31,Conference Paper,"Śmiałek, Michał;Nowakowski, Wiktor;Jarzȩbowski, Norbert;Ambroziewicz, Albert",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-38149008090,10.1016/j.ahj.2007.09.002,Geometry of the proximal isovelocity surface area in mitral regurgitation by 3-dimensional color Doppler echocardiography: Difference between functional mitral regurgitation and prolapse regurgitation,"Background: The geometry of the proximal isovelocity surface area (PISA) of functional mitral regurgitation (MR), which is conventionally assumed to be a hemisphere, remains to be clarified. We investigated the 3-dimensional (3D) geometry of PISA of functional MR as opposed to that of MR due to mitral valve prolapse (MVP) by real-time 3D echocardiography with color Doppler capability. Methods: Twenty-seven patients with functional MR and 27 patients with MVP were examined. The horizontal PISA length in the commissure-commissure plane and each PISA radius in 3 anteroposterior planes (medial, central, and lateral) were measured by real-time 3D echocardiography with 3D software. The effective regurgitant orifice (ERO) area was calculated with the maximum PISA radius and compared to that by 2D quantitative Doppler method. Results: En-face 3D color Doppler images showed an elongated and slightly curved PISA geometry along the leaflet coaptation in functional MR, whereas the geometry was rounder in MVP. The PISA horizontal length in functional MR was longer than that in MVP (2.3 ± 0.4 vs 1.2 ± 0.2 cm, P < .001). The PISA method with the maximum radius underestimated the ERO area by 2D quantitative Doppler method (by 24%) in functional MR, but not in MVP. Conclusions: The geometry of PISA in functional MR was elongated, distinctly different from the more focal pathology of MVP, leading to underestimation of the ERO area by PISA method. © 2008 Mosby, Inc. All rights reserved.",,American Heart Journal,2008-02-01,Article,"Matsumura, Yoshiki;Fukuda, Shota;Tran, Hung;Greenberg, Neil L.;Agler, Deborah A.;Wada, Nozomi;Toyono, Manatomo;Thomas, James D.;Shiota, Takahiro",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-85072276727,10.1109/ICSE.2019.00114,GreenBundle: An Empirical Study on the Energy Impact of Bundled Processing,"Energy consumption is a concern in the data-center and at the edge, on mobile devices such as smartphones. Software that consumes too much energy threatens the utility of the end-user's mobile device. Energy consumption is fundamentally a systemic kind of performance and hence it should be addressed at design time via a software architecture that supports it, rather than after release, via some form of refactoring. Unfortunately developers often lack knowledge of what kinds of designs and architectures can help address software energy consumption. In this paper we show that some simple design choices can have significant effects on energy consumption. In particular we examine the Model-View-Controller architectural pattern and demonstrate how converting to Model-View-Presenter with bundling can improve the energy performance of both benchmark systems and real world applications. We show the relationship between energy consumption and bundled and delayed view updates: bundling events in the presenter can often reduce energy consumption by 30%.",MVC | MVP | software architecture | software energy consumption,Proceedings - International Conference on Software Engineering,2019-05-01,Conference Paper,"Chowdhury, Shaiful Alam;Hindle, Abram;Kazman, Rick;Shuto, Takumi;Matsui, Ken;Kamei, Yasutaka",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-84960495291,10.1109/TCSVT.2015.2406199,HEVC Encoding Optimization Using Multicore CPUs and GPUs,"Although the High Efficiency Video Coding (HEVC) standard significantly improves the coding efficiency of video compression, it is unacceptable even in offline applications to spend several hours compressing 10 s of high-definition video. In this paper, we propose using a multicore central processing unit (CPU) and an off-the-shelf graphics processing unit (GPU) with 3072 streaming processors (SPs) for HEVC fast encoding, so that the speed optimization does not result in loss of coding efficiency. There are two key technical contributions in this paper. First, we propose an algorithm that is both parallel and fast for the GPU, which can utilize 3072 SPs in parallel to estimate the motion vector (MV) of every prediction unit (PU) in every combination of the coding unit (CU) and PU partitions. Furthermore, the proposed GPU algorithm can avoid coding efficiency loss caused by the lack of a MV predictor (MVP). Second, we propose a fast algorithm for the CPU, which can fully utilize the results from the GPU to significantly reduce the number of possible CU and PU partitions without any coding efficiency loss. Our experimental results show that compared with the reference software, we can encode high-resolution video that consumes 1.9% of the CPU time and 1.0% of the GPU time, with only a 1.4% rate increase.",Encoding optimization | graphics processing unit (GPU) | H.264 | High Efficiency Video Coding (HEVC) | multicore central processing unit (CPU),IEEE Transactions on Circuits and Systems for Video Technology,2015-11-01,Article,"Xiao, Wei;Li, Bin;Xu, Jizheng;Shi, Guangming;Wu, Feng",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-85034577155,10.1007/978-3-319-69926-4_21,How do software startups approach experimentation? Empirical results from a qualitative interview study,"Software startups often make assumptions about the problems and customers they are addressing as well as the market and the solutions they are developing. Testing the right assumptions early is a means to mitigate risks. Approaches such as Lean Startup foster this kind of testing by applying experimentation as part of a constant build-measure-learn feedback loop. The existing research on how software startups approach experimentation is very limited. In this study, we focus on understanding how software startups approach experimentation and identify challenges and advantages with respect to conducting experiments. To achieve this, we conducted a qualitative interview study. The initial results show that startups often spent a disproportionate amount of time focusing on creating solutions without testing critical assumptions. Main reasons are the lack of awareness, that these assumptions can be tested early and a lack of knowledge and support on how to identify, prioritize and test these assumptions. However, startups understand the need for testing risky assumptions and are open to conducting experiments.",Experiment | Experimentation | Lean startup | Minimum viable product | Software startups,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2017-01-01,Conference Paper,"Gutbrod, Matthias;Münch, Jürgen;Tichy, Matthias",Include,Yes
10.1016/j.infsof.2022.107144,2-s2.0-85072322489,10.1109/ICSSP.2019.00019,How do startups develop internet-of-things systems - A multiple exploratory case study,"Internet-of-Things applications are not only the new opportunity for digital businesses but also a major driving force for the modification and creation of software systems in all industries and businesses. Compared to other types of software-intensive products, the development of Internet-of-Things applications lacks a systematic approach and guidelines. This paper aims at understanding the methodological commonalities among startups who are developing Internet-of-Things products. Using the SEMAT Essence framework, we captured common team compositions, common types of Minimum Viable Products and common way of working in early stage Internet-of-Things startups. We found that startups include various engineering and business competence, but do not cover all of what is needed. The development of Internet-of-Things applications adopts certain speed-favor approaches, i.e. rapid prototyping, iterative development and outsourcing. The finding implies some recommendations for both researchers and practitioners in the area of Internet-of-Things development.",Case study | Hardware-related development | Internet-of-Things | Minimum Viable Products | SEMAT Essence,"Proceedings - 2019 IEEE/ACM International Conference on Software and System Processes, ICSSP 2019",2019-05-01,Conference Paper,"Nguyen Duc, Anh;Khalid, Khan;Lonnestad, Tor;Bajwa Shahid, Sohaib;Wang, Xiaofeng;Abrahamsson, Pekka",Exclude,EC1
10.1016/j.infsof.2022.107144,,,Hybrid Labels are the New Measure!,,,,,,,Include,Already selected
10.1016/j.infsof.2022.107144,2-s2.0-85040312234,10.1109/MS.2017.4541048,Hybrid Labels Are the New Measure!,"Developing minimum viable products (MVPs) is critical for start-up companies to hit the market fast with an accepted level of performance. The US Food and Drug Administration mandates additional nonfunctional requirements in healthcare systems, meaning that the MVP should provide the best availability, privacy, and security. This critical demand is motivating companies to further rely on analytics to optimize the development process. In a collaborative project with Brightsquid, the authors provided a decision-support system based on analogical reasoning to assist in effort estimation, scoping, and assignment of change requests. This experience report proposes a new metric, change request labels, for better prediction. Using different methods for textual-similarity analysis, the authors found that the combination of machine-learning techniques with experts' manually added labels has the highest prediction accuracy. Better prediction of change impacts allows a company to optimize its resources and provide proper timing of releases to target MVPs. This article is part of a special issue on Actionable Analytics for Software Engineering.",change impact analysis | digital care | digital health | software analytics | software development | software engineering,IEEE Software,2017-01-01,Article,"Nayebi, Maleknaz;Kabeer, Shaikh Jeeshan;Ruhe, Guenther;Carlson, Chris;Chew, Francis",Include,Yes
10.1016/j.infsof.2022.107144,2-s2.0-0027666576,,IBM's and Apple's multimedia solutions: new systems for application development,"With the increasing growing multimedia development, to deliver the ultimate in multimedia solutions, IBM introduced earlier this year its PS/Value Point MVP series with 30 new multimedia system, software and hardware packages that are built-to-order to meet the end-users' needs. MVP stands for Multimedia for ValuePoint. A user now can select the kind of microprocessor, hard disk drive, display options and media packages he/she wants from 30 different system configurations with choices ranging from 486Sx25MHz with 120-MB hard disk drives to 486Dx2 33/66 Mhz with 340-MB/527-MB hard disk drives. Memory is upgradeable to 64 MBs, in 2,4,8 or 16-MB increments, Video Memory can be upgraded to 2 MBs, and one can order 128-KB or 256-KB 1.2 Cache for super fast processing. WIth a minimum of 8 MBS of RAM memory, the system can run OS/2 2.1 with its Multimedia Presenter Manager (MMPM/2). Twenty-one packages meet or exceed the minimum standards set for Multimedia PC Level 2.",,Microcomputers for Information Management,1993-09-01,Article,"Chen, Ching chih",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-0029700913,,Image wavelet analysis with the multimedia video processor,"Images can be decomposed into wavelet components using quadrature mirror filtering (QMF) for significant signal entropy reduction and practically lossless subsequent reconstruction. The Multimedia Video Processor (MVP), a five-processor MIMD chip developed by Texas Instruments (TI), is considered for high speed image QMF. The image convolution operation is an integral part of QMF, as well as the basic computational workhorse for numerous other image processing functions. Computational and memory management techniques specific to image convolutions on this architecture are presented. Performance with these considerations is measured using the TI MVP software simulator.",,Conference Proceedings - IEEE SOUTHEASTCON,1996-01-01,Conference Paper,"Brooks, Geoffrey",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-84870662065,10.1016/j.iheduc.2012.11.004,Impact of online instructional game features on college students' perceived motivational support and cognitive investment: A structural equation modeling study,"Colleges and universities have begun to understand the instructional potential of digital game-based learning (DGBL) due to digital games' immersive features. These features, however, might overload learners as excessive motivational and cognitive stimuli thus impeding intended learning. Current research, however, lacks empirical evidences to align game features with their motivational and cognitive support. Therefore, this study explored the relationship among game features, learners' perceived motivational support, and cognitive investment based on the Theory on Motivation, Volition, and Performance (MVP). Based on 264 college students' responses after playing an open online instructional game, the finding first revealed three converging factors of DGBL features (game appeal, game involvement, game structure). Second, a structural equation modeling identified a significant model that aligns with MVP theory's constructs. Future research should develop a consolidated design model to consider all identified empirical relationships in order to support efficient digital game-based learning. © 2012 Elsevier Inc.",Cognitive investment | Design | Digital game-based learning | Motivational support | Structural equation modeling,Internet and Higher Education,2013-01-01,Article,"Huang, Wenhao David;Johnson, Tristan E.;Han, Seung Hyun Caleb",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-85084088906,10.1109/ICAICTA.2019.8904323,Implement a Lean UX Model: Integrating Students' Academic Monitoring through a mobile app,"This study explores how a Lean method collaborates with the UX characteristics to implement a single sign on application for the 'Y Generation' age group to monitor their daily academic life. With a personalized mobile application, students will be able to monitor their academic and/or nonacademic activities that scheduled every day. Lean UX will support the development phase by creating a minimum viable product (MVP) fast as possible during several steps or iterations. The UI / UX experiment results generated through two iterations with Think Aloud Interview Testing and Software Usability Testing. The results obtained are used to represent the user acceptance during User Experience testing with increasing SUS score to 72.85 and decreasing average time completion, which indicates an increasing point of cognitive process of the users as 80% while interacting with the application.",Lean UX | millennials | mobile application | usability,"Proceedings - 2019 International Conference on Advanced Informatics: Concepts, Theory, and Applications, ICAICTA 2019",2019-09-01,Conference Paper,"Mardhia, Murein Miksa;Anggraini, Ela Dwi",Include,Yes
10.1016/j.infsof.2022.107144,2-s2.0-84868614917,,Implementation of DNA markers to produce genomically - Enhanced EPDs in nellore cattle,"Background: The sequencing and publication of the cattle genome and the identification of single nucleotide polymorphism (SNP) molecular markers have provided new tools for animal genetic evaluation and genomic-enhanced selection. These new tools aim to increase the accuracy and scope of selection while decreasing generation interval. The objective of this study was to evaluate the enhancement of accuracy caused by the use of genomic information (Clarifide® - Pfizer) on genetic evaluation of Brazilian Nellore cattle. Review: The application of genome-wide association studies (GWAS) is recognized as one of the most practical approaches to modern genetic improvement. Genomic selection is perhaps most suited to the improvement of traits with low heritability in zebu cattle. The primary interest in livestock genomics has been to estimate the effects of all the markers on the chip, conduct cross-validation to determine accuracy, and apply the resulting information in GWAS either alone [9] or in combination with bull test and pedigree-based genetic evaluation data. The cost of SNP50K genotyping however limits the commercial application of GWAS based on all the SNPs on the chip. However, reasonable predictability and accuracy can be achieved in GWAS by using an assay that contains an optimally selected predictive subset of markers, as opposed to all the SNPs on the chip. The best way to integrate genomic information into genetic improvement programs is to have it included in traditional genetic evaluations. This approach combines traditional expected progeny differences based on phenotype and pedigree with the genomic breeding values based on the markers. Including the different sources of information into a multiple trait genetic evaluation model, for within breed dairy cattle selection, is working with excellent results. However, given the wide genetic diversity of zebu breeds, the high-density panel used for genomic selection in dairy cattle (Ilumina Bovine SNP50 array) appears insufficient for across-breed genomic predictions and selection in beef cattle. Today there is only one breed-specific targeted SNP panel and genomic predictions developed using animals across the entire population of the Nellore breed (www.pfizersaudeanimal.com), which enables genomically - enhanced selection. Genomic profiles are a way to enhance our current selection tools to achieve more accurate predictions for younger animals. Material and Methods: We analyzed the age at first calving (AFC), accumulated productivity (ACP), stayability (STAY) and heifer pregnancy at 30 months (HP30) in Nellore cattle fitting two different animal models; 1) a traditional single trait model, and 2) a two-trait model where the genomic breeding value or molecular value prediction (MVP) was included as a correlated trait. All mixed model analyses were performed using the statistical software ASREML 3.0. Results: Genetic correlation estimates between AFC, ACP, STAY, HP30 and respective MVPs ranged from 0.29 to 0.46. Results also showed an increase of 56%, 36%, 62% and 19% in estimated accuracy of AFC, ACP, STAY and HP30 when MVP information was included in the animal model. Conclusion: Depending upon the trait, integration of MVP information into genetic evaluation resulted in increased accuracy of 19% to 62% as compared to accuracy from traditional genetic evaluation. GE-EPD will be an effective tool to enable faster genetic improvement through more dependable selection of young animals.",Dna markers | Genetic evaluation | Genomic Enhanced epds | Genomic selection | Nellore cattle | Snp,Acta Scientiae Veterinariae,2011-12-01,Article,"Lôbo, Raysildo Barbosa;Nkrumah, Donald;Grossi, Daniela do Amaral;De Barros, Priscila Sales;Paiva, Pablo;Bezerra, Luiz Antônio Framatino;De Oliveira, Henrique Nunes;Da Silva, Marcos Vinícius Barbosa",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-85082662819,10.1109/GHTC46095.2019.9033107,Implementing Communications and Information Dissemination Technologies for First Responders,"Despite technological advances in voice communications for disaster response, firefighter fatalities continue. This highlights the inadequacies of current communication between incident commanders and those in the fireground. Through its Major Fires Investigation Project, the United States Fire Administration (USFA) repeatedly cites inadequate communication systems as a contributing factor in first responder, rescue worker, and civilian casualties. Hence, emergency Response Communication and Information Technology must be improved. Santa Clara University's Frugal Innovation Hub (FIH) has undertaken the development of a minimum viable product (MVP) that includes a novel set of mobile applications and mobile hardware devices suitable for firefighters during emergency responses. This work is an evolution of earlier research conducted by principals of IncidentAid, P.B.C. While the long-term vision for IncidentAid has been to provide software and services that cover the entire lifecyle of disaster management, one of it's immediate efforts have been to improve communications and information solutions that reach the individual first responder. FIH's prototype is an effort towards the actualization of this IncidentAid's immediate effort.",Computer Aided Dispatch | Emergency Response Applications | Emergency Response Communication and Information Technology (ERCIT) | First Responders | Mobile Information Communication and Management,"2019 IEEE Global Humanitarian Technology Conference, GHTC 2019",2019-10-01,Conference Paper,"Shaghaghi, Navid;Patel, Semal;Pabari, Brinda;Francis, Maya",Include,Yes
10.1016/j.infsof.2022.107144,2-s2.0-0031679105,10.1016/S0005-1098(97)00161-1,Improved software quality through improved development process descriptions,"The quality of software depends on the quality of the performance of the development process. Process documents (or so-called process models) help developers to perform their processes. Formal process models have advantages over informal ones (e.g. project handbooks) including completeness, consistency, and unambiguity. The problem addressed in this paper is the choice of a modeling procedure when formalizing existing, informal process descriptions. A study is presented in which an informal description of an IBM Cleanroom process was transformed into a formal Multi-View Process Modeling Language (MVP-L) model. With phase-, level-, and concept-based modeling three different formalization approaches were evaluated of which concept-based modeling turned out to be advantageous over the others with respect to its complexity and necessary rework. © 1998 Elsevier Science Ltd. All rights reserved.",Documentation | Process models | Software engineering | Software project management,Automatica,1998-01-01,Article,"Bunse, Christian;Verlage, Martin;Giese, Peter",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-84925128013,10.1109/MS.2015.44,Injecting value-thinking into prioritization decisions,"A proposed approach injects value-thinking into feature prioritization, using story mapping. The Web extra at http://youtu.be/Xm5VqODvVZE is an audio podcast in which author Jane Cleland-Huang provides an audio recording of the Requirements column, in which she discusses an approach that injects value-thinking into feature prioritization by using story mapping.",feature prioritization | incremental funding | minimum marketable features | minimum viable product | release planning | return on investment | ROI | software engineering | story mapping | value-thinking,IEEE Software,2015-03-01,Article,"Cleland-Huang, Jane",Exclude,EC1
10.1016/j.infsof.2022.107144,2-s2.0-85046994915,10.2514/6.2017-5145,Innovative test operations to support orion and future human rated missions,"This paper describes how the Orion program is implementing new and innovative test approaches and strategies in an evolving development environment. The Orion program successfully completed the EFT-1 flight test in 2014 and is currently assembling, integrating, and testing the EM-1 spacecraft to meet the flight test objectives of an unmanned orbital mission to the moon and return to earth in 2019. The EM-2 spacecraft will be the first crewed mission and is planned in 2021. The early flight test spacecraft are evolving in design maturity and complexity requiring significant changes in the ground test operations for each mission. The resulting testing approach for EM-2 is planned to validate innovative Orion production acceptance testing methods to support human exploration missions. This approach will also benefit other human exploration vehicles in the future in achieving affordable and low risk goals. The Orion flight test vehicle, EFT-1, was built and tested using the Neil Armstrong Operations and Checkout (O&C) facility at the Kennedy Space Center (KSC). Orion manufacturing and testing was located at KSC to provide a seamless transition directly to the launch site avoiding transportation and checkout of the spacecraft from other locations. Innovative test operations approaches were established early on in the O&C facility activation to integrate with the production operations providing a robust and flexible factory to meet Orion’s evolving requirements. As a development flight test article, EFT-1 experienced limited acceptance testing for structural static and dynamic testing and subsystem functional test and checkout. The success of the EFT-1 mission not only validated the engineering design, both hardware and software, but also demonstrated that the manufacturing and test operations established at the O&C were in place to support the Orion production needs in the future. The second flight test vehicle processed in the O&C is the EM-1, which will have additional flight systems installed to fly to the moon and return. EM-1 is designed as a human rated vehicle, but will be an un-crewed mission to continue to retire risk to verify EM-2 for crewed flight. The EM-1 test operations will expand to include test methods leading to an acceptable flight test vehicle, but also will support selected qualification milestones. Since the O&C facility does not currently have a system level test capability, the EM-1 spacecraft will be tested at the NASA Plum Brook Station (PBS) in Ohio using test capabilities for thermal vacuum and acoustic testing. This will require EM-1 to be transported to PBS by aircraft, tested, and returned to the O&C for final checkout and integration. The program has developed a comprehensive Master Verification Plan (MVP) that defines a qualification strategy utilizing existing test facilities, innovative test methods, and multiple test articles to meet program verification objectives. This innovative system test strategy utilizes the test capabilities at PBS and the O&C to qualify and accept the EM design using multiple flight and test articles. This approach qualifies the design and validates the acceptance test approach at the O&C avoiding the transportation of spacecraft, supporting test labor, and test tooling to PBS. The qualification test strategy is based on utilizing the system qualification results of the EM-1 vehicle, performing selected module level acceptance testing for the EM-2 Crew Module (CM) and Service Module (SM) separately, and validating acceptance test methods using portable test facilities for acoustic and thermal cycle testing based on system qualification results. This approach satisfies the verification and validation objectives of “test what you fly and fly what you test” approach meeting the 100% mission success goals of the Orion program. The Orion acceptance test approach for EM-2 in the O&C utilizes the existing altitude chamber and portable test equipment to meet the environmental test requirements. The O&C facility has been designed with a flexible factory layout to enable the factory to be reconfigured to meet a variety of production and test operations configurations. This approach was first used on EFT-1 and will continue into Orion production. Acoustic testing will be accomplished using a validated approach called Direct Field Acoustic Test (DFAT®). This approach uses portable acoustic speakers located in an open cell positioned around the spacecraft. Correlation tests were performed with the DFAT test equipment with reverberant acoustic chambers to demonstrate applicability for acceptance testing on the spacecraft. At the conclusion of the acoustic tests the DFAT test equipment is removed and stored offline. Thermal Vacuum (TVAC) testing simulates the on-orbit environments and the Orion spacecraft design will be qualified at PBS using the TVAC chamber. A key innovation of the Orion test strategy for acceptance is performing the vacuum and temperature environmental testing separately at the O&C. Thermal environmental testing will be accomplished using a reconfigurable thermal chamber which can be erected for the test and dismantled and stored offline. Supporting fluids equipment for the thermal chamber is permanently located in the basement below the test position enabling the test floor location to be available for other operations. EM-1 acceptance testing results will be correlated to the qualification results from PBS chambers to validate the O&C acceptance test processes. This innovative acceptance test approach for the Orion spacecraft provides a validated test method for production that reduces program risk. Additionally, this approach avoids the duplication of test chambers in the O&C. As the Orion development program has evolved the vehicle designs and mission capabilities, the acceptance testing approaches have also matured establishing a seamless and low risk production and test capability at KSC to support future NASA Deep Space Gateway (DSG) exploration missions.",,"AIAA SPACE and Astronautics Forum and Exposition, SPACE 2017",2017-01-01,Conference Paper,"Garcia, Rafael;Harris, Richard F.;Koenig, William J.;See, Michael J.;Dobson, Jill M.;Norris, Scott",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-85084629552,10.3997/2214-4609.201802579,Integrated field surveys with complex of electroprospecting methods using broadband multifunction EM instruments,"In a number of cases, it is necessary to combine several methods during geological mapping and exploration projects. For hydrocarbon exploration these are MT-MVP, TDEM, FDEMS-IP, CSAMT, less often AMT, MT, MVP, DES-IP, TEM. It is difficult at times for a contractor to acquire various equipment sets and maintain software for processing, visualizing, analyzing and interpreting data. To overcome these difficulties, increase efficiency and productivity of the entire integrated electroprospecting complex, designed were 4-channel and 8-channel broadband multifunction EM instruments GEPARD including all the necessary sensors and accessories for field data acquisition, processing, editing and analysis of all ground EM methods. EM data acquisition system is complemented by low power portable multifunction current source for investigations with control source methods up to 200-300m. For deep investigations with a controlled source, other mid-range and high-power transmitters can be used. However, the main focus for the deep soundings is on successful integration of MT, AMT and MVP methods as the most geologically and economically effective for investigations in the 10-150000m depth interval. Positive experience of integrated EM surveys has been accumulated in North America, Asia and Africa using instruments adapted for both ground and marine EM data acquisition system applications.",,24th European Meeting of Environmental and Engineering Geophysics,2018-09-09,Conference Paper,"Ingerov, I.;Mendrii, I.;Lozoviy, A.",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-66749157215,10.3779/j.issn.1009-3419.2009.03.018,Kanglaite for treating advanced non-small-cell lung cancer: A systematic review,"Background and objective: In the past years, many reports on Kanglaite were publicated in China, researchers across the country. The aim of this study is to review the effectiveness and safety of Kanglaite for treating advanced non-small-cell lung cancer. Methods: Authors searched the Cochrane Library, Pubmed, Embase, Cancerlit, CBM, CNKI and VIP. Mannual and additional search were also conducted. All randomized controlled trials/quasi-RCT comparing Kanglaite with other lung cancer treatment were included. Two reviewers independently performed data extraction and appraised the publications using the Juni instrument, disagreements were resolved by consensus. Double data were entered and analyzed by RevMan 4.2 software are by Cochrane Collaboration. Results: Sixteen reports were included in the meta-analysis. The quality of 16 studies was low. Pooling data of 5 studies indicated that the effect of Kanglaite+NP (Vinorelbine+Cisplatin) was better than NP with RR 1.46, 95% Confidence Interval 1.13 to 1.91. Pooling data of 3 studies of MVP (Mitomycin+Vindsine+ Cisplatin) plus Kanglaite indicated that the effect was better with RR 1.84, 95%CI 1.22 to 2.76. Pooling data of 2 studies showed that the effect of GP (Gemcitabine+Cisplatin) plus Kanglaite was better than GP with RR 1.63, 95%CI 1.09 to 2.43. Fourteen studies revealed that Kanglaite may reduce the side-effect induced by regular treatment. Ten studies showed regular treatment plus Kanglaite can stabilite/improve quality of life. Conclusion: Kanglaite can enhance clinical effect of regular treatment, reduce side-effect and stabilite/improve quality of life, but the effect of Kanglaite being used in clinical settings needs to be confirmed by further large and multicenter.",Kanglaite | Lung neoplasms | Meta-analysis,Chinese Journal of Lung Cancer,2009-03-01,Review,"Zhu, Lina;Yang, Zhenjun;Wang, Shiyong;Tang, Yanming",Exclude,EC4
10.1016/j.infsof.2022.107144,2-s2.0-0020249224,,"LARGE SCALE INTEGRATION BASED, SIGNAL PROCESSOR - ITS APPLICATION AND POSSIBLE EVOLUTION.",,,Proceedings of SPIE - The International Society for Optical Engineering,1982-12-01,Conference Paper,"Harland, W. L.;Carvell, R.",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-84948136036,10.1145/2814346,Lean software development-building and shipping two versions,,,Communications of the ACM,2015-12-01,Article,"Matsudaira, Kate",Exclude,EC4
10.1016/j.infsof.2022.107144,2-s2.0-85082131270,,Left ventricle study via 3d full-volume and heart-model software in mitral valve prolapse with severe mitral regurgitation,"Background: Most patients with mitral valve prolapse (MVP) are asymptomatic with a normal life expectancy; however, between 5% and 10% of them have progression to severe mitral regurgitation (MR). Because of this silent progression, the size and ejection fraction of the left ventricle are very important in decision-making for surgery in asymptomatic patients with MR. A 3D assessment of LV volumes and ejection fraction is preferred to 2D echocardiography because of its accuracy and reproducibility. Methods: Between April 3, 2018, and February 20, 2019, the present study enrolled 50 patients suffering from MVP with relatively severe MR undergoing transesophageal echocardiography at Rajaie Cardiovascular, Medical, and Research Center, affiliated with Iran University of Medical Sciences. The ejection fraction was analyzed via the visual 2D method, in addition to 3 other methods: the Simpson biplane, 3D full volume, and 3D heart model. Results: Of the 4 measurement methods, the 3D heart model had the highest agreement with the Simpson biplane method (ICC: 0.859, 95% CI: 0.745 to 0.922). The agreement rate between the 3D heart model and the 3D full volume was 72% and between the 3D heart model and the visual 2D method was 64%. In the measurement of the end-diastolic volume, there was a remarkable agreement between the 3D heart model and both the Simpson biplane and 3D full-volume methods (98% and 95%, respectively). Similarly, in the measurement of the end-systolic volume, the rate of agreement between the 3D heart model and both the Simpson biplane and 3D full-volume methods was 91% and 92%, correspondingly. Conclusions: This study showed that the use of the 3D heart model and the Simpson biplane method was more accurate in the study of the left ventricular ejection fraction than that of the visual 2D and 3D full-volume methods. It appears that the use of all 3 methods (ie, the Simpson biplane, 3D full volume, and 3D heart model) in the measurement of the end-systolic and end-diastolic volumes is reliable.",3D echocardiography | Ejection fraction | Full volume | Heart model | Mitral regurgitation | Simpson,Iranian Heart Journal,2020-01-01,Article,"Fesharaki, Mehrdad Jafari;Alizadehasl, Azin;Mohammadi, Kamran;Ghadrdoost, Behshid",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-84973330658,10.1109/ICIP.2014.7025745,Linear adaptive search range model for uni-prediction and motion analysis for bi-prediction in HEVC,"High Efficiency Video Coding (HEVC) is the up-to-date video coding standard. Compared to the predecessor H.264/AVC, HEVC can further reduce approximately 50% bit rate on average with the competing perceptual quality. On the other hand, experiment shows that HEVC requires more than 4 times computational complexity during the encoding procedure. In ours test, even using fast TZSearch, integer motion estimation (IME) still accounts for 20%-30% of encoding time. In this paper, we propose two adaptive search range (ASR) algorithms to address this problem in IME. First, we present an ASR algorithm based on linear adaptive search range model (LAM-ASR) for uni-prediction. This model considers the impacts of the motion consistency, PU size and the amplitude of motion vector predictor (MVP). In order to offer more flexibility, we introduce a scale factor to this model. Second, for bi-prediction, we propose another ASR algorithm based on motion analysis (MA-ASR), which assigns different search range to PU by making full use of the motion information obtained from uni-prediction. Experimental results show that when embedded into the fast TZSearch method of the reference software, the two proposed ASR algorithms can averagely save 42.0% of the IME time with 0.023dB BD-PSNR degradation or equally 0.7% BD-BR increase.",adaptive search range (ASR) | HEVC | linear adaptive model | motion analysis | motion estimation (ME),"2014 IEEE International Conference on Image Processing, ICIP 2014",2014-01-28,Conference Paper,"Du, Longshan;Liu, Zhenyu;Ikenaga, Takeshi;Wang, Dongsheng",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-84937519886,10.1055/s-0035-1550146,Lip Forces and Chewing Efficiency in Children with Peripheral Facial Paralysis,"Peripheral facial paralysis is accompanied by facial motor disorders and also, by oral dysfunctions. The aim of this study was to evaluate the lip forces and chewing efficiency in a group of children with peripheral facial paralysis. The degree of peripheral facial paralysis in the study group (n = 11) was assessed using the House-Brackmann scale. The control group consisted of 21 children without facial nerve impairment. To assess lip forces, acrylic vestibular plates of three sizes were used: large (LVP), medium (MVP) and small (SVP). The lip force was recorded with a force transducer coupled with the data acquisition system. Masticatory efficiency was evaluated by the ability to mix two differently colored chewing gums. The images were processed with Adobe Photoshop CS3 (Delaware Corporation, San Jose, California, United States) and the number of pixels was quantified with the Image J software (DHHS/NIH/NIMH/RSB, Maryland, United States). For statistical analysis, the following statistical analysis were used: Pearson or Spearman correlation coefficient, multiple linear regression analysis, multiple logistic regression analysis, and optimal cutoff values for muscular dysfunction. There were statistically significant differences between lip forces in the following three groups: p = 0.01 (LVP), p = 0.01 (MVP), and p = 0.008 (SVP). The cutoff values of lip forces in the study group were as follows: 7.08 N (LVP), 4.89 N (MVP), and 4.24 N (SVP). There were no statistically significant differences between the masticatory efficiency in the two groups (p = 0.25). Lip forces were dependent on the degree of peripheral facial paralysis and age, but not on gender. In peripheral facial paralysis in children, a significant decrease of lip forces, but not masticatory efficiency, occurs.",chewing efficiency | facial palsy | facial paralysis | lip | mastication | measurement of lip force,Neuropediatrics,2015-05-14,Article,"Ilea, Aranka;Cristea, Alexandru;Dudescu, Cristian M.;Hurubeanu, Lucia;Vâjâean, Cosmin;Albu, Silviu;Câmpian, Radu S.",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-0023342758,,LOW-COST WAY TO GET VMEBUS IMAGE PROCESSING.,"A graphics board set combining image processing capabilities is presented. On-board processing elements such as the arithmetic logic unit and the statistical processor can be used to perform complex imaging taks - including area-of-interest processing, where selected rectangular areas of the image are singled out for processing. An optional neighborhood processor increases image-processing speed and adds functions, and state-of-the-art high-performance graphics hardware effectively and efficiently delivers the image of a color monitor. The complex real-time image-processing functions performed by the MVP-VME are achieved with software programs that assemble sophisticated operators out of the simple primitive operations performed by the hardware - a primary reason for the low cost of the MVP-VME.",,Electronics,1987-12-01,Article,"Manuel, Tom",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-38449093354,10.1007/s11307-007-0112-5,Magnetic resonance imaging based bone marrow segmentation for quantitative calculation of pure red marrow metabolism using 2-deoxy-2-[F-18]fluoro-d- glucose- positron emission tomography: A novel application with significant implications for combined structure-function approach,"Aims: The aim of this study was to introduce a new concept for accurate measurement of the global metabolic activity of the red marrow by combining segmented volumetric data from structural imaging techniques such as magnetic resonance imaging (MRI) and quantitative metabolic information provided by functional modalities such as positron emission tomography (PET). Materials and Methods: Imaging studies from five subjects who had undergone both MRI and 2-deoxy-2-[F-18]fluoro-d-glucose(FDG)-PET were selected for this analysis to test the feasibility of this approach. In none of the subjects, there were any marrow abnormalities as determined either by the MRI or by FDG-PET studies. The mean blood glucose level was 96∈±∈25 mg/dl. The first step was to calculate vertebral volume at L1, L3, and L5 from the available MRI studies. The red and yellow marrows were then segmented within the lumbar vertebrae using the 3DVIEWNIX software system from which the respective volumes were also calculated for each. This also allowed calculating the bone volume in each of the vertebral bodies examined. By employing the standard techniques, the mean of the maximum standardized uptake values (mean SUVmax) for the bone marrow were calculated in L1, L3 and L5 of the lumbar spine, and then global red marrow activity was calculated using the following approach: (1) Whole vertebral metabolic activity (WVMA)∈=∈vertebral volume∈×∈mean SUVmax of the entire marrow, (2) whole vertebral metabolic activity for yellow marrow (WVMAYM)∈=∈yellow marrow volume∈×∈mean SUVmax of fat (obtained from measurements of subcutaneous fat), (3) whole vertebral metabolic activity for red marrow (WVMARM)∈=∈WVMA - WVMAYM; and finally, (4) SUVmax for pure red marrow∈=∈whole vertebral metabolic activity for red marrow (WVMARM)/red marrow volume (obtained from the segmentation data). Results: The mean volume of the lumbar vertebral body was 15.6∈±∈1.4 cm3, the bone marrow mean SUVmax was 1.5∈±∈0.3, and the MVP for the lumbar vertebral body was 23.4∈±∈5.9. The mean volume of the yellow marrow in the lumbar vertebral body was 7.7∈±∈1.1 cm3, the yellow marrow mean SUVmax was estimated to be 0.38∈±∈0.1 and the MVP for the yellow marrow in the lumbar vertebral body was 2.9∈±∈0.9. The mean volume of the red marrow in lumbar vertebral body was 7. 9∈±∈1.1 cm3, the red marrow mean SUVmax was estimated to be 2.6∈±∈0.6, and the MVP for the red marrow in the lumbar vertebral body was 20.5∈±∈5.9. Conclusion: Estimation of the individual component of the bone marrow is plausible using medical image segmentation with combined structure-function approach. This can have potential research and clinical applications concerning the study of global metabolic activity of the individual component and diagnosis of benign and malignant bone marrow disorders. © 2007 Academy of Molecular Imaging.",Bone marrow | FDG-PET | Image segmentation | MRI | Red marrow,Molecular Imaging and Biology,2007-11-01,Article,"Basu, Sandip;Houseni, M.;Bural, G.;Chamroonat, W.;Udupa, J.;Mishra, S.;Alavi, Abass",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-84887278727,10.1145/2512349.2512803,Making 3D content accessible for teachers,"One of the primary goals of teaching is to prepare learners' for life in the real world. Given that we live in a three dimensional world educators must teach 3D concepts. As 3D content becomes increasingly available through the Internet, large display touch and tangible manipulation needs to make 3D manipulation simple and uncluttered to enable adoption in classrooms. We describe an iterative process with actual customers to create a commercial product for education. In the process we discover customer needs such as occlusion minimizing 3D rotation, scale, simpler mixed reality cube selection, hide and reveal features, and labelling. This application paper summarizes 36 weeks of hardware and software development. It illustrates the use of a lean start-up methodology to achieve a minimum viable product. We discuss some of the lessons learned from Genchi Genbutsu (i.e. Toyota method meaning go see for yourself) observations at several school visits as part of a technical trial deployment. © 2013 ACM.",3d labelling | 3d product development | customer needs | occlusion minimization | toyota method,ITS 2013 - Proceedings of the 2013 ACM International Conference on Interactive Tabletops and Surfaces,2013-01-01,Conference Paper,"Tse, Edward;Xin, Min;Antonyuk, Viktor;Lai, Henry;Hudson, Carl",Exclude,EC2
10.1016/j.infsof.2022.107144,2-s2.0-84944313801,10.1109/ISESE.2003.1237990,Management of interdependencies in collaborative software development,"In this paper we report results of an informal field study of a software development team conducted during an eight week internship at the NASA/Ames Research center. The team develops a suite tools called MVP, and is composed of 31 co-located software engineers, who design, test, document, and maintain the different MVP tools. We describe the formal and informal approaches used by this group to manage the interdependencies that occur during the software development process. Formal approaches emerge due to the needs of the developers. We also describe how the software development tools used by this team support these approaches and explore where explicit support is needed. Finally, based on our findings, we discuss implications for software engineering research.",Collaborative software | Design engineering | Maintenance engineering | NASA | Programming | Software design | Software development management | Software maintenance | Software testing | Software tools,"Proceedings - 2003 International Symposium on Empirical Software Engineering, ISESE 2003",2003-01-01,Conference Paper,"De Souza, C. R.B.;Redmiles, D.;Mark, G.;Penix, J.;Sierhuis, M.",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-85077497668,10.1109/TMAG.2019.2923535,Massively Parallel Computation for 3-D Nonlinear Finite Edge Element Problem with Transmission Line Decoupling Technique,"Transmission line method (TLM) has been used in 2-D scalar finite-element (FE) analysis due to its parallelism and constant admittance matrix. In this paper, the TLM is extended for the 3-D nonlinear vector FE problem that is more widely used for electromagnetic apparatus in practice. TLM is specially adapted for tetrahedron edge elements to calculate quasi-static electromagnetic field distribution for eddy current problems, and a dummy scalar gauge is applied to make the reduced magnetic vector FE formulation full-ranked and uniquely solvable by TLM. For each element, the nonlinearity is separated by transmission lines and only local small-scale Newton-Rapson iteration is needed, which is suitable for massive parallelization due to the independence between different elements. The TLM is implemented on a many-core GPU for a nonlinear FE power inductor case study, and the comparison of the results with a commercial FE software shows over 50 times speedup with a relative error of less than 2%.",3-D edge element | Coulomb gauge | eddy current | finite-element method (FEM) | nonlinear | reduced magnetic vector potential (MVP) | transmission line method (TLM),IEEE Transactions on Magnetics,2019-10-01,Article,"Li, Jiacong;Liu, Peng;DInavahi, Venkata",Include,IC1
10.1016/j.infsof.2022.107144,,,Mathematical-oriented programming,,,Computer,,Article,,Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-0027612734,10.1016/0950-5849(93)90012-R,Measurement-based guidance of software projects using explicit project plans,"As first steps towards establishing software engineering as an engineering discipline, we need to create explicit models of its building blocks, i.e., projects, processes, products, and various quality perspectives; organize these models for effective reuse across project boundaries, and establish measurable criteria for project guidance. The paper investigates the possibilities of providing measurement-based project guidance using explicit project plans. Following a summary of technologies developed by the process modelling and measurement subcommunities of software engineering, a method for integrating these technologies is suggested, and the potential benefits for project guidance are discussed. Examples from the MVP Project at the University of Kaiserslautern are used throughout for illustration purposes. © 1993.",explicit models | improvement-oriented engineering model | measurement | project guidance | project modelling,Information and Software Technology,1993-01-01,Article,"Lott, CM;Rombach, HD",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-85034435278,10.22038/ijbms.2017.9620,Mechanisms of spinal cord injury regeneration in zebrafish: A systematic review,"Objective(s): To determine the molecular and cellular mechanisms of spinal cord regeneration in zebrafish. Materials and Methods: Medical databases of PubMed and Scopus were searched with following key words: Zebrafish; spinal cord injuries; regeneration; recovery of function. The map of mechanisms was performed using Xmind software. Results: Wnt/ß-catenin signaling, L1.1, L1.2, Major vault protein (MVP), contactin-2 and High mobility group box1 (HMGB1) had positive promoting effects on axonal re-growth while Ptena had an inhibitory effect. Neurogenesis is stimulated by Wnt/ß-catenin signaling as well as HMGB1, but inhibited by Notch signaling. Glial cells proliferate in response to fibroblast growth factor (fgf) signaling and Lysophosphatidic acid (LPA). Furthermore, fgf signaling pathway causes glia bridge formation in favor of axonal regeneration. LPA and HMGB1 in acute phase stimulate inflammatory responses around injury and suppress regeneration. LPA also induces microglia activation and neuronal death in addition to glia cell proliferation, but prevents neurite sprouting. Conclusion: This study provides a comprehensive review of the known molecules and mechanisms in the current literature involved in the spinal cord injury (SCI) regeneration in zebrafish, in a time course manner. A better understanding of the whole determining mechanisms for the SCI regeneration should be considered as a main goal for future studies.",Regeneration recovery - of function | Spinal cord injuries | Spinal cord regeneration | Zebrafish,Iranian Journal of Basic Medical Sciences,2017-12-01,Review,"Noorimotlagh, Zeynab;Babaie, Mahla;Safdarian, Mahdi;Ghadiri, Tahereh;Rahimi-Movaghar, Vafa",Exclude,EC4
10.1016/j.infsof.2022.107144,2-s2.0-80053018985,10.1007/978-3-642-21393-9_7,Metric-probabilistic assessment of multi-version systems: Some models and techniques,"This chapter presents a set of models of multi-version systems and related techniques of diversity level and multi-version systems safety assessment. Spectrum of concepts related to common cause failure (CCF) is expanded, as well as models of multi-version systems (MVS) and multi-version projects (MVP). Approach to metric-probabilistic assessment is proposed and considered in the context of evaluating the software-based and FPGA-based MVS. Direct and indirect estimation of diversity with metrics are considered as parts of system safety or reliability assessment with relevant reliability models. Comparative analysis of the reliability of redundant multi-channel systems of different architectures with the option of diverse components is carried out. © 2011 Springer-Verlag Berlin Heidelberg.",,Advances in Intelligent and Soft Computing,2011-09-26,Article,"Kharchenko, Vyacheslav;Volkoviy, Andriy;Siora, Olexandr;Duzhyi, Vyacheslav",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-71549145984,10.1016/j.ijmedinf.2009.08.002,Millennium Global Village-Net: Bringing together Millennium Villages throughout sub-Saharan Africa,"The Millennium Villages Project (MVP), based at The Earth Institute at Columbia University, is a bottom-up, community led approach to show how villages in developing countries can get out of the poverty trap that afflicts more than a billion people worldwide. With well-targeted, practical inputs can help the community invest in a path leading to self-sustaining development. There are 80 Millennium Villages clustered in 10 countries throughout sub-Saharan Africa. MVP is an important development process for empowering communities to invest in a package of integrated interventions aiming to increase food production, improve access to safe water, health care, education and infrastructure. The process benefits from synergies of the integrated approach and relies on community leadership as empowered by proven technological inputs. MVP is committed to a science-based approach to assess and monitor the progress of the communities towards clear objectives; the Millennium Development Goals (MDGs) and to do so with mechanisms that are scalable and sustainable. This approach offers much more than simply collecting and analyzing data since the mechanism used for recording progress would provide a bridge over the divide which separates the haves and the have-nots (by facilitating the sharing of solutions from one community to another bidirectionally). By so doing, it allows people to enhance their own futures in a sustainable manner. Solutions found in one community are transferable to similar communities in other MVP villages. To achieve this goal, the MVP requires an information and communication system which can provide both necessary infrastructure for monitoring and evaluation, and tools for communicating among the villages, cities and countries. This system is called the Millennium Global Village-Net (MGV-Net). It takes advantage of the latest in open source software (OpenMRS), databases (MySQL), interface terminology, a centralized concept dictionary, and uses appropriate technology locally for data entry. © 2009 Elsevier Ireland Ltd. All rights reserved.",Electronic medical records | Medical terminology | Millennium Development Goals | Open source software (OpenMRS) | Primary health care,International Journal of Medical Informatics,2009-12-01,Article,"Kanter, Andrew S.;Negin, Joel;Olayo, Bernard;Bukachi, Frederick;Johnson, Edward;Sachs, Sonia Ehrlich",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-84971572004,10.1007/978-3-319-33515-5_10,Minimum viable product or multiple facet product? The role of MVP in software startups,"Minimum viable product (MVP) is the main focus of both business and product development activities in software startups. We empirically explored five early stage software startups to understand how MVP are used in early stages. Data was collected from interviews, observation and documents. We looked at the MVP usage from two angles, software prototyping and boundary spanning theory. We found that roles of MVPs in startups were not fully aware by entrepreneurs. Besides supporting validated learning, MVPs are used to facilitate product design, to bridge communication gaps and to facilitate cost-effective product development activities. Entrepreneurs should consider a systematic approach to fully explore the value of MVP, as a multiple facet product (MFP). The work also implies several research directions about prototyping practices and patterns in software startups.",Empirical study | Exploratory case study | MFP | MVP | Prototype | Software development | Software startups,Lecture Notes in Business Information Processing,2016-01-01,Conference Paper,"Duc, Anh Nguyen;Abrahamsson, Pekka",Include,Yes
10.1016/j.infsof.2022.107144,2-s2.0-85063565946,10.3390/fi11020050,Minimum viable products for internet of things applications: Common pitfalls and practices,"Internet of Things applications are not only the new opportunity for digital businesses but also a major driving force for the modification and creation of software systems in all industries and businesses. Compared to other types of software-intensive products, the development of Internet of Things applications lacks a systematic approach and guidelines. This paper aims at understanding the common practices and challenges among start-up companies who are developing Internet of Things products. A qualitative research is conducted with data from twelve semi-structured interviews. A thematic analysis reveals common types of Minimum Viable Products, prototyping techniques and production concerns among early stage hardware start-ups. We found that hardware start-ups go through an incremental prototyping process toward production. The progress associates with the transition from speed-focus to quality-focus. Hardware start-ups heavily rely on third-party vendors in term of development speed and final product quality. We identified 24 challenges related to management, requirement, design, implementation and testing. Internet of Things entrepreneurs should be aware of relevant pitfalls and managing both internal and external risks.",Case study | Hardware start-ups | Internet of Things applications | Minimum Viable Products | Prototyping,Future Internet,2019-01-01,Article,"Nguyen-Duc, Anh;Khalid, Khan;Bajwa, Sohaib Shahid;Lønnestad, Tor",Exclude,EC2
10.1016/j.infsof.2022.107144,2-s2.0-84906318206,,Mitral annular morphology in mitral valve disease with three-dimensional transesophageal echocardiography.,"Three-dimensional (3D) transesophageal echocardiography (TEE) is useful for the quantification of mitral valve structures. The study aim was to investigate, in quantitative manner, any differences in mitral valve anatomy among patients with mitral valve prolapse (MVP) or functional mitral regurgitation (FMR), compared to normal control subjects. 3D-TEE was performed in 20 MVP patients, 10 FMR patients and in 15 control subjects. Analyses of the full-volume 3D mitral valve data sets were performed offline, using Q-Lab software. Distinctive patterns were identified in annular geometric changes in normal subjects compared to patients with MVP or FMR. Patients with FMR showed significant annular anterior to posterior dilatation (34.6 +/- 8.3 mm versus 28.4 +/- 2.9 mm, p < 0.04: FMR versus control), whereas in patients with MVP dilatation in the anterolateral to posteromedial diameter was more prominent (41.0 +/- 5.9 mm versus 36.6 +/- 2.4 mm, p < 0.03; MVP versus control). 3D-TEE represents a useful method for the evaluation of mitral valve geometry.",,The Journal of heart valve disease,2014-01-01,Article,"Tani, Tomoko;Kawai, Junichi;Kitai, Takeshi;Kim, Kitae;Okada, Yukikatsu;Kita, Toru;Furukawa, Yutaka",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-85037851614,10.1007/978-3-319-64719-7_8,Model-to-model transformation in approach by modeling to generate a RIA model with GWT,"The continuing evolution of business needs and technology makes Web applications more demanding in terms of development, usability and interactivity of their user interfaces. The complexity and diversity of these applications emerges the need of flexibility and combining operations with existing models to create other new, more complex models. As more complex models are used, the importance of transformations between models grows. This paper presents the application of the MDA (Model Driven Architecture) to generate, from the UML model, the code following the MVP (Model-View-Presenter), DI (Dependency Injection) and DAO (Data Access Object) patterns for a RIA (Rich Internet Application) using the standard MOF 2.0 QVT (Meta-Object Facility 2.0 Query-View-Transformation) as a transformation language. We adopt GWT (Google web Toolkit), Spring and Hibernate as a Frameworks for creating a target meta-model to generate an entire GWT-based N-Layers web application. That is why we have developed two meta-models handling UML class diagrams and N-Layers Web applications, then we have to set up transformation rules. The transformation rules defined in this paper can generate, from the class diagram, an XML file containing the Presentation, the Business, and the Data Access package. This file can be used to generate the necessary code of a RIA N-Layers web application.",GWT | Model Transformation | Model View Presenter | N-Layers | QVT | RIA,Advances in Intelligent Systems and Computing,2018-01-01,Conference Paper,"Esbai, Redouane;Erramdani, Mohammed;Elotmani, Fouad;Atounti, Mohamed",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-84979743573,10.1109/WICT.2015.7489648,Model-to-model transformation in approach by modeling: From UML model to Model-View-Presenter and Dependency Injection patterns,"The continuing evolution of business needs and technology makes Web applications more demanding in terms of development, usability and interactivity of their user interfaces. The complexity and diversity of these applications emerges the need of flexibility and combining operations with existing models to create other new, more complex models. As more complex models are used, the importance of transformations between models grows. This paper presents the application of the MDA (Model Driven Architecture) to generate, from the UML model, the code following the MVP (Model-View-Presenter), DI (Dependency Injection) and DAO (Data Access Object) patterns for a RIA (Rich Internet Application) using the standard MOF 2.0 QVT (Meta-Object Facility 2.0 Query-View-Transformation) as a transformation language. We adopt GWT (Google web Toolkit), Spring and Hibernate as a Frameworks for creating a target meta-model to generate an entire GWT-based N-tiers web application. That is why we have developed two meta-models handling UML class diagrams and N-tiers Web applications, then we have to set up transformation rules. The transformation rules defined in this paper can generate, from the class diagram, an XML file containing the Presentation, the Business, and the Data Access package. This file can be used to generate the necessary code of a RIA N-tiers web application.",dependency Injection | GWT | Model Transformation | Model View Presenter | MOF 2.0 QVT | transformation rules,"Proceedings of the 2015 5th World Congress on Information and Communication Technologies, WICT 2015",2016-06-10,Conference Paper,"Esbai, Redouane;Erramdani, Mohammed",Include,IC1
10.1016/j.infsof.2022.107144,,,Modular Voice Processor,,,Proceedings - IEEE Military Communications Conference,,Conference Paper,,Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-85065488929,10.1109/ENBENG.2019.8692461,Monitoring system for emergency service in a hospital environment,"The hospital emergency service remains the first choice for the vast majority of patients. The large influx of hospital emergency services, combined with the lack of health professionals, often makes the patients susceptible to excessive waiting times. As a result, their health condition may worse after triage, until they are observed by a doctor. In the developed prototype, a bracelet is placed on the patient's wrist, which reads their vital signs, accompanied by a mobile phone with an Android application, designed to send the collected vital signs data, as well as patient's location, periodically, to a server. There is a database, with the information of all patients under care and, through a dashboard, the interface is made with the health professionals. Such interface alerts the professional whenever a situation is considered critical. The prototype was positively evaluated by the usability tests carried out and could be considered a Minimum Viable Product in the business perspective.",,"6th IEEE Portuguese Meeting on Bioengineering, ENBENG 2019 - Proceedings",2019-04-15,Conference Paper,"Reis, A.;Coutinho, F.;Ferreira, J.;Tonelo, C.;Ferreira, L.;Quintas, J.",Include,Yes
10.1016/j.infsof.2022.107144,2-s2.0-85082792753,10.1093/gigascience/giaa025,Multi-omics Visualization Platform: An extensible Galaxy plug-in for multi-omics data visualization and exploration,"Background: Proteogenomics integrates genomics, transcriptomics, and mass spectrometry (MS)-based proteomics data to identify novel protein sequences arising from gene and transcript sequence variants. Proteogenomic data analysis requires integration of disparate 'omic software tools, as well as customized tools to view and interpret results. The flexible Galaxy platform has proven valuable for proteogenomic data analysis. Here, we describe a novel Multi-omics Visualization Platform (MVP) for organizing, visualizing, and exploring proteogenomic results, adding a critically needed tool for data exploration and interpretation. Findings: MVP is built as an HTML Galaxy plug-in, primarily based on JavaScript. Via the Galaxy API, MVP uses SQLite databases as input - a custom data type (mzSQLite) containing MS-based peptide identification information, a variant annotation table, and a coding sequence table. Users can interactively filter identified peptides based on sequence and data quality metrics, view annotated peptide MS data, and visualize protein-level information, along with genomic coordinates. Peptides that pass the user-defined thresholds can be sent back to Galaxy via the API for further analysis; processed data and visualizations can also be saved and shared. MVP leverages the Integrated Genomics Viewer JavaScript framework, enabling interactive visualization of peptides and corresponding transcript and genomic coding information within the MVP interface. Conclusions: MVP provides a powerful, extensible platform for automated, interactive visualization of proteogenomic results within the Galaxy environment, adding a unique and critically needed tool for empowering exploration and interpretation of results. The platform is extensible, providing a basis for further development of new functionalities for proteogenomic data visualization.",Galaxy | Integrated Genomics Viewer | mass spectrometry | proteogenomics | proteomics | RNA-Seq | transcriptomics | visualization,GigaScience,2020-04-06,Article,"Mcgowan, Thomas;Johnson, James E.;Kumar, Praveen;Sajulga, Ray;Mehta, Subina;Jagtap, Pratik D.;Griffin, Timothy J.",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-85049094619,10.1016/j.patrec.2018.06.022,Multi-view predictive latent space learning,"In unsupervised circumstances, multi-view learning seeks a shared latent representation by taking the consensus and complementary principles into account. However, most existing multi-view unsupervised learning approaches do not explicitly lay stress on the predictability of the latent space. In this paper, we propose a novel multi-view predictive latent space learning (MVP) model and apply it to multi-view clustering and unsupervised dimension reduction. The latent space is forced to be predictive by maximizing the correlation between the latent space and feature space of each view. By learning a multi-view graph with adaptive view-weight learning, MVP effectively combines the complementary information from multi-view data. Experimental results on benchmark datasets show that MVP outperforms the state-of-the-art multi-view clustering and unsupervised dimension reduction algorithms.",Multi-view learning | Predictive latent space learning | Unsupervised clustering | Unsupervised dimension reduction,Pattern Recognition Letters,2020-04-01,Article,"Yuan, Jirui;Gao, Ke;Zhu, Pengfei;Egiazarian, Karen",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-0036923282,,Multi-viewpoint clustering analysis (MVP-CA) tool,The demonstration of a semi-automated Multi-ViewPoint-Clustering Analysis (MVP-CA) tool was presented. The clustering of a knowledge base (KB) into related rule sets by the MCP-CA allowed the user to comprehend the KB in terms of the clusters of rules which were conceptually meaningful. The aid provided by the tool to the knowledge engineers and subject matter experts in managing the KB for its maximum utilization was also discussed.,,Proceedings of the National Conference on Artificial Intelligence,2002-12-01,Conference Paper,"Mehrotra, Mala;Bobrovnikoff, Dmitri",Include,IC1
10.1016/j.infsof.2022.107144,,,Multimedia teaching software in university education [Multimediální výukový program (MVP) ve vzdelávání na vysokých skolách.],,,"Acta medica (Hradec Králové). Supplementum Universitas Carolina, Facultas Medica Hradec Králové",,Article,,Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-85097009712,10.1074/mcp.RA120.002345,Mutation-independent Proteomic Signatures of Pathological Progression in Murine Models of Duchenne Muscular Dystrophy,"The absence of the dystrophin protein in Duchenne muscular dystrophy (DMD) results in myofiber fragility and a plethora of downstream secondary pathologies. Although a variety of experimental therapies are in development, achieving effective treatments for DMD remains exceptionally challenging, not least because the pathological consequences of dystrophin loss are incompletely understood. Here we have performed proteome profiling in tibialis anterior muscles from two murine DMD models (mdx and mdx52) at three ages (8, 16, and 80 weeks of age), all n = 3. High-resolution isoelectric focusing liquid chromatography-tandem MS (HiRIEF-LC–MS/MS) was used to quantify the expression of 4974 proteins across all 27 samples. The two dystrophic models were found to be highly similar, whereas multiple proteins were differentially expressed relative to WT (C57BL/6) controls at each age. Furthermore, 1795 proteins were differentially expressed when samples were pooled across ages and dystrophic strains. These included numerous proteins associated with the extracellular matrix and muscle function that have not been reported previously. Pathway analysis revealed multiple perturbed pathways and predicted upstream regulators, which together are indicative of cross-talk between inflammatory, metabolic, and muscle growth pathways (e.g. TNF, INFg, NF-kB, SIRT1, AMPK, PGC-1a, PPARs, ILK, and AKT/PI3K). Upregulation of CAV3, MVP and PAK1 protein expression was validated in dystrophic muscle by Western blot. Furthermore, MVP was upregulated during, but not required for, the differentiation of C2C12 myoblasts suggesting that this protein may affect muscle regeneration. This study provides novel insights into mutation-independent proteomic signatures characteristic of the dystrophic phenotype and its progression with aging.",,Molecular and Cellular Proteomics,2020-12-01,Article,"van Westering, Tirsa L.E.;Johansson, Henrik J.;Hanson, Britt;Coenen-Stass, Anna M.L.;Lomonosova, Yulia;Tanihata, Jun;Motohashi, Norio;Yokota, Toshifumi;Takeda, Shin'ichi;Lehtiö, Janne;Wood, Matthew J.A.;Andaloussi, Samir E.L.;Aoki, Yoshitsugu;Roberts, Thomas C.",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-85020498214,10.1002/2211-5463.12247,mvp – an open-source preprocessor for cleaning duplicate records and missing values in mass spectrometry data,"Mass spectrometry (MS) data are used to analyze biological phenomena based on chemical species. However, these data often contain unexpected duplicate records and missing values due to technical or biological factors. These ‘dirty data’ problems increase the difficulty of performing MS analyses because they lead to performance degradation when statistical or machine-learning tests are applied to the data. Thus, we have developed missing values preprocessor (mvp), an open-source software for preprocessing data that might include duplicate records and missing values. mvp uses the property of MS data in which identical chemical species present the same or similar values for key identifiers, such as the mass-to-charge ratio and intensity signal, and forms cliques via graph theory to process dirty data. We evaluated the validity of the mvp process via quantitative and qualitative analyses and compared the results from a statistical test that analyzed the original and mvp-applied data. This analysis showed that using mvp reduces problems associated with duplicate records and missing values. We also examined the effects of using unprocessed data in statistical tests and examined the improved statistical test results obtained with data preprocessed using mvp.",dirty data | duplicate record | mass spectrometry | missing value | MS data preprocessor | R package,FEBS Open Bio,2017-07-01,Article,"Lee, Geunho;Lee, Hyun Beom;Jung, Byung Hwa;Nam, Hojung",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-85096623676,10.1109/SEAA51224.2020.00060,MVP and experimentation in software startups: A qualitative survey,"The Lean Startup methodology disseminated the concept of MVP. Since then, the term has been used in several contexts aside startups with a blur definition. Practitioners name several artifacts as MVPs, such as prototypes or initial versions of a new product, rather than an instrument for experimentation. Given the importance of experimentation to the success rate of software startups, it is essential to understand if the experimentation element is still present in practitioners' understanding of the term and how they applied MVPs. To achieve this objective, we performed a survey with practitioners and coded their answers according to aspects found in a systematic mapping study on MVP. Our results indicate that MVP is mostly associated with the ideas of a product version and customer value rather than hypothesis testing and learning processes. Additionally, those respondents that focused on the first related group of terms did not give experiments as examples of MVP. In contrast, the opposite happened to those that used the second group.",experiment-driven software development | experimentation | minimum viable product | software startups,"Proceedings - 46th Euromicro Conference on Software Engineering and Advanced Applications, SEAA 2020",2020-08-01,Conference Paper,"Melegati, Jorge;Chanin, Rafael;Sales, Afonso;Prikladnicki, Rafael;Wang, Xiaofeng",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-85096860974,10.1109/CICN49253.2020.9242573,MVP Architecture Model with Single Endpoint Access for Displaying COVID 19 Patients Information Dynamically,"The use of Model View Presenter (MVP) architecture for tracking the data of COVID 19 patients has evolved novel innovation in the already existing architectural diagram used by the software industry. It introduced the use of GraphQL a very efficient backend framework providing dynamic and single-point access to queries made by the user. In contrary to the traditional REST API which uses GET and POST methods for fetching and posting data requiring a different URL for every API call, with GraphQL we can have single-point access. This paper aims to propose a simple backend driven dynamic cards model that can get data from real-world findings of patients' database by trusted sources and freely available research enabling the user of this application to get valuable information of its region, country and the globe and how exposed and vulnerable they are, all of this in a single application of its first type.",API | database | dynamic | GraphQL | MVP | REST,"Proceedings - 2020 12th International Conference on Computational Intelligence and Communication Networks, CICN 2020",2020-09-25,Conference Paper,"Singh, Akansha;Jeyanthi, N.",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-72949093780,,MVP CAST gauge optimizes seismic and hydrographic operations,"The ODIM Moving Vessel Profiler™ (MVP) allows for conductivity, temperature, depth (CTD) data to be logged in preparation for submission to onboard production systems during. The launch of the ODIM Moving Vessel Profiler™ (MVP) has demonstrated that sound speed profiles can be collected at a high spatial and temporal resolution while the survey vessel is under way. An MVP Computer-Assisted Sound Speed Technology (CAST) gauge has been developed as a means of visually displaying and quantifying the results of sequential real-time CTD casts. The software behind the MVP CAST gauge has been developed to optimize operational cost and to monitor and maintain accuracy. The CAST gauge integrates the concept of computing and visualizing sound speed uncertainty by comparing ray path analysis from one epoch to the next and displaying this result in real time.",,Sea Technology,2009-10-01,Article,"Peyton, Derrick R.;Smith, Mark",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-85076127553,10.1007/978-3-030-33742-1_33,MVP development process for software startups,"This paper presents a proposal of a Minimal Viable Development Process for Software Startups that can be used during the MVP development process. Defining a methodology is a major challenge for startups because they are creative, flexible, and reluctant to include bureaucratic measures in their day-to-day procedures that may disrupt their natural attributes. Thus, to make the process simple, we defined it in 3 main phases: requirements gathering, software development, and market validation.",MVP | Process development | Software engineering | Software startup,Lecture Notes in Business Information Processing,2019-01-01,Conference Paper,"Pompermaier, Leandro;Chanin, Rafael;Sales, Afonso;Prikladnicki, Rafael",Include,Yes
10.1016/j.infsof.2022.107144,2-s2.0-85018685711,10.1109/SEAA.2016.56,MVP Explained: A Systematic Mapping Study on the Definitions of Minimal Viable Product,"Context: One of the most important steps of the Lean Startupmethodology is the definition of Minimum Viable Product (MVP), needed to start the learning process by integrating the early adopters' feedbacks as soon as possible. Objective: This study aims at identifying the common definitions of MVP proposed and the key factors identified to help entrepreneurs efficiently define their MVP, reducing errors due to unconsidered unknown factors. Method: We identified the MVP definitions and key factors by means of a systematic mapping study, defining the research questions and the protocol to be used. We selected the bibliographic sources, the keywords, and the selection criteria for searching the relevant papers. Results: We found 97 articles and, through inclusion and exclusion criteria, removed 75 articles, which reduced the total to 22 at the end of the process. The results are a classification schema for characterizing the definition of Minimum Viable Product in Lean Startups and a set of common key factors identified in the MVP definitions. Conclusion: The identified key factors are related to technical characteristics of the product as well as market and customer aspects. We found a positive improvement of the state of the art of MVP and the definition of Minimum.",Entrepreneurship | Lean Startup | Minimum Viable Product | Startup,"Proceedings - 42nd Euromicro Conference on Software Engineering and Advanced Applications, SEAA 2016",2016-10-14,Conference Paper,"Lenarduzzi, Valentina;Taibi, Davide",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-85041821388,10.1016/j.humpath.2017.12.020,MVP immunohistochemistry is a useful adjunct in distinguishing leiomyosarcoma from leiomyoma and leiomyoma with bizarre nuclei,"Morphologically, distinguishing between leiomyoma (LM) and leiomyosarcoma (LMS) is not always straightforward, especially with benign variants such as bizarre leiomyoma (BLM). To identify potential markers of malignancy in uterine smooth muscle tumors, proteomic studies were performed followed by assessment of protein expression by immunohistochemistry. Archival formalin-fixed, paraffin-embedded tissues from tumors (n = 23) diagnosed as LM, BLM, and LMS (using published criteria) were selected for the study. Sequential window acquisition of all theoretical fragment ion spectra mass spectrometry was applied to pooled samples of formalin-fixed, paraffin-embedded LM and LMS tumor tissue to assay the relative protein quantities and look for expression patterns differentiating the 2 tumor types. A total of 592 proteins were quantified, and 10 proteins were differentially expressed between LM and LMS. Select proteins were chosen for evaluation by immunohistochemistry (IHC) based on antibody availability and biologic relevance in the literature. IHC was performed on a tissue microarray, and intensity was evaluated using imaging software. Major vault protein (MVP) and catechol O-methyltransferase had 3.05 and 13.94 times higher expression in LMS relative to LM by sequential window acquisition of all theoretical fragment ion spectra mass spectrometry, respectively. By IHC, MVP (clone 1014; Santa Cruz Biotechnology, Dallas, TX) was found to be 50% sensitive and 100% specific when comparing LMS to LM. Catechol O-methyltransferase (clone FL-271; Santa Cruz Biotechnology) had a sensitivity of 38% and a specificity of 88%. Six of 7 BLM had expression of MVP similar to LM. Immunohistochemical staining for MVP is a useful adjunct in distinguishing LMS from LM and BLM in difficult cases.",Bizarre leiomyoma | Leiomyoma | Leiomyosarcoma | Major vault protein (MVP) | Mass Spectrometry,Human Pathology,2018-03-01,Article,"Lintel, Nicholas J.;Luebker, Stephen A.;Lele, Subodh M.;Koepsell, Scott A.",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-84862574063,,Mvp osm: A tool to identify areas of high quality contributor activity in openstreetmap,"OpenStreetMap's success continues to grow and contributions are not limited to the collection of spatial data using GPS (Global Positioning System) equipment. A very wide range of software tools developed by, and available to, the OSM community means that at present, anyone can also make a contribution through, for example, tracing aerial imagery, directly importing data, or by adding spatial information retrieved from smartphones. Consequently 'the map'has become increasingly rich, but the quality of the data is very often questioned and comes under scrutiny from the GIS and LBS (Location-Based Services) communities. By examining the world map generated from OpenStreetMap, it is relatively easy to identify areas which are more or less well supported in community mapping activities; a very high level of spatial detail in certain areas can indicate the quality of OSM data. MVP OSM is a software tool designed to highlight areas in OpensStreetMap where users (contributors) are dedicated to providing high levels of spatial detail. This usually correlates with the use of a GPS and on-the-ground mapping, or, at the very least, a deep local knowledge of the area and an inherent desire to see it represented in the highest level of detail on OpenStreetMap. The input to MVP OSM is an OSM XML file, which is converted by Python into a file for spatialite (the GIS extension for sqlite). Within spatialite the data is processed to create clusters and using these spatial clusters, the tool can then derive the activity of single or multiple users in that area. Vector layers and heatmaps are generated as output that can be overlaidd onto OSM maps. A high level of detail can be considered a good indicator of the quality of OSM data within a given area. The MVP OSM tool hides the details of OSM XML processing, which many researchers find difficult, and processes the data to produce very useful visualizations of contributor activity in any given OSM area.",Crowdsourcing | Data quality | GIS | OpenStreetMap | Volunteered geographic information,Bulletin of the Society of Cartographers,2011-12-01,Article,"Napolitano, Maurizio;Mooney, Peter",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-0242410217,,MVP series: Part III,"A new, four-part Machine Vision Professional (MVP) series began in 2003 with new challenges for machine vision professionals to test their knowledge of machine vision technology and applications. A large number of machine vision applications require the fine-tuned algorithms, along with intuitive GUIs and powerful area and edge-based search engines. The need for the Machine Vision Professional (MVP) to learn all the tools is expanding daily.",,Advanced Imaging,2002-12-01,Review,"Yencharis, Len",Exclude,EC4
10.1016/j.infsof.2022.107144,2-s2.0-33846593907,10.1109/HLDVT.2005.1568809,MVP: A mutation-based validation paradigm,"A mutation-based validation paradigm that can handle complete high-level microprocessor implementations is presented. First, a control-based coverage measure is presented that is aimed at exposing design errors that incorrectly set control signal values. A method of automatically generating a complete set of modeled errors from this coverage metric is presented such that the instantiated modeled errors harness the rules of cause-and-effect that define mutation-based error models. Finally, we introduce a new automatic test pattern generation technique for high-level hardware descriptions that solves multiple concurrent constraints and is empowered by concurrent programming. © 2005 IEEE.",,"Proceedings - IEEE International High-Level Design Validation and Test Workshop, HLDVT",2005-12-01,Conference Paper,"Campos, Jorge;Al-Asaad, Hussain",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-85086222756,10.1088/1757-899X/830/2/022088,Optimization of financial technology (fintech) with lean UX development methods in helping technical vocational education and training financial management,"The effectiveness and optimization of financial services is one of the things that happens when there is financial technology or fintech. Various fintech services have a strategy to attract customers. One of the strategies is to offer promos to potential customers or early customers. Promos given to customers will provide maximum benefits when they use accurate type of promo on a promo provided by fintech services. Knowledge of various fintech services and a lot of promo information will provide an effective alternative for customers to use promos. For this reason, applications or software have been developed to provide information on various e-money and e-wallet services and promos. The method used is Lean UX which consists of 4 stages namely declare assumpts, Develop MVP, run experiments, feedback and user research. The result obtained on this research is a mobile androide application that can display fintech and promo information. Lean UX development is done with 2 iterations and produces features that are validly needed by the user but still need development in terms of User Experience.",,IOP Conference Series: Materials Science and Engineering,2020-05-18,Conference Paper,"Hendriadi, A. A.;Primajaya, A.",Include,Yes
10.1016/j.infsof.2022.107144,2-s2.0-85027009335,10.14257/ijgdc.2016.9.6.18,Patterns for development of windows form applications and web applications,"Design pattern is a mechanism to show experience in object-oriented design, as well as an appropriate solution which has been provided by experts for particular problems and which can be used over and over throughout the design. Using design patterns helps improve software quality and reusability. There are different patterns for development of data source (database, file, array, etc.) systems but most of them have features that are not appropriate for code generation. We seek in this research new patterns for development of data source systems that can accelerate the development of such systems and reduce costs and are appropriate for code generation as well. This article deals with challenges related to prototype, singleton and MV* (MVC, MVP, MVVM) patterns. As a solution, we will propose two patterns called MVC+ and MVC++ as well as a tool called LCG for code generation. We compare the proposed patterns with similar patterns in terms of efficiency. MVC+ and MVC++ are appropriate for model-driven architecture, code generation and the development of windows form applications and web applications.",Code generation | Design pattern | Model-driven architecture | MV* | MVC+ | MVC++,International Journal of Grid and Distributed Computing,2016-01-01,Article,"Lotfi, Rahim",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-0030835182,10.1109/4434.580452,Performance analysis and tuining for a single-chip multiprocessor DSP,"To achievemaximum performance, single-chip multiprocessor DSPs require a sophisticated performance-monitoring tool such as the MVP Performance Monitor. Using the MPM, programmers can easily and efficiently analyze and optimize DSP applications.",,IEEE Concurrency,1997-01-01,Article,"Kim, Jihong;Kim, Yongmin",Include,IC1
10.1016/j.infsof.2022.107144,,,Phonocardiography-based mitral valve prolapse detection using an artificial neural network [Fonokardiografska detekcija prolapsa mitralne valvule upotrebom arteficijalne neuronske mreže],,,Serbian Journal of Experimental and Clinical Research,,Article,,Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-79952984793,10.1017/S0959270910000183,"Population viability analysis and conservation of Chinese Grouse Bonasa sewerzowi in Lianhuashan Nature Reserve, north-west China","Chinese Grouse Bonasa sewerzowi is threatened by human activity, especially during the breeding season, in the Lianhuashan Mountains, Gansu Province, north-western China. We conducted a series of simulations on the viability of this population using the computer program VORTEX. The simulations suggested that the population had an extinction probability of 17% in 100 years using data gathered from current field work. Sensitivity analysis revealed that the predicted population trend was most sensitive to chick mortality, offspring per female per year, and adult male mortality. The first two parameters are correlated with human activity such as nest loss due to egg collecting by local people. When we set initial population size to the same size as carrying capacity, 2,500 individuals would constitute a minimum viable population (MVP). This would require a forest area of about 3,780 ha, which is smaller than the size of the Lianhuashan reserve, but the current population does not constitute an MVP due to the small initial population size. Furthermore, we found that if chick mortality declined by 5% or the number of offspring produced per female increased by 5% (i.e. reducing nest loss) under the current situation, local reserve size and current population would constitute an MVP. Therefore, the most practical and simple conservation management tool would be to increase the breeding success of Chinese Grouse, especially by limiting human activity during the incubation period. © 2010 BirdLife International.",,Bird Conservation International,2011-03-01,Article,"Lu, Nan;Sun, Yue Hua",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-85042378018,10.1109/ESEM.2017.20,Predicting the Vector Impact of Change-An Industrial Case Study at Brightsquid,"Background: Understanding and controlling the impact of change decides about the success or failure of evolving products. The problem magnifies for start-ups operating with limited resources. Their usual focus is on Minimum Viable Product (MVP's) providing specialized functionality, thus have little expense available for handling changes. Aims: Change Impact Analysis (CIA) refers to the identification of source code files impacted when implementing a change request. We extend this question to predict not only affected files, but also the effort needed for implementing the change, and the duration necessary for that. Method: This study evaluates the performance of three textual similarity techniques for CIA based on Bag of words in combination with either topic modeling or file coupling. Results: The approaches are applied on data from two industrial projects. The data comes as part of an industrial collaboration project with Brightsquid, a Canadian start-up company specializing in secure communication solutions. Performance analysis shows that combining textual similarity with file coupling improves impact prediction, resulting in Recall of 67%. Effort and duration can be predicted with 84% and 72% accuracy using textual similarity only. Conclusions: The relative effort invested into CIA for predicting impacted files can be reduced by extending its applicability to multiple dimensions which include impacted files, effort, and duration.",Bag of Words | Case Study | Change Impact Analysis | Effort estimation | Software Repository | Topic Modeling,International Symposium on Empirical Software Engineering and Measurement,2017-12-07,Conference Paper,"Kabeer, Shaikh Jeeshan;Nayebi, Maleknaz;Ruhe, Guenther;Carlson, Chris;Chew, Francis",Include,Yes
10.1016/j.infsof.2022.107144,2-s2.0-34247556653,10.1109/AGILE.2006.43,Presenter first: Organizing complex GUI applications for test-driven development,"Presenter First (PF) is a technique for organizing source code and development activities to produce fully tested GUI applications from customer stories using test-driven development. The three elements of Presenter First are a strategy for how applications are developed and tested, a variant on the Model View Presenter (MVP) design pattern, and a particular means of composing MVP triads. Presenter tests provide an economical alternative to automated GUI system tests. We have used Presenter First on projects ranging in size from several to a hundred MVP triads. This paper describes MVP creation, composition, scaling, and the tools and process we use. An example C# application illustrates the application of the Presenter First technique. © 2006 IEEE.",,"Proceedings - AGILE Conference, 2006",2006-01-01,Conference Paper,"Alles, Micah;Crosby, David;Erickson, Carl;Harleton, Brian;Marsiglia, Michael;Pattison, Greg;Stienstra, Curt",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-85020724609,,"Proceedings - 42nd Euromicro Conference on Software Engineering and Advanced Applications, SEAA 2016","The proceedings contain 53 papers. The topics discussed include: supporting feature estimation with risk and effort annotations; towards guidelines for preventing critical requirements engineering problems; busting software architecture beliefs: a survey on success factors in architecture decision making; technical debt management with genetic algorithms; evidence-based timelines for user experience software process improvement retrospectives; identifying developers' expertise in social coding platforms; continuous, lean, and wasteless: minimizing lead time from development done to production use; implementing continuous customer care: first-hand experiences from an industrial setting; estimating and quantifying the benefits of refactoring to improve a component modularity: a case study; a case study on the utilization of problem and solution domain measures for software size estimation; MVP explained: a systematic mapping study on the definitions of minimal viable product; product innovation through internal startup in large software companies: a case study; systematic mapping study of dealing with error in software development effort estimation; Bayesian synthesis for knowledge translation in software engineering: method and illustration; a property model ontology; handling uncertainty in automatically generated implementation models in the automotive domain; and literature review of empirical research studies within the domain of acceptance testing.",,"Proceedings - 42nd Euromicro Conference on Software Engineering and Advanced Applications, SEAA 2016",2016-10-14,Conference Review,,Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-84949228413,10.1007/3-540-59205-9_36,Process-based software risk assessment,"Analyzing software process models to predict the behavior of software processes helps in planning and enacting software projects. Since software process models can capture the key information that is necessary to assess proeessrelated risks, this paper discusses how approaches for software process analysis may be applied to software risk assessment. A characterization scheme for process analysis approaches is stated based on a set of necessary risk assessment requirements. Existing analysis approaches are evaluated with respect to the characterization scheme. Proceeding from this evaluation, an approach to software process analysis is proposed that is specifically tailored to software risk assessment. This analysis approach takes advantage of a wide range of information by integrating empirically validated models. It is also shown how this approach fits into the context of the MVP (multi-view processes) project at the University of Kaiserslautem.",MVP project | Processbased risk assessment | Risk analysis | Software process analysis | Survey of software process analysis approaches,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),1995-01-01,Conference Paper,"Bröckers, Alfred",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-84947252069,10.3997/2214-4609.201412360,Processing of MT/MV data on the Dovzhanka-Buz'ke profile,"The results of MTS and MVP field research were processed using the PRC-MTMV software and the transfer operators in a wide range of periods were obtained. Their pseudosections allow to qualitatively assess the electrical conductivity along the profile. Anomalous areas, mostly coinciding with the deep fault zones of the Ukrainian Shield (Podilska, Talnovska, Gvozdavska, Vradiyvska and Pervomayska) were allocated.",,"14th EAGE International Conference on Geoinformatics - Theoretical and Applied Aspects, Geoinformatics 2015",2015-01-01,Conference Paper,"Shyrkov, B.;Kushnir, A.;Usenko, A.",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-85050513240,10.23919/i-Society.2017.8354664,Product innovation with scrum: A longitudinal case study,"This paper describes the innovation processes used in a partnership between a company that provides asset integrity and maintenance management consulting services in the energy sector and a university. The challenge faced by the company is to make their in-house expertise more readily available to a worldwide audience. A longitudinal embedded case study has been used to investigate how installable desktop software applications have been redesigned to create a new set of cloud hosted software services. The innovation team adapted an agile scrum process to include exploratory prototyping and manage the geographical distribution of the team members. A minimum viable product was developed that integrated functional elements of previous software tools into an end-to-end data collection, analysis and visualisation product called AimHi which uses a cloud-hosted web services approach. The paper illustrates how the scrum software development method was tailored for a product innovation context. Extended periods of evaluation and reflection (field trials), prototyping and requirement refinement were combined with periods of incremental feature development using sprints. The AimHi product emerged from a technology transfer and innovation project that has successfully reconciled conflicting demands from customers, universities, partner companies and project staff members.",innovation process | knowledge transfer partnership | minimum viable product | scrum | technology transfer,"International Conference on Information Society, i-Society 2017",2018-05-03,Conference Paper,"Abdul, Adeniyi;Bass, Julian M.;Ghavimi, Hossein;Adam, Peter",Include,Yes
10.1016/j.infsof.2022.107144,2-s2.0-0029411803,,Programming TI's multimedia video processor,"The multimedia video processor (MVP) or the TMS320C80 processor from Texas Instruments affords the ability to program video algorithms in software-video DSP. This architecture is designed to achieve performance orders of magnitude greater than traditional DSPs. Although MVP is capable of accurately performing two billion operations per second, it also has several limitations which include cycles, memory, and bandwidth.",,Dr. Dobb's Journal,1995-11-01,Article,"May, William",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-84954526407,,Prototizer: Agile on steroids,"The model-driven software development (MDSD) vision has booked significant advances in the past decades. MDSD was said to be very promising in tackling the ""wicked"" problems of software engineering in general. However, a decade later MDSD is still far from becoming widely recognized within the mainstream software development. At the same time Agile software development methodologies are widely considered as the way to go. This is counter-intuitive as MDSD seems to be the right methodology to boost Agile approaches. From Agile software development perspective, design models are a waste. In this experience report, we present Prototizer, a tool based on model- driven software engineering that could boost the Agile vision.We present a validation of Prototizer on a recent case study and discuss the main lessons learned throughout the past years.",Agile software development | Lean entrepreneurship | Minimum viable product | Model-driven development process | Prototizer,CEUR Workshop Proceedings,2015-01-01,Conference Paper,"Hovsepyan, Aram;Landuyt, Dimitri Van",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-85019181689,,Pursuing commonality and extended life cycles,"Things are certainly changing, with the emergence of 50-GHz handheld analyzers; capable modular systems, usually PXI-able to handle mixed-signal and RF test; new instruments for V- and W-band measurements; and new software tools that simplify design, simulation, and test. What stays the same is the need to maintain test systems across decades in response to extended product life cycles. Marvin Test Solutions (MTS) offers test solutions that incorporate MIL-STD-1760 bus capabilities to enable 'smart' weapons test insupport of a range of products and airframes on the flightline. The result is more comprehensive test capabilities and improved test asset utilization. Keysight offers test equipment in the form factor users need: benchtop, small benchtop, handhelds, and modular. She said the Multi-emitter Scenario Generation for EW product uses off-the-shelf solutions to enable creation of a realistic multi- emitter environment with antenna scans and angle of arrival, streaming of pulse descriptor words (PDWs), and the capability to apply pulse arbitration and calibration to PDW data. Pacific Power Source (PPS) has introduced AFX Series of high power, programmable AC and DC power source systems. These brand new systems were designed from the ground up to support current and future generations of test systems with vastly superior power density and a smaller footprint than anything else available on the market today. The PXI-based GENASYS platform offers performance functional test for mission-critical, high-value electronic assemblies. MTS recently has expanded the GENASYS product line with the addition of the GX7017 chassis. Virginia Panel's Snap-In-Modular (SIM) VTAC right-angle insert. Capable of speeds beyond 10 Gb/s, the SIM VTAC right-angle insert serves a variety of applications that require a high-speed PCB solution. ADLINK Technology announced the release of the MVP-6000 Series, the first in its new line of fanless embedded computing platforms for use in harsh environments.",,EE: Evaluation Engineering,2016-09-01,Article,"Nelson, Rick",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-84911970599,10.1109/CGames.2014.6934143,Quantifying software development: Applying mobile monetization techniques to your software development process,"There are many well defined factors and metrics for the monetization of mobile free to play games, as well as direct solutions and strategies to increase such metrics. Technology and market changes have allowed us to provide software to our customers digitally, which has predicated a shift over to a live service model of development, and business methods emphasizing a minimum viable product followed by incremental changes based on customer responses to our product. Software development methodologies themselves have traditionally been measured only against their costs in development. The same methods that have driven changes in the business models for software development can now be applied to software development methodologies so that architecture decisions can be measured against future revenue in a consistent fashion. This paper presents an example of how such measurements can be made and applied.",mobile | monetization | software cost estimation | software design pattern,"Proceedings of CGAMES 2014 USA - 19th International Conference on Computer Games: AI, Animation, Mobile, Interactive Multimedia, Educational and Serious Games",2014-10-22,Conference Paper,"Ketola, Tom",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-79953833926,,Quantitative assessment of the effects of annuloplasty on mitral annulus dynamic geometry using real-time 3D echocardiography,"Mitral valve (MV) repair is the preferred treatment for mitral regurgitation associated with organic MV prolapse (MVP). Our goal was to describe the dynamic changes in mitral annulus (MA) geometry after annuloplasty, using custom software for MA tracking from transthoracic realtime 3D echocardiography (RT3DE). Forty-four MVP patients, divided into 2 subgroups (RIG and FLEX), were studied by RT3DE the day before, at 3 and 6 months after surgery. RT3DE was also obtained in 20 normal (NL) subjects. MA was tracked frame-by-frame and several parameters were computed. As expected, MVP had an enlarged MA and a reduced planarity compared to NL. Annuloplasty resulted in reduced area both in RIG and FLEX and in a more planar MA shape. Interestingly, at 3 and 6 months, FLEX height was greater than RIG, due to different ring design. This analysis gives new insights in the in-vivo performance of the implanted rings, offering a new tool in the clinical decision process and follow-up.",,Computing in Cardiology,2010-12-01,Conference Paper,"Fusini, Laura;Veronesi, Federico;Gripari, Paola;Maffessanti, Francesco;Corsi, Cristiana;Alamanni, Francesco;Zanobini, Marco;Naliato, Moreno;Tamborini, Gloria;Pepi, Mauro;Caiani, Enrico G.",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-85034589913,10.1007/978-3-319-69926-4_43,Rapid lean UX development through user feedback revelation,"The development of software within short timeframes calls for concepts like minimum viable products with lean development. An agile development setting allows software products to be put on the market in time. Nevertheless, quality, especially in terms of user requirements, suffers when the focus is on the speed of the development. Therefore, we have developed the approach Opti4Apps, which considers user feedback automatically. This automation enables rapid user feedback to be revealed, which is needed for lean development in order to achieve high software quality in accordance with the users’ needs. This paper shows how the approach can be applied smoothly in agile development settings by analyzing common agile practices with regard to our user-centric feedback approach Opti4Apps. It turned out that with most practices, the additional effort is low, and the positive influence can be highly beneficial.",Agile practices | Feedback | Lean development | Quality assurance | User experience | User-centered,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2017-01-01,Conference Paper,"Elberzhager, Frank;Holl, Konstantin;Karn, Britta;Immich, Thomas",Include,Yes
10.1016/j.infsof.2022.107144,,,Reactivity effect of iron reflector in LWR cores,,,Journal of Nuclear Science and Technology,,Article,,Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-10444225772,10.1117/12.174970,Real-time MPEG video codec on a single-chip multiprocessor,"We present a software implementation of a real-time MPEG video codec on the MediaStation 5000 multimedia system. Unlike other compression systems whose sole function is the encoding or decoding of video data, the MediaStation 5000 is capable of performing various real-time operations involving a wide range of multimedia data, including image, graphics, video, and even audio. This programmability is provided by Texas Instruments TMS320C80, better known as Multimedia Video Processor (MVP), which is a single-chip multiprocessing device with highly parallel internal architecture. The MVP integrates a RISC processor, four DSP-like processors, an intelligent DMA controller, video controllers, and a large amount of SRAMs onto a single chip. Since the MVP contains such a high degree of parallel features, developing the MPEG software and mapping it to the MVP requires a thorough study of the algorithms and a good understanding of the processor architecture. By exploiting the advanced features of the MVP, the MediaStation 5000 can achieve the MPEG compression and decompression of video sequences in real time.",,Proceedings of SPIE - The International Society for Optical Engineering,1994-05-02,Conference Paper,"Lee, Woobin;Golston, Jeremiah;Gove, Robert J.;Kim, Yongmin",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-0031976580,10.1023/A:1008844726747,Reintroducing capercaillie (Tetrao urogallus) into southern Scotland: Identification of minimum viable populations at potential release sites,"Capercaillie (Tetrao urogallus) populations are declining in western parts of their range, including Scotland. It has been proposed that their numbers, and the extent of their range in Scotland be increased to reduce the risk of a second extinction in the UK. The feasibility of a reintroduction of capercaillie to coniferous plantations in southern Scotland was assessed by undertaking a population viability analysis. Following a review of capercaillie ecology and habitat requirements, VORTEX population simulation software was used to identify a minimum viable population (MVP). From this the minimum dynamic area of suitable habitat required in order to support such a MVP was then calculated. It was estimated that a minimum of 60 individuals would be required in approximately 5000 ha of habitat in order for the population to have a > 0.95 probability of surviving for 50 years. Supplementation of populations with two unrelated individuals every five years reduced the MVP to ten individuals. Further simulations were run in order to establish the sensitivity of the model to changes in three key parameters. Assessment of areas of suitable habitat identified two potential release sites, Wauchope and Newcastleton forests, in southern Scotland. Some practical considerations relating to management of a release population are outlined. It was concluded that an appropriately planned and resourced reintroduction was feasible.",Minimum viable population | Reintroduction | Scotland | Tetrao urogallus | VORTEX,Biodiversity and Conservation,1998-05-07,Article,"Marshall, Keith;Edwards-Jones, Gareth",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-85092224188,,Repository data-based algorithm for selection of product teams of it specialists,"Due to the lack of qualified personnel in the IT sector, companies provide their employees with the opportunity to work remotely. That helps even a small company to stand as a global player on the market and recruit new professionals from all over the world. The companies involved in the development of product solutions are interested in hiring cohesive teams of developers who were working together for a long time. However, the HR processes of the company should be restructured and added by additional tools that will help to analyze the entire team's activity and created artifacts. The article contains a detailed description of the MVP that implements searching, selection of project teams based on data from open-source code repositories, and related artifacts. The report describes the algorithm for selecting the main team from the entire set of developers who took part in the development of the project.",Filtering | Metrics | Remote team | Repository | Search,CEUR Workshop Proceedings,2020-01-01,Conference Paper,"Zhelepov, Alexey;Yarushkina, Nadezhda",Exclude,EC1
10.1016/j.infsof.2022.107144,2-s2.0-84895924037,10.1111/echo.12365,Reproducibility in echocardiographic two- and three-dimensional mitral valve assessment,"Background: Three-dimensional transesophageal echocardiography (3DTEE) has been demonstrated to provide more accurate information than two-dimensional transesophageal echocardiography (2DTEE) in the localization of mitral valve prolapse (MVP). However, most studies have been single-rater studies. Few results were tested for inter-observer variability with a single second rater. This multicenter study aimed to determine reliability of 2D and 3DTEE mitral valve evaluations by calculating inter-observer agreement between various echocardiographers. Methods: Fifteen observers from 4 institutions in Germany and Switzerland interpreted 2D and 3DTEE images from 6 patients selected to represent a large spectrum of MVP diversity. Surgical findings served as reference. Individual assessments of MVP and ruptured chordae tendineae (ChR) pathology were compared by calculating Randolph's free-marginal multirater kappa coefficient. Results: Accuracy of MVP evaluation with 3DTEE was 83.9%, CI [81.0%; 86.8%] and 78.7% CI [76.6% 80.8%] with 2DTEE. Flail leaflets with chordal ruptures were described correctly in 91.1%, CI [85.8, 96.4] with 3D compared to 71.1%, CI [65.0, 77.2] with 2DTEE. The multirater kappa coefficient of inter-observer agreement among all 15 observers was κ = 0.65/0.58 for 3D/2D evaluation of MVP and κ = 0.70/0.54 for detection of ChR. Conclusion: Three-dimensional assessment of MVP was superior to 2DTEE, although the accuracy of both 3DTEE and 2DTEE was found to be lower than previously published. 3D MVP assessment is less operator dependent than 2DTEE evaluation. Although validity has been demonstrated before, we provide evidence that 3DTEE is reproducible among 15 observers and is a reliable method for MVP evaluation. © 2013, Wiley Periodicals, Inc.",inter-observer agreement | inter-observer variability | mitral valve prolapse evaluation | multicenter study | reliability | ruptured chordae tendineae,Echocardiography,2014-01-01,Article,"Hien, Maximilian Dominik;Großgasteiger, Manuel;Weymann, Alexander;Rauch, Helmut;Rosendal, Christian",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-85084380910,10.1016/j.procs.2020.02.012,Research on MVP design pattern modeling based on MDA,"In recent years, mobile devices (such as various brands of mobile phones, tablet computers, smart watches, etc.) have gained popularity among users, which has also promoted the rapid development of mobile software application market. In order to meet the needs of mobile device users for better user interaction experience, the demand of mobile software application market for user interface is becoming more and more complex, and software developers are constantly exploring and developing more popular user interface. Due to the shortage of production technology, the development of mobile user interface has some problems such as low efficiency and high cost. In order to solve these problems, this paper proposes a method of modeling PIM using IFML and UML by introducing MVP design pattern in a model-driven framework. By combining the advantages of model-driven and MVP design pattern, this method improves the granularity of PIM modeling in user interface development under model-driven framework, reduces the difficulty of model design, and promotes software reuse.",IFML | MDA | Modeling | MVP design pattern | PIM | UML | User interface development,Procedia Computer Science,2020-01-01,Conference Paper,"Li, Dan Dan;Liu, Xiao Yan",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-85051144205,10.1051/matecconf/201817303062,Research on operational model of PUBG,"This paper mainly studies operational model of the famous Computer Games - PlayerUnkown's BattleGrounds (PUBG), be aimed at human beings in the game or human beings regarded as intelligent robots, including the influence of objective factors and subjective factors on the game results, linear programming model is established for the various factors and the game results, using Excel software, realized in different situations the relationship between various factors and the result of game problem solving and plotting table. To solve the problem 1, the paper find out the trend of the safety area and the random coverage circle of the safety area through statistical data and analyze the data, and then push it to the parachute jumping time and the parachute jumping place. To solve the problem 2, the paper build a game model based on the analysis of the distance between two sides, the judgement of the azimuth and the random running and attacking each other caused by the psychological state of the bullet avoidance, and then, according to experience, how to perform micro manipulation to improve the hit rate. To solve the problem 3, the paper make KDA as a measure of bureau of the game in the best performing team and the best individual (MVP) of the key indicators, through the calculation of KDA for the game and the individual scores and rankings, distribution to determine the winners of the prize gaming contest.",,MATEC Web of Conferences,2018-06-19,Conference Paper,"Ding, Yong",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-85088755631,10.3997/2214-4609.201600475,Results of experimental electromagnetic studies of the Crimean region,"Spatial-temporal pattern of distribution of geomagnetic variations and electric field on the Earth's surface was obtained as a result of modern experimental observations conducted in 2007-2013 along 9 profiles (48 points) by the methods of magnetotelluric sounding (MTS) and magnetovariation profiling (MVP). These profiles cross various geological structures of the Crimean region. It is possible to estimate the value of electrical conductivity and vertical and horizontal geo-electric structure. The processing of these data is done using modern software system PRC-MTMV (author Varentsov Iv. M.) that provides the common noise-protected evaluation of the impedance, tipper and horizontal magneto-variation response according to synchronous MT/MV records. The main result of qualitative interpretation of geo-electric research is the detection of high conductivity regions in the Earth's crust and upper mantle of the Crimea, that are characterized by the variations of conductivity, depth and configuration. They characterize the various geological structures differently. The sub-vertical conductive zones often coincide with the fault structures, most of these objects are confined to the suture zones between tectonic elements such as the East European platform and the Scythian plate, the Scythian plate and the Crimean mountain, North and South Kerch zone. This fact may reflect high permeability of the suture zones for deep fluids in the process of their formation. Although the qualitative interpretation of the experimental data of magnetotelluric sounding (MTS) and magnetovariation profiling (MVP) provides inconsistent understanding of the depth distribution of the Crimean region electrical conductivity, the combination of these methods allows constructing the model of resistivity distribution within a three-dimensional environment much more accurately and adequately to the observed experimental data.",,Geoinformatics 2016 - XVth International Conference on Geoinformatics - Theoretical and Applied Aspects,2016-01-01,Conference Paper,"Burahovich, T.;Kushnir, A.",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-85051215587,10.2514/1.I010601,Review of formal agile methods as cost-effective airworthiness certification processes,"SAFETY-CRITICAL software systems are part of our daily life and any error in these systems can result in catastrophic consequences, with the worst-case scenario being loss of human life. Therefore, a rigorous safety certification process is needed to prove the correctness and reliability of such systems. The purpose of the certification process is to ensure that the system to be used in a specific environment under specific conditions is safe. To make these software systems trustworthy and more reliable, the Federal Aviation Administration (FAA) is imposing safety requirements on the development and verification of airborne avionic systems as stated in the DO-178 [1] (“Software Considerations in Airborne Systems and Equipment Certification”) guidance document developed by the Radio Technical Commission for Aeronautics, Inc. and the European Organisation for Civil Aviation Equipment (EUROCAE; a nonprofit organization providing a European forum for resolving technical problems with electronic equipment for air transport). The latest DO-178C guidance includes modern technologies and methodologies necessary to achieve a more reliable and safe system within a constrained time and cost. The DO-178C guidance document also describes various guidelines to engineer (design, specify, develop, test, and deploy) a software component and all associated equipment with a certain level of safety that complies with the FAA airworthiness requirements [2]. Although these standards define the requirements for a process to remain compliant when used to develop a safety-critical system, the standards do not specify which process to use. Thus, software developers can use any preferred processes if they meets the objectives and safety standards of DO-178C, which in our case leave us with an option to then use Agile, formal methods, and model-based development (MBD) [3,4] with all their associated advantages in the certification and development process. The agile software development process is a set of practices and methods that are based on the values and principles expressed in the agile manifesto established on 17 February 2001 [5]. These methods take an iterative and lean development approach that emphasizes the rapid development of a minimum viable product and frequent releases of the software, producing high-quality code and reducing process overhead and direct involvement of the customer in the development process. Agile is significantly accepted in the industry but not as widely accepted in safety-critical systems development because of its undisciplined nature when it comes to documentation and the lack of rigorous verification and validation techniques. One study suggests that using the Agile process as a standalone method to develop a safety-critical system has proven to be a failure because of the quality control mechanisms used by Agile such as informal reviews and pair programming, which have not assured developers or authorities that the product is safe [6]. However, the study also suggests that using Agile can deliberately reduce the complexity on the aircraft development process and evolutionary technology used [7]. The study suggests using project awareness to handle the process complexity and open-source tools to start processes from the second half of the development life cycle earlier in order to detect and react to possible blockers as soon as possible. Scaling agile methods for large systems is hard and, in handling this issue, the study suggests using virtual simulation and testing that will reduce system complexity, save the budget, and get early feedback about the system. However, critical systems need upfront design, exhaustive documentation, and continuous integration, which is practically challenging when using Agile. Therefore, the aviation industry avoids applying Agile in the development process.",,Journal of Aerospace Information Systems,2018-01-01,Article,"Blooshi, Mouza Al;Jafer, Shafer;Patel, Krishan",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-85071887193,,"Review of ios architectural pattern for testability, modifiability, and performance quality","In the mobile development especially in iOS, a correct selection of architecture patterns is crucial. Many architectural patterns used by developers such as Model View Controller (MVC), Model View Presenter (MVP), Model View ViewModel (MVVM), and View Interactor Presenter Entity Router (VIPER) have promised stability of the product. Nowadays, most developers tend to use MVC architectural pattern as this pattern is easy to use and separate the logic between model, view and controller. However, this architecture has common problems which are hard to test and manage the code because all the codes for business application are placed in controller components. Therefore, this paper reviewed some of the existing architectural patterns qualities specifically in testability, modifiability and performance quality in order to investigate the mentioned problems. By using Contact mobile apps as a case study, the results show the MVVM architecture is good for testability, modifiability (cohesion level procedural), and performance (memory consumption). In addition, VIPER is the best in modifiability (coupling level data and coupling level message) and performance of CPU.",Architecture pattern | Design pattern | Quality attributes | Software architecture | Software professionals,Journal of Theoretical and Applied Information Technology,2019-08-15,Article,"Sholichin, Fauzi;Isa, Mohd Adham Bin;Halim, Shahliza Abd;Harun, Muhammad Firdaus Bin",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-78649264641,,Role of real-time three-dimensional transesophageal echocardiography in mitral valve repair,"Background and objective: Pre-operative assessment of mitral valve (MV) anatomy is essential to surgical design in patients undergoing MV repair. Although 2-dimensional (2D) echocardiography provides precise information regarding MV anatomy, RT-3D TEE could increase the understanding of MV apparatus and individual scallop identification. We aimed to investigate the value of RT-3DTEE in MV repair. Methods: RT-3DTEE was performed in six patients with mitral valve prolapse (MVP) by using Philips IE33 with X7-2t probe. Preoperative RT-3DTEE studies were compared with surgical findings in patients undergoing surgical mitral valve repair, and quantitative evaluation was performed by QLab 6.0 software before and after surgical mitral valve repair. Results: RT-3DTEE could display dynamic morphology of MV, the location of prolapse, and spatial relation to the surrounding tissue. It could provide surgical views of the valves and the valvular apparatus. These results were consistent with surgical findings. The quantitative evaluation before and after surgical MV repair indicated that anterolateral to posteromedial diameter of annulus, anterior to posterior diameter of annulus, perimeter of annulus, and area of annulus in projection plane were significantly smaller after operation compared with those before operation (P<0.05). The length of posterior leaflet, the area of anterior and posterior leaflet, the maximal prolapse height, the volume of leaflet prolapse and the length of coaptation in projection plane were significantly reduced after operation (P<0.05). Conclusion: RT-3DTEE is a unique new modality for rapid and accurate evaluation of mitral valve prolapse and mitral valve repair.",Echocardiography | Mitral valve repair | Real-time | Transeophageal,Journal of Geriatric Cardiology,2008-09-01,Article,"Pan, Cuizhen;Shu, Xian Hong;Cao, Qiling;Wang, Chunsheng;Ding, Wenjun;Chen, Haozhu",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-84986236295,10.1007/978-3-319-43606-7_5,RSL-DL: Representing domain knowledge for the purpose of code generation,"In the paper a new extension to the existing RSL (Requirements Specification Language) language has been proposed, called RSL-DL (Requirements Specification Language-Domain Logic). Based on the declarative paradigm of programming its aim is to enable defining ontologies at the requirements level and as a consequence also describing the domain logic part of requirements specification. Being fully complement with RSL it supplements ReDSeeDS (Requirements-Driven SoftwareDevelopment System) technology with a possibility to generate by far missing code of the Model layer of standard MVP architectural pattern. The main idea of the solution has been described, together with the definition of the key language elements, in terms of syntax, notation and semantics as well. Additionally the role of the RSL-DL within the whole ReDSeeDS technology framework has been precisely defined and comparison with other languages has also been included.",,Advances in Intelligent Systems and Computing,2017-01-01,Conference Paper,"Rybiński, Kamil;Parol, Rafał",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-0022275921,,SHANGHAI ECONOMETRIC MODEL (SHECMOD) AND COMPUTER APPLICATIONS.,"The Shanghai Econometric Model (SHECMOD) in combination with the methodology of econometric model building is presented. SHECMOD is a non-linear and dynamic model. In order to compare different approaches for model building, two different forms are developed: SHECMOD-A (SHECMOD on Apple II plus microcomputer) and SHECMOD-W (SHECMOD on Wang MVP-2200 computer). A stability study of the model, multipier analysis and policy evaluation of selected economic objectives, and analysis of multivariable disturbed projected simulation and its impact on economic objectives have been carried out for the years 1984-1987. Suggestions for Shanghai municipal economic development are proposed. Software packages developed for macro econometric modeling on Apple II plus microcomputer and Wang MVP-2200 computer are briefly described.",,Proceedings of the Annual Conference of the Association for Computing Machinery,1985-12-01,Conference Paper,"Gu, Weiwen;Wu, Dinghua;Xie, Zhiliang;Gu, Qingliang",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-85046479556,10.1109/CSEET.2017.38,Software Engineering Education: Converging with the Startup Industry,"Startups are agents of change that bring in innovations and find solutions to problems at various scales. An all-rounded engineering team is a key driver for the ability to execute the entrepreneurial ambition, from building a minimum viable product to later stages of product vision. Software engineering education provides students with the knowledge to transition to mature companies with defined structure in place successfully. However, the fluidity, risk, time-sensitivity, and uncertainty of startups demand a dynamic and agile set of skills to rapidly identify, conceptualize and deliver features as per market needs. This requires the adoption of latest development trends in software processes, engineering and DevOps practices with automation to iterate fast with low governance and the ability to take on multiple roles. This paper presents a study of the dynamics and engineering at startups and compares it with the current curriculum of software engineering.",Innovation and Education | Software Engineering Degree Programs | Software Engineering Education | Startup Engineering | Startups,"Proceedings - 30th IEEE Conference on Software Engineering Education and Training, CSEE and T 2017",2017-12-04,Conference Paper,"Devadiga, Nitish M.",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-85075692704,10.1007/978-3-030-33547-2_5,Software Product Quality in DevOps Contexts: A Systematic Literature Review,"DevOps is a change in the organizational culture that aims to reduce the gap between development and operation teams, accelerating the software release process. However, little is known about the impact of this approach on software product quality. This study aims to analyze the influence of the application of DevOps on software product quality; therefore, a systematic literature review was conducted. Thirty-one articles related to DevOps and its influence on product quality were identified. The studies indicate a strong influence of some product quality characteristics, specifically: Reliability and Maintainability. Additionally, practices associated with DevOps, such as the minimum viable product, deployment automation, test automation, cloud computing and team cooperation, show a relationship with the improvement in software product quality, however, its adoption also brings new challenges to preserve security.",DevOps | ISO/IEC 25000 | Product quality | Systematic literature review,Advances in Intelligent Systems and Computing,2020-01-01,Conference Paper,"Céspedes, Daniel;Angeleri, Paula;Melendez, Karin;Dávila, Abraham",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-85061873966,10.3390/sym11020129,Spatial correlation-based motion-vector prediction for video-coding efficiency improvement,"H.265/HEVC achieves an average bitrate reduction of 50% for fixed video quality compared with the H.264/AVC standard, while computation complexity is significantly increased. The purpose of this work is to improve coding efficiency for the next-generation video-coding standards. Therefore, by developing a novel spatial neighborhood subset, efficient spatial correlation-based motion vector prediction (MVP) with the coding-unit (CU) depth-prediction algorithm is proposed to improve coding efficiency. Firstly, by exploiting the reliability of neighboring candidate motion vectors (MVs), the spatial-candidate MVs are used to determine the optimized MVP for motion-data coding. Secondly, the spatial correlation-based coding-unit depth-prediction is presented to achieve a better trade-off between coding efficiency and computation complexity for interprediction. This approach can satisfy an extreme requirement of high coding efficiency with not-high requirements for real-time processing. The simulation results demonstrate that overall bitrates can be reduced, on average, by 5.35%, up to 9.89% compared with H.265/HEVC reference software in terms of the Bjontegaard Metric.",CU depth | H.265/HEVC | Motion-vector prediction | Video-coding efficiency,Symmetry,2019-02-01,Article,"Jiang, Xiantao;Song, Tian;Katayama, Takafumi;Leu, Jenq Shiou",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-84928527735,10.1386/josc.5.2.259_1,Start me up: Lean screenwriting for American entrepreneurial cinema,"This article proposes a new approach to script development modelled after lean software development practices and entrepreneurial startup principles. First, it argues that the Hollywood mode of production and its methods of project development, when applied to microbudget film-making, are inherently wasteful and fail in the face of extreme uncertainty and unpredictability. Second, it argues that entrepreneurial screenwriters and writer/film-makers can adopt lean thinking in order to eliminate waste from their creative labour and enhance learning at every stage of development and production, adding value for their audience. Finally, it argues that inexperienced writer/film-makers are particularly susceptible to the false security of the ‘blueprint’ metaphor, often clinging to an original plan even as it fails them. The flexibility inherent to lean thinking, on the other hand, not only reduces waste but also enhances creativity and collaboration, increasing a project’s chances of success.",Entrepreneurship | Lean screenwriting | Lean startup | Minimum viable product | MVP | Script development | Validated learning,Journal of Screenwriting,2014-01-01,Article,"Gay, Andrew Kenneth",Exclude,EC2
10.1016/j.infsof.2022.107144,2-s2.0-85067809797,10.1016/j.infsof.2019.06.008,Startup ecosystem effect on minimum viable product development in software startups,"Context: Software startups develop innovative products through which they scale their business rapidly, and thus, provide value to the economy, including job generation. However, most startups fail within two years of their launch because of a poor problem-solution fit and negligence of the learning process during minimum viable product (MVP) development. An ideal startup ecosystem can assist in MVP development by providing the necessary entrepreneurial education and technical skills to founding team members for identifying problem-solution fit for their product idea, allowing them to find the right product-market fit. However, existing knowledge on the effect of the startup ecosystem elements on the MVP development is limited. Objective: The empirical study presented in this article aims to identify the effect of the six ecosystem elements (entrepreneurs, technology, market, support factors, finance, and human capital) on MVP development. Method: We conducted a study with 13 software startups and five supporting organizations (accelerators, incubator, co-working space, and investment firm) in the startup ecosystem of the city of Oulu in Finland. Data were collected through semi-structured interviews, observation, and materials. Results: The study results showed that internal sources are most common for identifying requirements for the product idea for MVP development. The findings indicate that supporting factors, such as incubators and accelerators, can influence MVP development by providing young founders with the necessary entrepreneurship skills and education needed to create the right product-market fit. Conclusions: We conclude from this study of a regional startup ecosystem that the MVP development process is most affected by founding team members’ experiences and skill sets and by advanced technologies. Furthermore, a constructive startup ecosystem around software startups can boost up the creation of an effective MVP to test product ideas and find a product-market fit.",Empirical study | Minimum viable product | Product idea | Prototype | Software startup | Startup ecosystem,Information and Software Technology,2019-10-01,Article,"Tripathi, Nirnaya;Oivo, Markku;Liukkunen, Kari;Markkula, Jouni",Include,Yes
10.1016/j.infsof.2022.107144,2-s2.0-85034426704,10.1109/SEAA.2017.46,Startup trust model: The role of trust in successful software startup,"the increasing desire by many for a better world and easier living conditions have contributed to various efforts to the frontiers of innovation in information technology (IT). The ensuing phenomena is the launch of many software startups to give meaning to such innovations in IT. Interestingly, the rate at which many of such startups fail is usually higher than expected. A collaborative effort by actors in IT innovation ecosystem has been posited to lead to a successful startup. However, there is the need for a trust model to ensure that the collaborative effort become meaningful. Through the lens of Morgan and Hunt's commitment trust theory, this study examines the antecedents of trust among actors in successful software startup. The paper proposes 'Startup Trust Model' and contributes to understanding of formation and maintenance of trust in software startups and makes a case for the study of trust in software startup.",Actors | Antecedent | Ecosystem | Minimum Viable Product | MVP | Software Startup | Startup | Trust,"Proceedings - 43rd Euromicro Conference on Software Engineering and Advanced Applications, SEAA 2017",2017-09-26,Conference Paper,"Assyne, Nana;Adjei, Joseph",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-85099400133,10.1117/12.2576297,TANGO-grafana: An online diagnostic tool to assist in the analysis of interconnected problems difficult to debug in the context of the Square Kilometre Array (SKA) telescope project,"The selected solution for monitoring the SKA Minimum Viable Product (MVP) Prototype Integration (SKAMPI) is Prometheus. Starting from a study on the modifiability aspects of it, the Grafana project emerged as an important tool for displaying data in order to make specific reasoning and debugging of particular aspect of SKAMPI. Its plugin architecture easily allow to add new data sources like prometheus but the TANGO related data sources has been added as well. The main concept of grafana is the dashboard, which enable to create real analysis. In this paper four example analysis are presented which take advantage of four different datasources and a variety of different panel (widget) for reasoning on archiving data, monitoring data, state of the system and general health of it.",Bridging | diagnostic | SKA | Software develop-ment | System team | TANGO | TANGO controls framework,Proceedings of SPIE - The International Society for Optical Engineering,2020-01-01,Conference Paper,"Di Carlo, M.;Harding, P.;Le Roux, G.;Dolci, M.",Exclude,EC1
10.1016/j.infsof.2022.107144,2-s2.0-85058608633,10.1201/9781315365664,Technology selection for software startups,"Many, perhaps most, software startups start with just an “idea.” • It should be easier to get a ride to go where I need to go now; • I want to sell my beanie babies online; • It should be easier to find information. If the inventor is a software engineer they might just start writing soft- ware-using tools that they already know. Some might think a little harder and learn a new tool that seems particularly well suited to the job. The founder of Instagram famously taught himself to code while creating the app. In every case, a decision will be made and a minimum viable product will be built using some set of tools. In this chapter we will lay out how this choice-made during a software startup’s birth-can affect a startup’s culture and eventual success.",Agile | Choices | Cto | Innovation | Startups | Technology,Ecosystems and Technology: Idea Generation and Content Model Processing,2017-01-01,Book Chapter,"Floyd, Michel",Exclude,EC4
10.1016/j.infsof.2022.107144,2-s2.0-85087144942,10.1016/j.tele.2020.101455,The benefits of interdisciplinary scenario-building for hybrid radio applications,"In this paper, we make the case for building interdisciplinary scenarios, integrating technological, business and user perspective during the fuzzy front-end of innovation. We start from a living lab framework, underpinning the iterative process to integrate insights from all three perspectives within research projects. Then, we explain how the approach was applied within the HRADIO project1. This EU funded project focuses on the development of hybrid radio applications. We demonstrate how the process of building interdisciplinary scenarios and the involvement of multiple perspectives to evaluate these scenarios, has enabled both strategic decision making (1) and improved the technical development process within the HRADIO project (2). The first focuses on the (lack of) interest in certain scenarios from a business, technology and/or user perspective, to explain: (a) how these thresholds can be overcome and (b) what the consequences are for the project. The latter explains how we moved from interdisciplinary scenarios to a first Minimum Viable Product (MVP) that could be tested in the first pilot phase, to prototypes to be tested in the second pilot phase. To validate the importance of the scenarios, we also explain how the scenarios are integrated into the exploitation timeline. Finally, and importantly, we address how the process of multidisciplinary scenario building and evaluation can be improved.",Hybrid radio | Interdisciplinary scenarios | Living lab | Requirements engineering | Software architecture | Software engineering,Telematics and Informatics,2020-11-01,Article,"Jennes, Iris;Friedrich, Markus;Van der Bank, Jaco;Van den Broeck, Wendy;Ebert, André;Boonen, Michelle",Include,Yes
10.1016/j.infsof.2022.107144,2-s2.0-85062501413,,The long-term effects of a short-term helping hand: Software startups in accelerators,"This study examines the effect of mentorship on the early stage development of software firms. The software industry is characterized by extremely high rates of failure in the first two years after founding. It is during this stage of the firm's evolution that mentorship can provide significant value. Drawing on prior work studying the effect of mentorship, albeit, in different contexts, we theorize about how mentors may benefit software startups by providing access to resources and knowledge that can help the startups achieve both short-term and long-term goals in the firm's trajectory. We test these arguments using data collected on a cohort of software firms within a large international accelerator, wherein focused short-term programs are conducted for very early-stage new ventures with the view to getting them ready to compete in the marketplace and for venture capital. Our econometric analysis shows that startups that receive mentorship have a higher likelihood of achieving short-term outcomes, such as the release of a minimum viable product (MVP) and a first sale. Further, we find that the achievement of these short-term outcomes significantly mediates the relationship between mentorship and long-term outcomes, specifically the startup's survival three years later and the acquisition of funding. Our work contributes to a better understanding of the role of mentorship in helping software startups succeed, a significant gap in IS research.",Accelerator | Firm survival | Funding | Mentorship | Software industry | Startup,"International Conference on Information Systems 2018, ICIS 2018",2018-01-01,Conference Paper,"Mejia, Jorge;Gopal, Anandasivam",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-84946905134,10.1088/1757-899X/94/1/012012,The mathematical statement for the solving of the problem of N-version software system design,"The N-version programming, as a methodology of the fault-tolerant software systems design, allows successful solving of the mentioned tasks. The use of N-version programming approach turns out to be effective, since the system is constructed out of several parallel executed versions of some software module. Those versions are written to meet the same specification but by different programmers. The problem of developing an optimal structure of N-version software system presents a kind of very complex optimization problem. This causes the use of deterministic optimization methods inappropriate for solving the stated problem. In this view, exploiting heuristic strategies looks more rational. In the field of pseudo-Boolean optimization theory, the so called method of varied probabilities (MVP) has been developed to solve problems with a large dimensionality.",,IOP Conference Series: Materials Science and Engineering,2015-01-01,Conference Paper,"Kovalev, I. V.;Kovalev, D. I.;Zelenkov, P. V.;Voroshilova, A. A.",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-21644488060,,The mathematical system model for the problem of Multi-Version software design,"The problem of developing an optimal structure of Multi-Version software system presents a kind of very complex optimization problem. This causes the use of deterministic optimization methods inappropriate for solving the stated problem. In this view, exploiting heuristic strategies looks more rational. In the field of pseudo-Boolean optimization theory, the so called method of varied probabilities (MVP) has been developed to solve problems with a large dimensionality.",,"Proceedings of Modelling and Simulation, MS'2004",2004-12-01,Conference Paper,"Kovalev, I. V.;Dgioeva, N. N.;Slobodin, M. Ju",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-85076980914,10.1007/978-3-030-33695-0_49,The mobile application development based on online music library for socializing in the world of bard songs and scouts’ bonfires,"The aim of the current work is to create a mobile application that helps bard singers and guitar players sing the same songs and play the same chords. The development of this software product was conducted under the operating system Android using Java programming languages and Kotlin. SQLite database management system was selected for storing data. XML is the main markup language for the development of the graphical interface. Pure architecture as the basic architecture in conjunction with the MVP pattern has been chosen. The developed mobile application is simple and easy to use and provides the following basic functions: display a list of songs with chords to them, search for songs by name, detailed song display, ability to show-hide chords, add our own songs to the songwriter, automatically detect and mark chords in song lyrics, dynamically show chords when we click on it in a song, create a list of our favorite songs, change the tone of the song, show chords for the musical instrument chosen by user.",Android | Database management system | Java | Kotlin | Mobile application | Software | SQLite,Advances in Intelligent Systems and Computing,2020-01-01,Conference Paper,"Rusyn, Bohdan;Pohreliuk, Liubomyr;Rzheuskyi, Antonii;Kubik, Roman;Ryshkovets, Yuriy;Chyrun, Lyubomyr;Chyrun, Sofiia;Vysotskyi, Anatolii;Fernandes, Vitor Basto",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-84946925664,10.1088/1757-899X/94/1/012013,The pseudo-Boolean optimization approach to form the N-version software structure,"The problem of developing an optimal structure of N-version software system presents a kind of very complex optimization problem. This causes the use of deterministic optimization methods inappropriate for solving the stated problem. In this view, exploiting heuristic strategies looks more rational. In the field of pseudo-Boolean optimization theory, the so called method of varied probabilities (MVP) has been developed to solve problems with a large dimensionality. Some additional modifications of MVP have been made to solve the problem of N-version systems design. Those algorithms take into account the discovered specific features of the objective function. The practical experiments have shown the advantage of using these algorithm modifications because of reducing a search space.",,IOP Conference Series: Materials Science and Engineering,2015-01-01,Conference Paper,"Kovalev, I. V.;Kovalev, D. I.;Zelenkov, P. V.;Voroshilova, A. A.",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-84937510941,10.1007/978-3-319-19593-3_2,The relationship between business model experimentation and technical debt,"The use of lean software development methodology and business model experimentation has become popular in software companies in recent years. Business model experimentation is used to validate assumptions made on a product from real customers before the actual product is created. A minimum viable product is used to test the business model by gathering and measuring customer feedback. However, in many cases creating a minimum viable product requires the development team to take shortcuts and workarounds in the product. This phenomenon in software development is called ‘technical debt’, where companies trade long-term software quality to short-term gain in time-tomarket. We investigated four software companies and conducted nine interviews to understand the relationship between business model experimentation and technical debt. The goal was to study how business model experimentation is affecting to technical debt. The results showed that business model experimentation has a clear relationship to technical debt.",Business model experimentation | Case study | Large company | Minimum viable product | Software development lifecycle | Startup company | Technical debt,Lecture Notes in Business Information Processing,2015-01-01,Conference Paper,"Yli-Huumo, Jesse;Rissanen, Tommi;Maglyas, Andrey;Smolander, Kari;Sainio, Liisa Maija",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-84963563079,10.1016/j.jss.2016.03.034,The RIGHT model for Continuous Experimentation,"Context: Development of software-intensive products and services increasingly occurs by continuously deploying product or service increments, such as new features and enhancements, to customers. Product and service developers must continuously find out what customers want by direct customer feedback and usage behaviour observation. Objective: This paper examines the preconditions for setting up an experimentation system for continuous customer experiments. It describes the RIGHT model for Continuous Experimentation (Rapid Iterative value creation Gained through High-frequency Testing), illustrating the building blocks required for such a system. Method: An initial model for continuous experimentation is analytically derived from prior work. The model is matched against empirical case study findings from two startup companies and further developed. Results: Building blocks for a continuous experimentation system and infrastructure are presented. Conclusions: A suitable experimentation system requires at least the ability to release minimum viable products or features with suitable instrumentation, design and manage experiment plans, link experiment results with a product roadmap, and manage a flexible business strategy. The main challenges are proper, rapid design of experiments, advanced instrumentation of software to collect, analyse, and store relevant data, and the integration of experiment results in both the product development cycle and the software development process.",Agile software development | Continuous experimentation | Lean software development | Product development | Software architecture | Software development process,Journal of Systems and Software,2017-01-01,Article,"Fagerholm, Fabian;Sanchez Guinea, Alejandro;Mäenpää, Hanna;Münch, Jürgen",Exclude,EC1
10.1016/j.infsof.2022.107144,2-s2.0-0033992890,,The surgical experiences and risk factors of combined valvular procedure and myocardial revascularization,"OBJECTIVE: To introduce the experience of combined valve procedure and CABG. METHODS: 61 men and 15 women, with a mean age of 56 years, underwent combined valve procedure and CABG. CABG was performed with AVR (1 - 3 grafts) in 25 patients, with MVR (1 - 4 grafts) in 31 (MVR + AVP in 2, MVR + TVP in 3), with aortic and mitral valve replacement (1 - 3 grafts) in 18 (BVR + TVP in 2), with MVP (1 graft) in 1 and with MVP + TVP (1 graft) in 1 patient. Rheumatic disease was present in 67 and degenerative aortic and mitral valve disease was present in 9. SPSS statistical software was used to analyse the risk factors of the operation. RESULTS: 6 operative deaths (7.89%) occurred. 63 patients (63/70) who survived the operation were followed up for a mean period of 26.8 months. The function of heart in 62 patients was significantly improved. One patient died of SBE 9 months after operation. CONCLUSION: The combination of valve replacement or repair with coronary revascularization generally increases operative mortality. The hospital mortality is related to preoperative myocardial infarction, NYHA class IV, lower EF and the longer time of CPB and clamping aorta. Grafting in all significant coronary lesions, restoration of valvular function and good myocardial protection are the key factors for the success of CABG with valvular procedure.",,Zhonghua yi xue za zhi,2000-01-01,Article,"Wu, Q.;Meng, Q.;Hu, S.",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-84949210074,10.1007/3-540-59205-9_37,The use of roles and measurement to enact project plans in MVP-S,"Software development organizations are beginning to recognize that measurement is a prerequisite for systematic process improvement, and have started to measure their products and processes in order to understand, analyze, plan, and guide their projects. Successful measurement requires a solid understanding of the products, processes, and resources to be measured, an understanding which can only be gained via explicit models. In the MVP Project we are integrating the G/Q/M measurement paradigm with the MVP-L process modeling language in order to guide teams of software developers. This integrated approach is supported by a prototype system, MVP-S, a process-sensitive software engineering environment which offers advanced project guidance using role definitions and measurement data. We motivate the need for measurement, sketch an integration of the measurement and modeling approaches, and demonstrate how MVP-S improves the quality of guidance using measurement.",,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),1995-01-01,Conference Paper,"Lott, Christopher;Hoisl, Barbara;Rombach, H. Dieter",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-84982794686,10.1145/2855321.2855373,Three patterns for user involvement in startups,"Creating products in software startups consists of a great deal of uncertainty combined with little resources. Rapid validation of created solutions with the potential customers is essential to startups. However, often startups lack people with skills needed for the validation. We present three patterns that help in involving users to gain meaningful feedback and learning. First, the feedback has to be gotten from the right people and the right questions have to be asked. Furthermore, if the feedback is collected with a prototype, often called a Minimum Viable Product, users should be able to give feedback of the actual idea, not to any roughness caused by the immaturity and the prototypishness of the product.",Lean | Startups | User experience,ACM International Conference Proceeding Series,2015-07-08,Conference Paper,"Hokkanen, Laura;Leppänen, Marko",Include,Yes
10.1016/j.infsof.2022.107144,2-s2.0-0028458201,,To multiprocess or not to multiprocess?,"It is always best to opt for a one-processor implementation if a one-processor system can do the job. In cases where one will not be enough, however, there are approaches and tools that can help one stay on schedule and avoid high costs. Of these, TI's MVP includes a 320-bit RISC master processor and four 32-bit DSPs, as well as a video controller and a transfer controller that manages communication among the processors. Motorola's 68360 QICC (quad integrated communications controller), includes a 32-bit microcontroller core, a special-purpose RISC processor, and four serial-communication controllers. Star Semiconductor's SPROC-1400 chip includes, among other elements, four 24-bit fixed-point DSPs. Adaptive Solutions' CNAPS chips include as many as 80 16-bit fixed point DSPs on a single piece of silicon.",,EDN,1994-06-01,Article,"Strassberg, Dan",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-85028654928,10.1016/j.procs.2017.06.087,Towards Automated Capturing and Processing of User Feedback for Optimizing Mobile Apps,"Mobile devices are nowadays ubiquitous and are heavily used for business and private purposes. Millions of apps exist that support users in multiple ways, e.g., for car navigation, fitness purposes, or messaging in our private lives, but also for business planning purposes and even for controlling whole business processes. Failures in mobile business apps can lead to dramatic consequences in terms of lost revenue, but also in terms of lost trust or even threats for human beings, and thus quality plays a crucial role. On the other hand, as software is nowadays one of the main drivers for innovation, fast delivery of new apps, respectively new functionality, is necessary, i.e., the time to market must often be short. However, in order to understand whether the quality is sufficient, and whether the functionality of the app serves the needs of the users, lean development approaches are emerging and propose the deployment of apps as a minimal viable product (MVP). Here, the app is provided with acceptable quality, but not with every feature, just with the main functionality. Based on such an MVP, early feedback from users is to be collected, which may be related to the quality of the app, but also include wishes and requests for new functionality. In order to analyze and draw conclusions from user feedback, we first have to understand what kind of feedback exists and how it can be interpreted, respectively how valid such feedback is. In this publication, we provide a classification of user feedback for mobile apps, derive feedback channels, and sketch how this can be used in a continuous process to improve mobile apps.",mobile | mobile apps | Opti4Apps | user feedback,Procedia Computer Science,2017-01-01,Conference Paper,"Elberzhager, Frank;Holl, Konstantin",Include,Yes
10.1016/j.infsof.2022.107144,2-s2.0-85098586388,10.1109/FIE44824.2020.9274225,Towards Designing an Experience-based Course around Innovation Bootcamps - A Cohort Study,"Context: This full research paper presents an experience-based course designed around a semester-long external Innovation Bootcamp activity. Objective: We sought to evaluate the impact of Innovation Bootcamp on students' learning and startup formation. To this end, we measured how the Innovation Bootcamp affected students' perceived challenges related to technical, soft project management skills and the startup formation mindset. Method: We conducted a cohort study comprising questionnaires, interviews, and focus groups with both students and stakeholders participating in the Innovation Bootcamp. In total, 44 students participated in the questionnaires run before and after the Innovation Bootcamps during both academic years. Moreover, we conducted four individual interviews (student cohort 1), four focus group interviews (student cohort 2), and six individual interviews with different stakeholders participating in the Innovation Bootcamp during both years. Results: We find that perceptions of challenges regarding soft and project management skills drop, while perceptions regarding technical skills challenges do not vary during the course. Students exhibit increased motivation to engage in startup formation following close collaboration with external stakeholders only after developing their first minimum viable product. Contribution: The overall outcomes of the study contribute to validating a new course design model, which will help develop a course framework to help future educators, researchers, and practitioners adopt Innovation Bootcamp activities within a software engineering-focused experience-based course.",Bootcamp | Experience-based course | External stakeholders | Interdisciplinary course | Project management skills | Soft skills | Technical skills,"Proceedings - Frontiers in Education Conference, FIE",2020-10-21,Conference Paper,"Cico, Orges;Jaccheri, Letizia;Duc, Anh Nguyen",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-84994189345,10.1016/j.echo.2016.07.002,Using Anatomic Intelligence to Localize Mitral Valve Prolapse on Three-Dimensional Echocardiography,"Background Accurate localization of mitral valve prolapse (MVP) is crucial for surgical planning. Despite improved visualization of the mitral valve by three-dimensional transesophageal echocardiography, image interpretation remains expertise dependent. Manual construction of mitral valve topographic maps improves diagnostic accuracy but is time-consuming and requires substantial manual input. A novel computer-learning technique called Anatomical Intelligence in ultrasound (AIUS) semiautomatically tracks the annulus and leaflet anatomy for parametric analysis. The aims of this study were to examine whether AIUS could improve accuracy and efficiency in localizing MVP among operators with different levels of experience. Methods Two experts and four intermediate-level echocardiographers (nonexperts) retrospectively performed analysis of three-dimensional transesophageal echocardiographic images to generate topographic mitral valve models in 90 patients with degenerative MVP. All echocardiographers performed both AIUS and manual segmentation in sequential weekly sessions. The results were compared with surgical findings. Results Manual segmentation by nonexperts had significantly lower sensitivity (60% vs 90%, P < .001), specificity (91% vs 97%, P = .001), and accuracy (83% vs 95%, P < .001) compared with experts. AIUS significantly improved the accuracy of nonexperts (from 83% to 89%, P = .003), particularly for lesions involving the A3 (from 81% to 94%, P = .006) and P1 (from 78% to 88%, P = .001) segments, presumably related to anatomic variants of the annulus that made tracking more challenging. AIUS required significantly less time for image analysis by both experts (1.9 ± 0.7 vs 9.9 ± 3.5 min, P < .0001) and nonexperts (5.0 ± 0.5 vs 13 ± 1.5 min, P < .0001), especially for complex lesions. Conclusions Anatomic assessment of mitral valve pathology by three-dimensional transesophageal echocardiography is experience dependent. A semiautomated algorithm using AIUS improves accuracy and efficiency in localizing MVP by less experienced operators.",Computer imaging | Mitral valve | Three-dimensional echocardiography | Transesophageal echocardiography,Journal of the American Society of Echocardiography,2016-10-01,Article,"Jin, Chun Na;Salgo, Ivan S.;Schneider, Robert J.;Kam, Kevin Ka Ho;Chi, Wai Kin;So, Chak Yu;Tang, Zhe;Wan, Song;Wong, Randolph;Underwood, Malcolm;Lee, Alex Pui Wai",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-37349065897,10.1007/3-540-64574-8_427,Using artificial intelligence planning techniques to automatically reconfigure software modules,"One important approach to enhancing software reuse is through the creation of large-scale software libraries. By modularizing functionality, many complex specialized applications can be built up from smaller reusable general purpose libraries. Consequently, many large software libraries have been formed for applications such as image processing and data analysis. However, knowing the requirements and formats of each of these routines requires considerable expertise - thus limiting the usage of these libraries by novices. This paper describes an approach to enable novices to use complex software libraries. In this approach, the interactions between and requirements of the software modules are represented in a declarative language based on Artificial Intelligence (AI) Planning techniques. The user is then able to specify their goals in terms of this language - designating what they want done, not how to do it. The AI planning system then uses this model of the available subroutines to compose a domain specific script to fulfill the user request. Specifically, we describe three such systems developed by the Artificial Inteligence Group of the Jet Propulsion Laboratory. The Multimission VICAR Planner (MVP) has been deployed for 2 years and supports image processing for science product generation for the Galileo mission. MVP has reduced time to fill certain classes of requests from 4 hours to 15 minutes. The Automated SAR Image Processing system (ASIP) is currently in use by the Dept. of Geology at ASU to support aeolian science analysis of synthetic aperture radar images. ASIP reduces the number of manual inputs in science product generation by 10- fold. Finally, the DPLAN system reconfigures software modules which control complex antenna hardware to configure antennas to support a wide range of tracks for NASA's Deep Space Network of communications and radio science antennas.",,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),1998-01-01,Conference Paper,"Chien, Steve;Fisher, Forest;Mortensen, Helen;Lo, Edisanter;Greeley, Ronald;Govindjee, Anita;Estlin, Tara;Wang, Xue Mei",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-0004664352,10.3233/IDA-1999-3302,Using artificial intelligence planning to automate science image data analysis,"In recent times, improvements in imaging technology have made available an incredible array of information in image format. While powerful and sophisticated image processing software tools are available to prepare and analyze the data, these tools are complex and cumbersome, requiring significant expertise to properly operate. Thus, in order to extract (e.g., mine or analyze) useful information from the data, a user (in our case a scientist) often must possess both significant science and image processing expertise. This article describes the use of artificial intelligence (AI) planning techniques to represent scientific, image processing and software tool knowledge to automate knowledge discovery and data mining (e.g., science data analysis) of large image databases. In particular, we describe two fielded systems. The Multimission VICAR Planner (MVP) which has been deployed for since 1995 and is currently supporting science product generation for the Galileo mission. MVP has reduced time to fill certain classes of requests from 4 h to 15 min. The Automated SAR Image Processing system (ASIP) was deployed at the Department of Geology at Arizona State University in 1997 to support aeolian science analysis of synthetic aperture radar images. ASIP reduces the number of manual inputs in science product generation by ten-fold. © 1999 Published by Elsevier Science B.V.",Planning | Reconfiguration of software modules | Science data analysis,Intelligent Data Analysis,1999-01-01,Article,"Chien, Steve;Fisher, Forest;Lo, Edisanter;Mortensen, Helen;Greeley, Ronald",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-0030172610,10.1006/rtim.1996.0019,UWICL: A multi-layered parallel image computing library for single-chip multiprocessor-based time-critical systems,"Many software libraries have been created to support the commonly used primitive operations needed in image processing, image analysis and image understanding. Generally, these libraries are based on the single-layered Application Program Interface (API). While a single-layered API provides the useful abstraction level to interact with the library and hides unnecessary implementation details from the user, it does not produce an efficient program when a new algorithm is implemented by assembling the selected existing library routines. The composed program suffers from the inefficient data movement and additional loop control overhead. Furthermore, when a system employs a highly integrated processor such as a single-chip multiprocessor, the single-layered API prevents the user from fully utilizing the resources available in the system. In this article, we describe the University of Washington Image Computing Library (UWICL), the multi-layered high-performance parallel image computing library for Texas Instruments TMS320C80 Multimedia Video Processor (MVP)-based time-critical systems. Our goal in designing the UWICL is to provide the TMS320C80 user community with efficient and flexible image computing library routines. The UWICL provides three levels of APIs to the programmers under the multi-layered organization, the MVP-level API, the DSP-level API, and APIs for data flow and processing cores. By optimizing the processing core functions, we have achieved high performance in the individual function level, and by allowing the sub-primitive library routine composition, we can achieve efficient image processing application development, avoiding most problems encountered in using the single-layered library routines. The performance of the multi-layered organization vs. the single-layered one is analysed and compared using the Canny's edge detection algorithm as an example. The balanced composition based on the multi-layered organization outperforms the single-layered composition by 14 to 41% depending on the system's memory bandwidth available. As an adjunct to the UWICL, we have also developed an integrated MVP performance monitor (MPM). The MPM can identify the performance bottleneck of the TMS320C80 applications and can be used in optimization by enabling the user to select the most efficient library composition level in building the application with the UWICL. In order to provide the overall performance evaluation model of the MVP, the simple MVP functional model has also been defined in the MPM. For the image thresholding operation, the difference between the measured execution time and the analysis prediction is less than 2%. The design and implementation of the MPM, and the applicability and usefulness of the MPM and MVP performance model are described in this article. © 1996 Academic Press Limited.",,Real-Time Imaging,1996-01-01,Article,"Kim, Jihong;Kim, Yongmin",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-0026845731,10.1080/18811248.1992.9731532,Vectorization of continuous energy monte carlo method for neutron transport calculation,"The vectorization method was studied to achieve a high efficiency for the precise physics model used in the continuous energy Monte Carlo method. The collision analysis task was reconstructed on the basis of the event based algorithm, and the stack-driven zone-selection method was applied to the vectorization of random walk simulation. These methods were installed into the vectorized continuous energy MVP code for general purpose uses. Performance of the present method was evaluated by comparison with conventional scalar codes VIM and MCNP for two typical problems. The MVP code achieved a vectorization ratio of more than 95% and a computation speed faster by a factor of 8-22 on the FACOM VP-2600 vector supercomputer compared with the conventional scalar codes. © 1992 Taylor & Francis Group, LLC.",Computer calculations | Computer codes | Continuous energy | Efficiency | Monte Carlo method | Neutron transport | Vectorization,Journal of Nuclear Science and Technology,1992-01-01,Article,"Mori, Takamasa;Nakagawa, Masayuki;Sasaki, Makoto",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-0022239355,10.1002/esp.3290100104,Ventifacts distribution in Qatar,"This study attempts to investigate the distribution of ventifacts in Qatar. It is believed that ventifacts are confined to the areas within about 5 km of the Miocene or Mio‐Pliocene Hofuf formations and the spreads of continental gravels derived from them. Three hypotheses were formulated: (1) Ventifacts in Qatar are confined to areas within about 5 km of the Hofuf formations and the spreads of continental gravels derived from them. The distribution of ventifacts within these areas varies according to the nature of the ground surface; (2) The most active ventifaction areas are where the continental gravels merge with the Eocene limestone because of the increase in saltation particle speed in these areas where bedrock or bare limestone is exposed; (3) The unit area ratio of ventifact to non‐ventifact pebbles varies inversely with the total amount of pebbles. To test these hypotheses, nine land class categories were identified in the three major Hofuf formations. Line transects were carried out from randomly selected stations near the middle of the Hofuf formations. Along each transect systematic sampling was carried out at 200 m intervals. The data were processed using a WANG MVP 2200 computer with software developed for the project. It was found that ventifacts tend to concentrate on the outer edges of the continental gravels in areas of limestone outcrop and limestone pavement. Higher areas have big gravel counts and a low ratio of ventifacts while the low‐lying plains have small gravel counts and a higher ratio of ventifacts. In certain areas ‘ventifact fields’ were found where the density of ventifacts was as high as 30 per m2. Many of the ventifacts in these fields were buried beneath the surface suggesting that the ventifaction predates the present site conditions. Other high ventifact density areas were discovered where the ventifacts have collected in shallow depressions or hollows on the limestone plateaux. Water action has washed these ventifacts, a high proportion of which are dreikanters, into the hollows, where they have been partially buried in fine alluvial silts. These ‘ventifact graveyards’ are generally only a few metres wide but contain large numbers of fine specimens. Copyright © 1985 John Wiley & Sons, Ltd",Continental gravels | Dreikanters | Hofuf formation | Qatar | Ventifact graveyards | Ventifacts,Earth Surface Processes and Landforms,1985-01-01,Article,"Babikir, A. A.A.;Jackson, C. C.E.",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-85091630718,10.1109/TG.2019.2910248,Video Game Development in a Rush: A Survey of the Global Game Jam Participants,"Video game development is a complex endeavor, often involving complex software, large organizations, and aggressive release deadlines. Several studies have reported that periods of 'crunch time' are prevalent in the video game industry, but there are few studies on the effects of time pressure. We conducted a survey with participants of the Global Game Jam (GGJ), a 48-h hackathon. Based on 198 responses, the results suggest the following: iterative brainstorming is the most popular method for conceptualizing initial requirements; continuous integration, minimum viable product, scope management, version control, and stand-up meetings are frequently applied development practices; regular communication, internal playtesting, and dynamic and proactive planning are the most common quality assurance activities; and familiarity with agile development has a weak correlation with perception of success in the GGJ. We conclude that GGJ teams rely on ad hoc approaches to the development and face-To-face communication, and recommend some complementary practices with limited overhead. Furthermore, as our findings are similar to recommendations for software startups, we posit that game jams and the startup scene share contextual similarities. Finally, we discuss the drawbacks of systemic 'crunch time' and argue that game jam organizers are in a good position to problematize the phenomenon.",Game development | game jam | opinion survey | software engineering | time pressure,IEEE Transactions on Games,2020-09-01,Article,"Borg, Markus;Garousi, Vahid;Mahmoud, Anas;Olsson, Thomas;Stalberg, Oskar",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-0026189153,10.1016/0169-2607(91)90124-C,VTM - an image-processing system for measuring ocular torsion,"This paper reports a new, fast, accurate realization of an image-processing method of measuring ocular torsion (rotation of the eyeball around the visual axis) called Video Torsion Measurement (VTM). The method is to cross-correlate the two grey-level distributions of an arc of the iris from two separate images using a fast image processor card interfaced to an IBM-AT compatible computer. The card (Matrox MVP-AT) is supplied with a library of low-level functions for controlling the hardware operations of the board and the VTM system software, which is written in the C programming language, incorporates these low-level functions to interface with the MVP-AT board as well as carrying out the data-acquisition and processing algorithms. These programs: acquire an image of an iris illuminated by a single infrared (IR) light source; threshold this image in order to identify the pupil; calculate the pupil area and locate the centre of the pupil using a centre-of-gravity algorithm; record the grey-level distribution along an arc 256 pixels long at a selected radius from the pupil centre; carry out an FFT on this (interpolated) grey level distribution; store the parameters of this reference FFT and cross-correlate the comparable iral grey-level distribution from other test images of the same eye in order to determine the amount of torsional rotation of the test images relative to the reference image. This system is interactive and is designed for operation in a clinical testing situation with a minimum of operator intervention. The VTM system has a resolution of the order of 0.1 deg depending on the arc radius used and it has been validated in two ways: by using it to measure known torsional rotations of an artificial iris-like pattern and also by direct simultaneous comparison of measures on the same human iris images from VTM and those from the standard 35 mm photographic procedure of measuring torsion. © 1991.",Image-processing | Linear acceleration | Ocular counterrolling | Ocular torsion | Oculomotor | Otolith | Vestibular,Computer Methods and Programs in Biomedicine,1991-01-01,Article,"Moore, S. T.;Curthoys, I. S.;McCoy, S. G.",Include,IC1
10.1016/j.infsof.2022.107144,2-s2.0-85018679705,10.1007/978-3-319-57633-6_2,What influences the speed of prototyping? An empirical investigation of twenty software startups,"It is essential for startups to quickly experiment business ideas by building tangible prototypes and collecting user feedback on them. As prototyping is an inevitable part of learning for early stage software startups, how fast startups can learn depends on how fast they can prototype. Despite of the importance, there is a lack of research about prototyping in software startups. In this study, we aimed at understanding what are factors influencing different types of prototyping activities. We conducted a multiple case study on twenty European software startups. The results are two folds; firstly we propose a prototype-centric learning model in early stage software startups. Secondly, we identify factors occur as barriers but also facilitators for prototyping in early stage software startups. The factors are grouped into (1) artifacts, (2) team competence, (3) collaboration, (4) customer and (5) process dimensions. To speed up a startup’s progress at the early stage, it is important to incorporate the learning objective into a well-defined collaborative approach of prototyping.",MVP | Prototype | Prototyping-learning loop | Software startups | Speed | Validated learning,Lecture Notes in Business Information Processing,2017-01-01,Conference Paper,"Nguyen-Duc, Anh;Wang, Xiaofeng;Abrahamsson, Pekka",Include,Yes
10.1016/j.infsof.2022.107144,2-s2.0-85055807026,10.1007/978-3-030-02131-3_20,What is a minimum viable (video) game?: Towards a research agenda,"The concept of ‘Minimum Viable Product’ (MVP) is largely adapted in the software industry as well as in academia. Minimum viable products are used to test hypotheses regarding the target audience, save resources from unnecessary development work and guide a company towards a stable business model. As the game industry is becoming an important business domain, it is not surprise that the concept has been adopted also in the game development. This study surveys how a Minimum Viable Game (MVG) is defined, what is reported in extant literature as well as present results from a small case study survey done to nine game development companies. The study shows that despite popularity of minimum viable games in the industrial fora, the presented views on the concept are diverged and there is lack of practical guidelines and research supporting game companies. This study points out research gaps in the area as well as calls for actions to further develop the concept and to define guidelines.",Game business | Minimum viable game | Minimum viable product,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2018-01-01,Conference Paper,"Hyrynsalmi, Sami;Klotins, Eriks;Unterkalmsteiner, Michael;Gorschek, Tony;Tripathi, Nirnaya;Pompermaier, Leandro Bento;Prikladnicki, Rafael",Exclude,EC1
